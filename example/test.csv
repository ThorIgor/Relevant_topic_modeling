container_type,source,bib_title,bib_author,bib_pub_year,bib_venue,bib_abstract,filled,gsrank,pub_url,author_id,url_scholarbib,url_add_sclib,num_citations,citedby_url,eprint_url,query,public_id,internal_id,fulltext,url_related_articles
Publication,PUBLICATION_SEARCH_SNIPPET,Exploring the Implications of ChatGPT for Language Learning in Higher Education,"['FR Baskara', 'FX Mukarto']",2023,IJELTAL (Indonesian Journal of …,"However, the impact of large language models like ChatGPT in higher education language  learning has not been thoroughly investigated. Therefore, this paper aims to contribute to the",False,14,https://repository.usd.ac.id/46291/1/9599_1387-3947-1-PB.pdf,"['zjO7_JQAAAAJ', 'isf7nkwAAAAJ']",/scholar?q=info:1FxA4s3CVu8J:scholar.google.com/&output=cite&scirp=13&hl=en,"/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522large%2Blanguage%2Bmodels%2522%2B%252B%2522higher%2Beducation%2522%26hl%3Den%26start%3D10%26as_sdt%3D0,33%26as_ylo%3D2000%26as_yhi%3D2023&citilm=1&update_op=library_add&info=1FxA4s3CVu8J&ei=zReNZKCnB4jimgH2vJ6gDQ&json=",1,"/scholar?cites=17246186012581846228&as_sdt=5,33&sciodt=0,33&hl=en",https://repository.usd.ac.id/46291/1/9599_1387-3947-1-PB.pdf,"""large language models"" +""higher education""",1FxA4s3CVu8J_2023_Exploring the Implications of ChatGPT for Language Learning in Higher Education,d8929ccd1af14a34a4f9d8541eba1cd9,"In the realm of higher education, there is an increasing fascination with the capabilities of technology to improve language learning experiences (Aljawarneh, 2020; García Botero et al., 2019; Hoi, 2020; Parmaxi & Demetriou, 2020; Shadiev & Yang, 2020; Sun & Gao, 2020) . Among these technologies is ChatGPT, a member of the category of large language models (Kasneci et al., 2023; Perkins, 2023) . Using sophisticated algorithms and deep learning methods, these models can produce written text that closely resembles that created by human beings (Brown et al., 2022; Khalil & Er, 2023; Schwitzgebel et al., 2023) . Although Indonesian Journal of English Language Teaching and Applied Linguistics, 7(2), 2023 some studies have explored the potential of ChatGPT in education, a thorough investigation into its effects on higher education language learning has yet to be conducted. To provide a strong foundation for this study, it is essential to first review existing literature on the topic. Previous studies on language learning and technology have examined the effectiveness of various tools and techniques in promoting language acquisition (Albiladi & Alshareef, 2019; Hoi, 2020; Shadiev & Yang, 2020) . For instance, some studies have explored using chatbots and virtual assistants in language learning (Chuah & Kabilan, 2021; Huang et al., 2022; Jeon, 2021; Kim et al., 2019) . However, the impact of large language models like ChatGPT in higher education language learning has not been thoroughly investigated. Therefore, this paper aims to contribute to the existing body of knowledge by exploring the potential benefits and challenges of incorporating ChatGPT into higher education language courses and programs. Incorporating ChatGPT into language learning in higher education offers many opportunities for exploration and research (Atlas, 2023; Kasneci et al., 2023) . One of the most significant areas of research would be to evaluate the effectiveness of ChatGPT in language learning through empirical studies. By comparing language learners who use ChatGPT with those who do not, researchers could identify the advantages of this technology. These studies could measure various language proficiency metrics such as vocabulary, grammar, reading comprehension, or speaking abilities. Additionally, evaluating the accuracy and coherence of ChatGPT's generated text and detecting and mitigating potential biases or stereotypes in its output could enhance the safety and efficiency of utilising ChatGPT in language learning. Moreover, further research must also emphasise the ethical and social ramifications of utilising ChatGPT in language learning. Such research would investigate the impact of ChatGPT on language teachers, learners, and society at large, through techniques such as surveys, interviews, focus groups, or other qualitative or quantitative methodologies. The outcomes of this research could shed light on the ethical and social implications of using ChatGPT in language learning and provide valuable insights into this subject. Furthermore, studying the limitations of ChatGPT in processing complex or abstract concepts and investigating its potential applications in language learning games, providing feedback on learners' writing, and assisting with language translation, among others, could open new possibilities in language learning. However, there is a need for further research to comprehend ChatGPT's potential and limitations fully. By exploring the challenges and concerns, ethical and social implications, limitations, and opportunities for improvement, future research could unlock the full potential of ChatGPT in language learning and advance our understanding of its role in higher education. Reviewing the current literature on the subject matter is essential to establish a solid theoretical foundation for this investigation. Prior studies on language learning and technology have assessed the effectiveness of various tools and techniques in facilitating language acquisition (Andujar et al., 2020; Randall, 2019; R. Zhang & Zou, 2020) . However, there is a paucity of research on using large language models like ChatGPT in higher education language learning. Despite this gap in the literature, the potential of large language models like ChatGPT in language learning is an emerging area of interest. ChatGPT, in particular, has garnered significant attention due to its ability to generate human-like text and has been proposed as a promising tool for language education. Therefore, this paper aims to bridge this gap by providing a conceptual framework for understanding the relationship between ChatGPT and language learning in higher education. The goal is to explore the potential benefits and challenges of incorporating ChatGPT into language education in higher education. To achieve this goal, this paper will employ a comprehensive literature review to explore the current knowledge of ChatGPT and its implications for language learning. Additionally, this paper will examine the potential applications and limitations of ChatGPT in language instruction and practice. By doing so, this paper aims to contribute to the ongoing discourse surrounding the role of technology in language learning, specifically regarding ChatGPT in higher education. Ultimately, this paper seeks to stimulate further research, providing a more in-depth understanding of the relationship between technology and language learning. In examining the potential implications of ChatGPT for language education in higher education, this paper will first provide an overview of ChatGPT and its capabilities. Subsequently, the discussion will explore the potential benefits and challenges of incorporating such language models into language education in higher education. The scope of this paper is restricted to ChatGPT, with emphasis placed on exploring its potential applications and implications in language instruction and practice. It is important to note that this paper does not aim to comprehensively examine all existing large language models or language learning technologies. The focus remains on ChatGPT, providing a deeper understanding of its role in language learning within the context of higher education. Additionally, the paper will suggest areas for further research in this area to contribute to the ongoing discourse on the impact of technology on language learning. This paper aims to contribute to the ongoing discourse on the role of technology in language learning, particularly in the context of ChatGPT in higher education. By exploring the potential advantages and drawbacks of integrating ChatGPT in language learning, this study aims to inspire further research in this field. The use of language models such as ChatGPT has excellent potential in higher education, and to fully comprehend the benefits and drawbacks of their utilisation, further research is required. Natural Language Processing (NLP) has been a significant area of research for many years, aiming to enhance computer systems' ability to understand and generate human language (Cambria & White, 2014; Hirschberg & Manning, 2015; Torfi et al., 2020) . Recent advancements in this field have led to the development of large language models, which use machine-learning algorithms to learn from vast amounts of text data and generate humanlike language (Dida et al., 2023; Maddigan & Susnjak, 2023) . The Generative Pre-trained Transformer (GPT) series, developed by OpenAI, has received significant attention among these large language models. The most recent iteration, ChatGPT, is a large-scale unsupervised language model that can generate human-like text on various subjects (Taecharungroj, 2023) . The development of ChatGPT marks a significant milestone in the field of NLP, as it represents a significant step towards creating more advanced and sophisticated computer systems capable of understanding and generating natural language (Kasneci et al., 2023 is trained on vast text data and can generate coherent and contextually appropriate responses to a prompt. The model's capacity to generate text that resembles human language has significant implications for language learning, communication, and education. While ChatGPT represents a significant advancement in NLP, it is not the only large language model currently used. BERT, developed by Google, is another prominent example of a large language model (Devlin et al., 2018) . Like ChatGPT, BERT is pre-trained on vast amounts of text data and can be fine-tuned for various natural languages processing tasks, such as sentiment analysis, question-answering, and language translation (Mathew & Bindu, 2020; Min et al., 2021) . While the core functionality of BERT and ChatGPT is similar, they differ in their pre-training methodology and model architecture (Zhou et al., 2023) . The development of these large language models has the potential to revolutionise many industries, including education, healthcare, and communication, by enabling more sophisticated and natural interactions between humans and machines (Blanco-Gonzalez et al., 2022; Ferruz & Höcker, 2022; Kasneci et al., 2023; S. Zhang et al., 2023) . In today's interconnected society, the importance of multilingualism for personal and professional success cannot be overstated (Conteh, 2007; Maharaja, 2018; Mitits, 2018) . Language learning allows students to develop cross-cultural communication skills, broaden their perspectives, and access new knowledge (Citron, 1995; Tafazoli et al., 2018; Truong & Tran, 2014) . Higher education institutions offer a variety of language courses and programs to help students achieve language proficiency (Erling & Hilgendorf, 2006; Dimova & Kling, 2020; Oralova, 2012) . These programs often use instructional methods and technologies, such as communicative language teaching, task-based language learning, and computer-assisted language learning (CALL) (Chong & Reinders, 2020; Nguyen et al., 2015; Parmaxi & Demetriou, 2020) . Technology integration in language learning holds several potential benefits, including personalised instruction, communicative language practice, and the generation of authentic language material for learners to engage with (Chen et al., 2021; Kirkwood & Price, 2014; Vieira et al., 2014) . With the rapid advancement of natural language processing technology, there is growing interest in the potential of large language models such as ChatGPT to enhance language learning and instruction in higher education (OguzhanTopsakal, 2022). The following sections of this paper delve into the potential impact of ChatGPT on language learning in higher education and propose avenues for future research in this field. ChatGPT is a large-scale generative language model developed by OpenAI (Lund & Wang, 2023; Mhlanga, 2023; Pavlik, 2023) . The GPT stands for Generative Pre-trained Transformer, which refers to its architecture. ChatGPT has a vast vocabulary and can generate human-like text on various subjects, making it a powerful tool for language learning and instruction (Cotton et al., 2023; Shahriar & Hayawi, 2023; Shen et al., 2023) . Its development builds on the success of previous models such as GPT-1, GPT-2, and GPT-3, which OpenAI also created. ChatGPT has a massive training dataset consisting of billions of words, making it possible to generate text that is not only grammatically correct but also coherent and semantically relevant (Zhou et al., 2023) . This is achieved using a transformer architecture, a neural network model that processes sequential data (Zhou et al., 2023) . The transformer allows ChatGPT to learn the relationships between words and generate text similar to natural human language. Additionally, ChatGPT can be fine-tuned on specific tasks, making it even more versatile in its applications (Lund & Wang, 2023) . One of the unique features of ChatGPT is its ability to generate text conditional on input prompts (Sallam, 2023) . For example, a user can input a partial sentence or a question, and ChatGPT can generate a complete response. ChatGPT's potential for language learning and instruction is particularly significant, as it can provide personalised and interactive learning experiences. With its vast vocabulary and ability to generate contextually appropriate responses, ChatGPT can aid in developing communicative proficiency in a foreign language. ChatGPT is a robust large language model developed by OpenAI (Baidoo-Anu & Owusu Ansah, 2023; Kasneci et al., 2023; Lund & Wang, 2023; Sallam, 2023) . The model is trained using a transformer architecture that utilises unsupervised learning to generate human-like text across various domains. The most recent version of the model, GPT-3, has an unprecedented number of parameters, estimated to be around 175 billion (Benbya et al., 2020; Ferruz & Höcker, 2022; Reis et al., 2021) . This extensive training results in the model's ability to produce coherent and contextually appropriate responses to various prompts, including questions, prompts, and text completions. ChatGPT's capabilities extend beyond simply generating text. The model could understand natural language queries and provide answers and summaries. ChatGPT can also communicate in the text between different languages, including low-resource languages (RudolphA, 2022). These features offer significant language learning and instruction potential, particularly in higher education. ChatGPT's text-generation capabilities make it a powerful tool for generating educational content and creating interactive learning experiences. In language learning, the model's ability to generate realistic dialogues can provide learners with authentic language use examples (George & George, 2023) . The model can also generate writing prompts and provide feedback on written work, which can improve learners' writing skills (Baidoo-Anu & Owusu Ansah, 2023). ChatGPT's language translation capabilities offer a new approach to learning a second language (Jiao et al., 2023) . Learners can input text in their native language and have it automatically translated into their target language. They can also use ChatGPT to practice translating texts from their target language into their native language, providing an opportunity for additional practice. While ChatGPT's capabilities have significant potential for language learning, there are also challenges to consider. One such challenge is the potential for the model to produce biased or inappropriate content (Sallam, 2023) . This issue arises due to the model's training data, which can contain biased or discriminatory language (Hacker et al., 2023) . Additionally, because ChatGPT is an unsupervised learning model, it has the potential to generate incorrect or misleading information (Borji, 2023) . To address these challenges, researchers must develop strategies to identify and mitigate these issues. Despite these challenges, ChatGPT's capabilities offer promising potential for enhancing language learning experiences in higher education. This study embraces a multi-disciplinary approach, incorporating linguistics, education, and computer science insights. An extensive review of existing literature in natural language processing and utilisation of large language models, such as ChatGPT, in language learning, precedes the analysis of ChatGPT's ability to generate human-like text. This includes creating test cases to evaluate its coherence, fluency in various topics, and handling complex concepts. Comparison of the results with other language models determines ChatGPT's strengths and weaknesses in this context. Integration of ChatGPT into language courses and programs in higher education is then considered, including developing strategies and curricula that incorporate the model and analysing its benefits and challenges in language learning. Exploration of ChatGPT's potential applications in language learning entails examining existing examples and creating new case studies, highlighting its capabilities in generating language learning materials, providing feedback, and assisting with translation. A critical examination of the ethical implications of utilising a machine learning system in language learning rounds off the methodology, considering the impact on human language teachers, the role of language learning, and potential risks and benefits. The examination informs future research and guides the development of ethical guidelines for large language model utilisation in higher education. Thus, the methodology presents a comprehensive and interdisciplinary approach to investigating the implications of ChatGPT for language learning in higher education and informs future research in this field. The use of ChatGPT in language generation holds certain limitations that should be considered. While capable of generating text resembling human speech, it may encounter difficulties rendering more complex or abstract concepts. This is due to the predominant conversational nature of the data utilised in its training, which may not encompass comprehensive information regarding such topics. Moreover, using ChatGPT raises ethical considerations, such as the possibility of producing biased or offensive output (Atlas, 2023; Qadir, 2022; Zhuo et al., 2023) . The vast corpus of conversational text used in its training may encompass biases and stereotypes present in the source data, resulting in the generation of text that is sexist, racist, or otherwise inappropriate. Additionally, as ChatGPT lacks human nuance, it may not possess the same cultural awareness and understanding of appropriate language use as a human language teacher (Atlas, 2023; Susnjak, 2022) . Finally, the potential substitution of human language teachers with ChatGPT raises ethical concerns regarding the impact on employment and the profession and questions about the necessity and desirability of such a replacement. In higher education, the advent of large language models such as ChatGPT holds the promise of revolutionising language learning and instruction. This section delves into the opportunities and obstacles of utilising ChatGPT for language instruction in higher education and offers illustrations of ChatGPT's potential applications in this context. Personalization, a hallmark of ChatGPT, represents a significant advantage for language instruction. By harnessing ChatGPT, language educators can fashion lesson plans and materials that cater to each learner's specific needs and preferences, thereby enhancing the effectiveness and appeal of language instruction (Zhai, 2022) . Lastly, ChatGPT's ability to generate authentic language materials, such as dialogues, news articles, or reading passages, represents another advantage for language instruction. Using ChatGPT, language teachers can provide learners authentic language exposure, thereby improving their reading and comprehension skills and language proficiency. Using ChatGPT in language learning can potentially provide personalised instruction to learners. Language teachers, through ChatGPT, can craft lesson plans and materials attuned to the needs and interests of individual students, thus improving the efficacy and engagement of language instruction. One example of ChatGPT's personalisation capability is creating practice exercises that align with the learner's proficiency level, interests, and objectives. Such targeted practice activities can enhance learners' language abilities and bolster their learning motivation. Another advantage of incorporating ChatGPT into language learning is its ability to generate authentic language material. Language teachers, through ChatGPT, can produce authentic language resources, such as dialogues, news articles, or reading passages, for learners to engage with and learn from. This can boost learners' reading and comprehension skills and provide exposure to authentic language material for improving language proficiency. For instance, ChatGPT can generate realistic dialogues, news articles, or reading passages for learners to interact with and learn from. ChatGPT can increase learners' motivation to learn and language proficiency by offering authentic language material. The deployment of ChatGPT, an innovative language model, presents a wealth of opportunities for language learning. However, it is imperative also to examine potential challenges and concerns that may arise in its implementation. One challenge is the potential for ChatGPT to produce biased or inappropriate content, as it is trained on a vast corpus of conversational text that may reflect the biases and stereotypes in the data. Thus, ensuring diverse and inclusive data sources is crucial in mitigating this risk. The utilisation of ChatGPT raises ethical considerations, such as the potential loss of jobs in the language teaching profession and the impact of technology on human language teachers. This area warrants further examination and reflection. Another challenge posed by ChatGPT is its limitations in comprehending more complex or abstract concepts, leading to inaccuracies in generated text and hindering its effectiveness for language learning in specific contexts. Understanding and addressing these limitations is crucial. The safe and effective implementation of ChatGPT in language learning demands careful monitoring and evaluation, potentially requiring the development of new evaluation methods and tools. Assessing ChatGPT's usefulness in language learning is essential for ensuring its safe and effective use. In summary, the deployment of ChatGPT holds significant potential for revolutionising language learning. However, it is imperative to consider its challenges and concerns, such as the potential for biased content, its impact on the language teaching profession, limitations in dealing with complex concepts, and the need for careful monitoring and evaluation. By understanding these challenges and concerns, the language learning community can work together to leverage the full potential of ChatGPT while mitigating its potential drawbacks. ChatGPT presents an array of applications in language learning, each with its benefits and challenges. This section provides several illustrations of the use of ChatGPT in language courses and programs. These examples aim to demonstrate the potential advantages and difficulties of ChatGPT in language learning and inspire ideas for its various applications. Personalised language instruction stands as a potential application of ChatGPT. Using ChatGPT, language teachers can tailor lesson plans and materials to individual learners' needs and interests, enhancing the effectiveness and motivation of language instruction. For instance, ChatGPT could create personalised practice exercises for learners, reflecting their language proficiency, interests, and goals. Such tasks could range from gap-filling to sentence completion to translation, catering to each learner's requirements and preferences. ChatGPT can improve language skills and increase learners' learning motivation by personalising practice exercises. Generating authentic language material constitutes a third application of ChatGPT in language learning. With ChatGPT, language teachers can produce authentic language material, such as dialogues, news articles, or reading passages, for learners to learn from and engage with. This enhances learners' reading and comprehension skills, exposing them to authentic language material that can be used to improve their language skills. For instance, ChatGPT could generate authentic dialogues, news articles, or reading passages for learners to learn from and engage with. These materials could be used in reading comprehension exercises, or writing prompts, providing learners with opportunities to improve their language skills through exposure to authentic language material. ChatGPT can increase learners' motivation to learn and overall language proficiency by providing such authentic language material.  In the realm of higher education language learning, ChatGPT offers a multitude of avenues for investigation and examination. A deliberate drive towards further research is necessary to maximise the benefits of this technology. Research initiatives could cover a broad spectrum of studies, targeting different facets of utilising ChatGPT in language learning. Evaluating the effectiveness of ChatGPT for language learning through empirical studies would be crucial in determining the true potential of this technology. Comparisons between language learners using ChatGPT and those without could yield important information regarding the advantages of this technology. These studies could measure various language proficiency metrics, such as vocabulary, grammar, or reading comprehension. Future research must also emphasise the ethical and social ramifications of utilising ChatGPT in language learning. This would involve investigating the impact of ChatGPT on language teachers, learners, and society at large, through techniques such as surveys, interviews, focus groups, or other qualitative or quantitative methodologies. The outcomes of this research could shed light on the ethical and social implications of utilising ChatGPT in language learning and provide valuable insights into this subject. To guarantee the safety and efficiency of utilising ChatGPT in language learning, it is essential to create novel methods and tools for evaluating the performance of ChatGPT in this context. These tools could include automated or manual evaluations of the accuracy and coherence of ChatGPT's generated text, as well as methods for detecting and mitigating potential biases or stereotypes in the output of this technology. Investigating the limitations of ChatGPT in processing complex or abstract concepts is another significant area of future research. Such research could aim to understand this technology's strengths and weaknesses better. Studies examining the relationship between ChatGPT and language learning in higher education would also be valuable. These studies could explore how ChatGPT can support language learning in higher education and offer suggestions for future research. Additionally, exploring the possibility of substituting human language teachers with machines is critical. Such research could examine the ethical implications of this potential substitution and the role of human language teachers in language learning. It could also provide valuable perspectives on whether replacing human language teachers with machines in language learning is necessary or desirable. In conclusion, using ChatGPT in higher education language learning offers many opportunities for further research and examination. By focusing on the challenges and concerns, ethical and social implications, limitations, and opportunities for improvement, future research could unlock the full potential of this technology and advance our understanding of its role in higher education language learning. The utilisation of ChatGPT in language learning in higher education is a topic that requires further examination and investigation. Beyond the areas already discussed, there are numerous avenues for exploration. Indonesian Journal of English Language Teaching and Applied Linguistics, 7(2), 2023 Creating new techniques and resources for utilising ChatGPT in language learning is crucial to harnessing its full potential. These techniques and resources could encompass innovative ways of personalising language instruction or generating authentic language materials. Developing such methods and tools could enhance the effectiveness and efficiency of utilising ChatGPT for language learning. The assimilation of ChatGPT into existing language learning programs and courses is another aspect that requires attention. Strategies for integrating ChatGPT into current language learning programs and courses should be developed to ensure consistency with the goals and objectives of language learning in higher education. This could involve the creation of new curricula, pedagogical methods, or assessment techniques that integrate ChatGPT. In addition, there are potential new applications of ChatGPT in language learning that warrant investigation. This includes, but is not limited to, using ChatGPT in language learning games, providing feedback on learners' writing, and assisting with language translation. Exploring these and other potential applications of ChatGPT will allow for a better comprehension of the full range of possibilities for its usage in language learning. Investigating the utilisation of ChatGPT in language learning in higher education is a valuable endeavour that promises to provide new and innovative solutions to language learning challenges. Examining various aspects of ChatGPT usage, including new methods and tools, integration into existing programs and courses, and exploration of new applications, we can comprehensively understand its potential and limitations in language learning.  Evaluating the effectiveness of ChatGPT for language learning and comparing it with traditional methods through empirical studies. Investigating the impact of ChatGPT on language teachers, learners, and society through surveys, interviews, and focus groups. Developing methods and tools for evaluating the accuracy, coherence, and bias of ChatGPT's generated text. Examining ChatGPT's limitations in comprehending complex and abstract concepts to understand its strengths and weaknesses. Investigating the extent to which ChatGPT can support language learning in higher education and exploring its potential uses. Developing innovative techniques and resources for using ChatGPT in language learning to enhance its effectiveness and efficiency. Creating strategies for integrating ChatGPT into current language learning programs and courses. Exploring new applications of ChatGPT in language learning, such as language learning games, writing feedback, and translation. Integrating large language models like ChatGPT into language learning and instruction in higher education presents an exciting opportunity for advancing the field. Its ability to offer personalised instruction and generate authentic language material highlights its potential for improving the effectiveness and efficiency of language education. However, using ChatGPT also brings ethical and social considerations that must be addressed. The need for further research in this area cannot be overstated. Such research would provide insight into the potential benefits and challenges of using ChatGPT in language learning and facilitate the development of methods and tools that ensure its safe, effective, and ethical use. It is essential to consider the impact of ChatGPT on language teachers, learners, and society. Investigating the ethical and social implications of using ChatGPT for language learning will contribute to a better understanding of its role in higher education. The generated text's accuracy and coherence must be evaluated to ensure the effectiveness of using ChatGPT in language learning. Both automated and manual evaluations could be employed for this purpose, and methods for detecting and addressing biases and stereotypes in the technology's output should also be developed. Investigating the limitations of ChatGPT in handling complex and abstract language concepts is another area of future research that requires attention. This would provide insights into the technology's strengths and weaknesses and help identify ways to overcome these limitations. Finally, the potential for substituting human language teachers with machines must also be explored. The ethical implications of this potential substitution and the role of human teachers in language learning are crucial to consider. Such research would suggest whether replacing human language teachers with machines in the language learning process is desirable or necessary. In conclusion, using ChatGPT in language learning in higher education offers many opportunities for research and exploration. Through a focus on ethical and social implications, limitations, and opportunities for improvement, future research can unlock the full potential of this technology and contribute to a better understanding of its role in language education. Utilising ChatGPT to generate personalised lesson plans and materials and produce authentic language material enhances the effectiveness and efficiency of language instruction in higher education. Considering the ethical and social implications of ChatGPT usage in language education, including the impact on language teachers, learners, and society, is crucial for the safe and effective implementation. Evaluating ChatGPT's generated text's accuracy, coherence, and bias through automated and manual evaluation methods Indonesian Journal of English Language Teaching and Applied Linguistics, 7(2), 2023 ensures its safe and efficient use in language learning in higher education Limitations in Handling Complex Concepts Investigating ChatGPT's limitations in processing complex and abstract language concepts can identify ways to overcome these limitations and enhance its effectiveness in specific language-learning contexts Substitution of Human Language Teachers with Machines Exploring the potential substitution of human language teachers with ChatGPT raises ethical concerns about its impact on employment and the profession and the necessity and desirability of such a replacement in language learning The potential of ChatGPT to impact language learning in higher education is vast, making it a worthwhile subject of research and exploration. It is essential to thoroughly examine its potential benefits and challenges to leverage its advantages. Through empirical studies, the efficacy of ChatGPT for language learning can be established, providing crucial insights into its impact on language proficiency. Moreover, the ethical and social implications of ChatGPT for language learning must be thoroughly scrutinised, examining its impact on teachers, learners, and society at large. This can be done through qualitative or quantitative research methods, such as surveys, interviews, or focus groups. Doing so can garner a clear understanding of this technology's ethical and social implications. Developing evaluation methods and tools for ChatGPT's performance in language learning is crucial to ensure its safe and effective use. These tools can encompass evaluations of its accuracy, coherence, and bias in output. Furthermore, exploring the limitations of ChatGPT in dealing with complex or abstract language concepts is essential for a comprehensive understanding of its capabilities and limitations. Investigating the relationship between ChatGPT and language learning in higher education can also be valuable. This can help determine how much ChatGPT can support language learning, providing avenues for future research. The potential for substituting human language teachers with machines also deserves consideration. Research in this area can examine the ethical implications of such substitution and the role of human teachers in language learning. Doing so can provide valuable insights into the necessity and desirability of such substitution. In conclusion, ChatGPT's potential for language learning in higher education is significant. Through further research, its benefits and challenges, ethical and social implications, limitations, and opportunities for improvement can be better understood, helping unlock its full potential for language learning in higher education.",
Publication,PUBLICATION_SEARCH_SNIPPET,Large Language Models Like ChatGPT in ABME: Author Guidelines,['C Norris'],2023,Annals of Biomedical Engineering,"The use of Large Language Models (LLMs) within the scientific community has resulted in  a  A conversation on artificial intelligence, chatbots, and plagiarism in higher education. Cell",False,17,https://link.springer.com/article/10.1007/s10439-023-03212-2,['bkYOk4EAAAAJ'],/scholar?q=info:OodeayMxAqUJ:scholar.google.com/&output=cite&scirp=16&hl=en,"/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522large%2Blanguage%2Bmodels%2522%2B%252B%2522higher%2Beducation%2522%26hl%3Den%26start%3D10%26as_sdt%3D0,33%26as_ylo%3D2000%26as_yhi%3D2023&citilm=1&update_op=library_add&info=OodeayMxAqUJ&ei=zReNZKCnB4jimgH2vJ6gDQ&json=",1,"/scholar?cites=11890119994406504250&as_sdt=5,33&sciodt=0,33&hl=en",https://link.springer.com/content/pdf/10.1007/s10439-023-03212-2.pdf,"""large language models"" +""higher education""",OodeayMxAqUJ_2023_Large Language Models Like ChatGPT in ABME: Author Guidelines,b369b1d07d224debb41bd09e333e60c3,"The use of Large Language Models (LLMs) within the scientific community has resulted in a storm of ethical discussions in recent months. LLMs are an emerging form of artificial intelligence which have been trained to output plausible sequences of words based on the likelihood that the sequence may occur within the natural human language. These unique sentences are strung together based on the text data that the model was trained on [1] . For example, Chat-GPT is an LLM that was trained on a very large dataset from the Internet and has recently demonstrated its effectiveness at constructing sequences of sentences with valid deductive reasoning. Further illustrating its power within the scientific community, ChatGPT recently authored peer-reviewed papers in Oncoscience [2] and Nurse Education and Practice [5] journals and demonstrated expert-level knowledge by receiving a passing score on the United States Medical Licensing Exam [1] . This powerful tool is capable of providing quick, custom responses to help answer niche questions, however, there exist major concerns related to its use for scientific reporting. In particular, LLMs cannot be held accountable for the accuracy and validity of the science discussed within the written text. This is particularly important because LLMs, including ChatGPT, can provide largely inaccurate or biased responses based on the input data it was trained on [1, 3, 4] . Therefore, many scientific publishers now prohibit LLMs from authoring manuscripts, which includes Springer Nature. Details can be found within the editorial policies on authorship criteria. As a Springer Nature journal, the Annals of Biomedical Engineering (ABME) will adhere to these guidelines and reject manuscripts that do not satisfy the authorship criteria. Transparent reporting of the use of LLMs in scientific works remains a major ethical discussion. The use of LLMs like ChatGPT threaten scientific rigor and integrity when the authors adopt the original language that was output from these generated models as their own [3] . Therefore, ABME now requires full transparency within the methods or acknowledgements section if the authors have used LLMs in any way to while developing their manuscripts. By stating the use of the LLM, the author is accepting responsibility for the accuracy of what was reported and spreads awareness to the reviewers so that they may identify any potential biases, inaccuracies, or misreporting. Kung et al. provided a good example of transparent reporting of the use of Chat-GPT within the methods section as it directly related to data collection and analysis [4] . Statements should be provided in the acknowledgements section in instances where the LLM enhanced or motivated any ideas or discussions throughout the document, especially if any of the generated text was used. Examples of how to report the use of LLMs in the acknowledgements section are included below. The author acknowledges that this article was partially generated by ChatGPT (powered by OpenAI's language model, GPT-3; http:// openai. com). The editing was performed by the author [3] . The author acknowledges that some content in this article was partially generated by ChatGPT (powered by OpenAI's language model, GPT-3.5; http:// openai. com) to discover the roles that chatGPT can play in public health. The editing was performed completely by the human author [4] . As the use of LLMs like ChatGPT continue to expand and models continue to improve, it is imperative for scientists to strive for the highest degree of scientific rigor and integrity through deep critical thinking and transparent reporting. Only then can we be confident in the data that will power future models and scientific discoveries, which will hopefully converge upon groundbreaking solutions.",
Publication,PUBLICATION_SEARCH_SNIPPET,Authorship policy of the Korean Journal of Radiology regarding artificial intelligence large language models such as ChatGTP,['SH Park'],2023,work,Large language models (LLMs) enabled by artificial intelligence (AI) technology can  generate sentences that are increasingly difficult to distinguish from text written by people. In,False,25,https://www.kjronline.org/src/PDFs/kjr-v24n3.pdf,['N1QQ-lMAAAAJ'],/scholar?q=info:yRGsXnrC70YJ:scholar.google.com/&output=cite&scirp=24&hl=en,"/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522large%2Blanguage%2Bmodels%2522%2B%252B%2522higher%2Beducation%2522%26hl%3Den%26start%3D20%26as_sdt%3D0,33%26as_ylo%3D2000%26as_yhi%3D2023&citilm=1&update_op=library_add&info=yRGsXnrC70YJ&ei=zxeNZOtT5NSxAtLEl6AD&json=",6,"/scholar?cites=5111517932918936009&as_sdt=5,33&sciodt=0,33&hl=en",https://www.kjronline.org/src/PDFs/kjr-v24n3.pdf,"""large language models"" +""higher education""",yRGsXnrC70YJ_2023_Authorship policy of the Korean Journal of Radiology regarding artificial intelligence large language models such as ChatGTP,59f27f4cbce84c198a4f04533ea4a435,"https://doi.org/10.3348/kjr.2023.0112 kjronline.org The coronavirus disease 2019 (COVID-19) outbreak affected health systems worldwide, with implications for radiology practice, research, and education; learning from the first Severe Acute Respiratory Syndrome (SARS) crisis in 2003, many radiology departments responded quickly to protect patients and staff [1] . The prioritization of infection control measures has resulted in a reduced workload in radiology departments due to cancellations of outpatient imaging studies and elective interventional procedures [2] . Although we experienced different conditions during the height of the pandemic lockdown, there was a common disruption to the conventional workplace-based education and planned instructional activities essential for professional development. Radiologists responded to these challenges by being adaptable and inventive, restructuring our teaching technology to pivot abruptly to socially distanced remote working [3] . More significantly, the pandemic resulted in a required shift in culture in all facets of education, which not only helped hasten the adoption and implementation of technology-enhanced learning methods but also called into question well-recognized and practiced pre-pandemic pedagogies and methodologies in medical education that were made inappropriate or irrelevant despite their longevity and perceived importance [4] . In this editorial, we describe three initiatives using online virtual platforms to continue radiology education during the pandemic and reflect on lessons learned for the future. We first describe how a popular final-year medical student radiology workshop pivoted online during the pandemic: ""Survival Radiology"" was previously a full-day interactive https://doi.org/10.3348/kjr.2023.0029 kjronline.org case-based in-person workshop introducing important and urgent radiological core knowledge expected for interns [5] . We found that the online platform allowed personalized remote viewing of radiological images and enhanced realtime interactions using online ""word cloud"" and ""image hot spot"" audience response systems ( Fig. 1 ) and ""live"" chat responses from supporting faculty (who were not the main speaker) [5] . Such contemporaneous feedback and deliberate blending of the most beneficial aspects of existing face-toface interactions with the strengths of online platforms can improve content delivery and ultimately enhance a learner's educational experience [6, 7] . Next, we addressed the decreased attendance of real patients with brain tumors during resident neuroradiology rotation. We overcame the lack of reporting opportunities using a database of past histology-proven cases within the clinical Picture Archiving and Communications System (PACS), which had been previously collected for a separate machine learning validation project. With this brain tumor PACS worklist, residents can individually review the images at their own pace and check their diagnosis against an answer key (Fig. 2 ). This project leveraged existing informatics tools as a learning platform in a self-directed, asynchronous manner [8, 9] . Finally, we developed an online e-learning module aimed at teaching magnetic resonance (MR) safety concepts set in a virtual 3D radiology department, including simulated patient screening scenarios and decision-making in managing an emergency MR-related accident. Such serious games provide realistic, immersive, engaging, and relatable play, incorporating formative assessment minigames with instantaneous feedback in a non-threatening safe environment that cannot be otherwise created [10] . The three examples above illustrate how resourceful radiology educators can quickly adapt and use virtual online platforms during the height of the pandemic [6, 11] . More importantly, as we transition to a post-pandemic world, we should take the opportunity to familiarize ourselves with basic pedagogical concepts and medical educator skillsets. We need to reflect on the advantages and drawbacks of virtual teaching by combining old and new teaching methods based on sound principles. Designing and implementing effective online learning curricula involves clarity in course expectations and outcomes, developing an e-community, selecting and optimizing online tools to encourage interaction, creating an environment in which the exchange of ideas can flourish, and providing timely and targeted feedback, all within a student-centered environment [12] . A basic understanding of fundamental pedagogical concepts such as Bloom's Taxonomy, active learning, and student feedback would go a long way in creating purposeful experiences for teachers and learners [13] . The main advantage of teaching using remote platforms is increased accessibility, even in unprecedented geographically diverse regions [11] ; however, videoconferencing fatigue is an important limitation [14, 15] . Hence, it is timely to consider the curriculum and pedagogical design to continue the next step in the development of online (and offline) teaching methods and resources, since what developed organically and out of sheer necessity in the early days of pandemic education may be haphazard and unfit for purpose in the long run. It is time Fig. 1 . Screengrab of ""word cloud"" audience response systems used in Survival Radiology online virtual workshop for medical students. We found that audience response systems and ""live"" chat functions enhanced learners' educational experiences. https://doi.org/10.3348/kjr.2023.0029 kjronline.org to review and plan according to pedagogical principles so that the overarching curriculum is appropriate and not impractical or incoherent. Three baseline requirements are necessary to enable this late/post-pandemic change management. First, radiology departments should emphasize and invest in faculty education and development [16] . Second, radiologists should seek opportunities for consultation, collaboration, and research with pedagogical experts in university medical education departments [17] . Finally, and most crucially, clear learning outcomes within the curriculum are needed, tailored to their different backgrounds and needs, including residency trainees, medical students, and radiographers: they all have different needs. There are many limitations to this editorial, and it barely scratches the surface of post-pandemic initiatives. We did not cover major topics that deserve separate discussions, including procedural and interventional radiology, assessments/examinations, interprofessional education, and simulations. However, we hope that this will be a conversation starter regarding whether online virtual/ remote platforms can replicate the intangible atmosphere and nuances of in-person interactions, how to develop and incorporate blended learning for teaching, and role modeling such domains as non-interpretive skills, mentoring, and leadership skills [18, 19] . Video recordings and remotely supervised, technology-enhanced learning methods such as augmented/virtual reality in immersive learning environments may be novel but may also be hampered by being extremely resource-intensive [20] . Several other important literature-supported emerging trends, such as flipped classrooms, interprofessional education, and gamification, can also be explored. Online radiology educational best practices should be underpinned by sound pedagogical theory and a coherent curriculum; thus, in addition to our content and technical knowledge, radiology teachers should master the appropriate pedagogical knowledge to prepare to educate and inspire our learners in this and future pandemics. The authors have no potential conflicts of interest to disclose. Conceptualization: all authors. Data curation: Choie Cheio Tchoyoson Lim. Supervision: Choie Cheio Tchoyoson Lim. An example of answer key of Picture Archiving and Communications System worklist of patients with brain tumor for self-directed asynchronous resident review during neuroradiology rotation. We overcame the lack of reporting opportunities during the pandemic by leveraging existing informatics tools. https://doi.org/10.3348/kjr.2022.1023 kjronline.org processing and PACS, it seems logical and pragmatic to incorporate a module on AI fundamentals and applications as part of the new paradigm. Therefore, we propose the inclusion of topics such as: 1. Fundamental concepts of AI and machine learning: Here, learners will gain a broad understanding of machine learning in its various forms, including deep learning and machine learning, otherwise commonly termed as AI. The distinction between artificial generalized intelligence and narrow AI and the potential capabilities of AI should be covered. As a result, future radiologists/ learners should be further educated about the strengths and weaknesses of current AI technologies to understand the subsequent modules that specifically cover AI in radiology. 2. Overview of AI in medicine and radiology: Here, the learners will apply their understanding of the fundamental concepts of AI and machine learning to the practice of medicine, such as image-based computer vision in radiology, pathology, and other clinical specialties (fundal photography and endoscopy), and text-based natural language processing for data mining and predictive analytics. An up-to-date review of regulations and ethical issues surrounding AI should be incorporated into the curriculum for learners to appreciate the complexity of real-world AI adoption. We suggest that an interactive discussion or case study format should be implemented to enhance the effectiveness of teaching and learning. 3. Clinical validation and application of AI models: Herein, learners will appreciate the role of AI in augmenting radiology clinical and operational workflows throughout the service continuum. Ethical considerations and risk mitigation techniques pertaining to the application of AI and real-world deployment of algorithms in radiology should be covered. Learners should further understand bias and be able to recognize and address these biases in their decision-making by applying guidelines that advocate for standardized approaches to randomized controlled trial evaluation of AI models [6] . As a practical example, the Korean Society of Thoracic Radiology issued a position statement on the use of AI-based software as a medical device for chest radiography [7] . 4. Development of machine learning models for solving clinical problems: For more advanced learners, a deeper competency in AI, such as coding and the use of programming languages (e.g., R and Python), can be imparted. This opens up a new field of research and development for radiology, led by future radiologists, in solving issues of diagnostic accuracy, disease prediction, and workflow inefficiencies. For example, the American College of Radiology has set up AI-LAB TM , which offers radiologists ""tools designed to help them learn the basics of AI and participate directly in the creation, validation, and use of health care AI"" [8] . Since AI is constantly evolving and new developments are being made every day, we propose that these mandatory didactic modules be supplemented by other opportunities for staying up-to-date, such as attending and presenting at journal clubs, webinars, workshops, and conferences. For example, the Radiological Society of North America offers a case-based AI course that provides radiologists with practical know-how on the application of AI in radiology [9] . Recently, the Asian Oceanian Society of Radiology Emerging Trends Committee organized a series of webinars to increase awareness among members of the ethical and real-world considerations in the adoption of AI [10] . Radiology educators and leaders should address the lack of coverage of AI know-how in our conventional curriculum. Now is the opportune time to implement AI in residency programs. A wait-and-see attitude will only jeopardize the progress of radiology in providing state-of-the-art healthcare services. The clarion call has been sounded. Magnetic resonance imaging (MRI) has emerged as the imaging modality of choice for evaluating patients with focal or diffuse liver disease. Its unique advantages compared with computed tomography include the lack of ionizing radiation exposure and an inherently high soft tissue signal. Therefore, Strategies and Techniques for Liver Magnetic Resonance Imaging: New and Pending Applications for Routine Clinical Practice https://doi.org/10.3348/kjr.2022.0838 kjronline.org by additional inflammation with or without fibrosis [7] . Liver biopsy is the reference standard for diagnosing fat accumulation and differentiating NAFLD from NASH. However, biopsy is invasive and prone to sampling bias, particularly in cases of heterogeneous disease distribution. There is a great need for non-invasive biomarkers for the detection and quantification of fat accumulation, especially in the early stages. Current MRI techniques exploit the differences in the resonance frequencies of water and fat protons. Until recently, magnetic resonance spectroscopy (MRS) has been considered a non-invasive reference standard for the quantification of hepatic fat accumulation. In MRS, the proton signals of water and fat are acquired in a single breath hold and then depicted as a high-resolution spectrum. Currently, point-resolved spectroscopy (PRESS) and stimulated-echo acquisition mode (STEAM) are the most common techniques in practice. Although PRESS is characterized by a higher signal-to-noise ratio (SNR), STEAM is often preferred because it is less affected by J-coupling [8] . Despite rapid MRS techniques (such as, high-speed T2-corrected multiecho single voxel spectroscopy), MRS is limited to a voxel basis and, therefore, prone to sampling bias. Multivoxel MRS increases the imaging time proportionally, but can be used to cover larger volumes. More recently, proton density frat fraction (PDFF) has been introduced and has already superseded MRS. PDFF refers to the fraction of mobile protons in the liver that are attributable to fat. It is an uncorrected confounded measure of steatosis that is influenced by biological, physical, and technical factors. Therefore, imaging techniques need to address all confounding factors (T1 bias, T2 relaxation, T2* decay, the spectral complexity of fat, J-coupling, noise bias, and eddy currents). PDFF is an unconfounded measure for the quantification of fat accumulation, independent of magnetic field strength, scanner platform, and technical parameters [9] . To calculate PDFF, multi-echo gradient echo (GRE) sequences with chemical shift-encoding (CSE) are used, enabling coverage of the whole liver in a single breath-hold. PDFF measurements correlate closely with histology [10] and are expressed in percentage (0%-100%) ( Fig. 1) . Different strategies for post-processing and calculation exist, with the exact strategy for CSE depending on the vendor. Magnitudebased techniques are simpler to implement but suffer from a low SNR and coverage of a limited PDFF range (0%-50%). Complex-based CSE techniques enable measurement of the full PDFF range (0%-100%). However, they are more sensitive to phase errors and may suffer from occasional water-fat swaps. Lastly, hybrid-based methods combine the advantages of both approaches [9] . Confounder-corrected CSE-MRI further enables the simultaneous assessment of iron deposition. The presence of iron results in tissue signal loss in T2 and T2*-weighted images, which is proportional to the iron content. Based on R2* measurements, fat-corrected R2*maps are a by-product of multi-echo CSE acquisitions used to create R2*-corrected PDFF maps [11] . There is growing evidence for the use of PDFF, which is an increasingly accepted technique, especially for the evaluation of NAFLD. In a meta-analysis comparing PDFF measurements with transient elastography, MRI offered pooled sensitivities and specificities of 0.71-0.91 and 0.88-0.93, respectively, for the staging of hepatic steatosis [12] . Studies have shown that PDFF can be used to monitor and predict therapeutic effects in patients with NAFLD [4, 13] . Other potential applications for PDFF measurements include surveillance of patients undergoing bariatric surgery [14] and preoperative evaluation of living liver donor candidates [15] . Concomitant fat and/or iron deposition is often present in patients with chronic liver disease (CLD), and quantification is clinically useful for diagnosis and follow-up. PDFF measurements with simultaneous evaluation of iron content provide a great opportunity for the implementation of abbreviated MRI protocols specifically tailored to these clinical indications. Automated assessment of PDFF and T2* maps based on deep learning algorithms may facilitate analysis; until then, a consensus on a standardized approach for placement of regions of interest would be desirable. Free-breathing techniques, including navigator-based image acquisition or non-cartesian sampling strategies, are the current areas of research. Hepatic fibrosis results from progressive liver injury in all causes of CLDs. It is defined as an excessive accumulation of extracellular matrix proteins and is commonly staged from F0-F4 in the radiology literature [16] . CLD is a major health problem, with significant morbidity and mortality worldwide. https://doi.org/10.3348/kjr.2022.0838 In the USA, CLD and cirrhosis are the 10th leading causes of death [17] . Liver biopsy is the reference standard for diagnosis and staging of hepatic fibrosis. Early detection and treatment of the cause are critical because early stage fibrosis is potentially reversible, and liver transplantation is the only curative treatment for decompensated cirrhosis [16] . Magnetic resonance elastography (MRE) is currently the leading MRI technique for staging hepatic fibrosis, with stiffness measurements directly related to fibrosis stage [18] . A passive driver that generates mechanical waves is positioned over the patient's liver. Mechanical vibrations are produced by an active driver outside the MRI room and transported through a flexible tube to the passive driver. A phase-contrast pulse sequence with motion-encoding gradients is used to evaluate wave propagation. Postprocessing enables the visualization of wave images and quantitative maps of liver stiffness, known as elastograms [16] . Higher liver stiffness causes faster wave propagation and is directly associated with a higher fibrosis stage (Fig. 2) . Although MRE is the most established MRI technique for the assessment of hepatic fibrosis, the need for additional hardware is a drawback for the expansion of clinical implementation. Reliability has been reported to be lower in patients with iron overload, massive ascites, or high body mass index [16, 19] . The recently implemented MRE using spin-echo echo-planar imaging (SE-EPI) may overcome some of these limitations. Acquisition of MRE is traditionally performed with GRE sequences, which tend to have a relatively long echo time (TE) and are therefore sensitive to iron overload. Compared with GRE sequences, SE or SE-EPI sequences have shorter TEs and are inherently insensitive to T2* effects due to a 180° refocusing pulse, as shown in a study by Zhan et al. [20] for MRE at 3T. Studies have shown that 2D or 3D MRE using SE-EPI has lower technical failure rates and a larger confidence area while maintaining a comparable or higher diagnostic performance than conventional 2D GRE-MRE [20] [21] [22] . Notably, the cut-off values for staging hepatic fibrosis are not significantly different between these two sequences [20, 23] . Recently, 3D MRE has been introduced for the evaluation of hepatic fibrosis. In 2D MRE, elastograms are reconstructed based on waves propagating in the slice plane, whereas waves propagating oblique to the splice plane are discarded. In a 3D MRE, wave motions are encoded in three planes (x, y, and z), providing more accurate information on the properties of materials in theory. Specifically, in a 3D MRE, the storage and loss moduli can be calculated independently, as compared to the magnitude of the complex shear modulus (that is, liver stiffness value) of a 2D MRE. For 3D MRE, more data are required; SE-EPI sequences are usually used to acquire multiple slices in a limited timeframe. Recent studies have shown that the liver damping ratio in 3D MRE is further associated with inflammation in patients without or early stage fibrosis [24] . Notably, the cut-off values for the staging of fibrosis between 3D and conventional 2D MRE may be different [25, 26] . A more advanced technical approach is the multifrequency MRE. Currently, the staging of hepatic fibrosis is usually performed at a single frequency (60 Hz). Even though single-frequency MRE has been applied successfully for the staging of hepatic fibrosis, its accuracy, especially for the detection of early stage fibrosis, is relatively low A B C Fig. 1 . A 51-year-old male patient referred for magnetic resonance imaging (MRI) with clinical suspicion of iron storage disorder. On the in-phase image (A), a slightly increased signal intensity of the liver can be observed compared to that of the spleen. Opposed-phase imaging (B) reveals a distinct signal drop in the liver parenchyma. Quantification using chemical-shift encoded MRI (C) demonstrates a proton density fat fraction of approximately 17%, consistent with mild steatosis, but with no significant iron deposition (R2* below 70 s -1 ). ROI = region of interest, std = standard deviation https://doi.org/10.3348/kjr.2022.0838 kjronline.org kjronline.org [27] . This can be improved by adopting the concept of viscoelasticity. For multi-frequency MRE, tissue oscillations are acquired either separately or simultaneously at multiple frequencies (25-62.5 Hz) [28, 29] . The storage and loss moduli are then calculated using different rheological models, for example, Voit, Maxwell, or spring-pot models [29] . Recent studies have shown that multi-frequency MRE may improve the performance of MRE in the diagnosis of hepatic fibrosis and in differentiating fibrosis from inflammation [28, 30] . With the use of MRE, high areas under the receiver operating characteristic or area under receiver operating characteristics have been determined for the classification of fibrosis as ≥ 1, ≥ 2, ≥ 3, or 4 [18, [31] [32] [33] . Compared with ultrasound elastography, MRE has a higher diagnostic performance for staging liver fibrosis, especially in patients with ascites [19, 34] . However, it is important to note that the threshold for liver stiffness on MRE needs to be further validated depending on the etiology of CLD and scan parameters, including applied sequences, dimensions, and frequencies [16] . MRI evaluation of hepatic fibrosis using hepatobiliary contrast agents is also feasible. Hepatocellular contrast uptake in the hepatobiliary phase is quantified as a surrogate biomarker for the estimation of liver fibrosis. Different techniques have been developed for quantifying hepatocellular contrast uptake. Signal intensity-based indices such as relative liver enhancement and liver-to-spleen index are easy to implement because there is no need for specific sequences or post-processing [35] . Studies have shown a good correlation of signal intensity (SI)-based indices with liver function tests and established clinical scores [3, 36] . However, it must be noted that SI measurements are only relative values and are dependent on technical parameters. In addition, the nonlinear relationship between gadolinium (Gd) concentration and SI is a potential caveat. T1 mapping, also known as relaxometry, overcomes some of the limitations of direct SI measurements. Contrastinduced T1 relaxation time changes are directly correlated with Gd concentration and are therefore more reliable than SI measurements [37] . For hepatic fibrosis evaluation, the variable flip-angle method with B1 inhomogeneity correction, modified look-locker, and look-locker inversion recovery sequences have been proposed [38] [39] [40] . In addition to T1 relaxation time, the contrast uptake ratio or contrast uptake rate can be calculated using a dedicated software [41, 42] (Fig. 3) . Encouragingly, T1 relaxation time and calculated contrast uptake ratio have been shown to correlate with liver function and clinical outcome [40, 43] . kjronline.org Although T1 relaxometry has theoretical advantages over direct SI measurements, the requirement for dedicated sequences and software limits its application in research settings. Moreover, confounding factors, such as iron, fat, and off-resonance effects, may affect T1 values. For example, if fat is not suppressed correctly when performing T1 mapping using the modified look-locker technique, T1 values may be overestimated owing to the fat. Recent studies have demonstrated the feasibility of obtaining confounding factor-corrected T1 values [44] [45] [46] . MRE is likely to be more widely implemented in the near future, along with verification of etiology-based cut-off values. The possibility of differentiating between fibrosis and inflammation, as well as an increase in the diagnostic accuracy for early stage fibrosis are promising expectations. T1 mapping may improve in precision by corrections in confounding factors and liver MR fingerprinting may enable water-specific T1 acquisition [47, 48] . The integration of automatic liver segmentation and automated reporting of liver stiffness or T1 values will ease the radiology workflow [49] . The same is true for the implementation of deep-or machine-learning algorithms for the evaluation of fibrosis and liver function derived from routine MRI sequences [50, 51] . These techniques are expected to play an important role in the context of abbreviated MRI in combination with PDFF measurements for the evaluation of diffuse liver diseases, including NAFLD and NASH [26, 52] . Finally, improving the cost-effectiveness of these applications by adopting lowfield point-of-care MRI [53] will help to further popularize the implementation of MRI for the evaluation of diffuse liver disease. In healthy livers, most incidentally detected FLLs in patients without known malignancies are benign. Most malignant FLLs are metastases, especially from the gastrointestinal tract, pancreas, breast, and lungs. In the cirrhotic liver, however, approximately 75% of FLLs are consistent with hepatocellular carcinoma (HCC) [54] . Therefore, differential diagnosis is dependent on patient history, age, and clinical examination. Imaging is a mainstay not only for diagnosis but also for the determination of the number and localization of lesions. In this context, MRI has evolved into the imaging modality of choice for evaluating patients with suspected or known FLLs. A conventional full MRI exam, however, is time consuming, which is in contrast to the rising clinical demand and overall limited scanner availability. Recently, abbreviated MRI protocols have been introduced. This approach is characterized by the acquisition of only a limited number of selected sequences tailored to a specific disease. With acquisition times of approximately 10 min or less, abbreviated MRI aims to reduce exam complexity while maintaining a high diagnostic sensitivity. Therefore, it is of utmost importance that each sequence has a consistent and acceptable image quality. Rapid imaging techniques may facilitate adherence to this timeframe. For example, compressed sensing-based rapid imaging has been successfully adopted for T1-weighted imaging in full MRI protocols [55] . Deep-learning-based T2-or diffusionweighted imaging may shorten acquisition times while simultaneously improving image quality and lesion detection [56] [57] [58] . The implementation of these techniques may further reduce the acquisition times without compromising the image quality, which is critical for abbreviated MRI. Three general abbreviated MRI approaches have been developed for FLLs, as follows, and are currently being discussed in the literature: non-contrast abbreviated MRI, dynamic abbreviated MRI, and hepatobiliary abbreviated MRI ( Fig. 4) . Each protocol has specific advantages and disadvantages [59, 60] . The clinical potential of abbreviated MRI protocols is promising, for example, for the evaluation and follow-up of diffuse liver disease [61] and the detection and follow-up of metastatic liver disease [62, 63] . However, most evidence is available in the context of HCC screening and surveillance. A meta-analysis showed that abbreviated MRI had higher sensitivity than ultrasound (82% vs. 53%) for HCC screening [64] . Similarly, for HCC surveillance, abbreviated MRI had high sensitivity, especially for very early tumor detection, with pooled sensitivities and specificities of 85% and 94%, respectively, for any tumor stage [65] . Abbreviated MRI protocols are likely to become firmly established in clinical routine in the near future. Implementation of deep-learning algorithms may improve the diagnostic confidence and accuracy for the detection https://doi.org/10.3348/kjr.2022.0838 kjronline.org of FLLs [66] . However, despite apparent advantages, some open issues for the use of abbreviated MRI still need to be addressed: the optimal target population, which patients benefit the most, how findings should be reported and followed-up, and the appropriate cost of abbreviated MRI. In addition, there is a lack of large prospective studies directly comparing abbreviated MRI with full MRI or other imaging modalities; until then, the best abbreviated MRI protocol for each setting needs to be defined. MRI has advanced from a mere diagnostic tool for the assessment of morphological disorders to a non-invasive quantitative biomarker for predicting prognosis and therapeutic success. Multiparametric imaging enables the comprehensive assessment of diffuse liver disease. PDFF is an emerging technique for the quantification of hepatic steatosis. Similarly, MRE) and the use of hepatocytespecific contrast agents are promising applications for the quantification of hepatic fibrosis. Abbreviated MRI protocols tailored to a specific disease (such as focal lesions and diffuse Fig. 4 . Abbreviated magnetic resonance imaging (AMRI) in three different patients with hepatocellular carcinoma. Non-contrast (NC)-AMRI (A), hepatobiliary (HBP)-AMRI (B) and dynamic (DYN)-AMRI (C) in three different patients with hepatocellular carcinoma (arrows in A-C). In the hepatobiliary phase an additional lesion can be appreciated (dashed arrow in B). *There is no consensus on whether diffusion-weighted imaging (DWI) should be a part of this protocol or not. in/opp = in and opposed phase imaging, pre = pre-contrast 4 , Ho Joong Choi 5 , Pil Soo Sung 6 , Joon-Il Choi 3 https://doi.org/10.3348/kjr.2022.0560 kjronline.org primary liver malignancies that lack the typical radiologic features of HCC are collectively called ""if probably or definitely malignant but not HCC specific"" or ""LI-RADS M (LR-M)"" [2] . Since targetoid appearance is frequent in non-HCC malignancies, the presence of any one targetoid feature is sufficient for LR-M categorization [5] . Targetoid primary liver malignancies require biopsy or further imaging for a conclusive diagnosis [4, 6] . Thus, existing studies have focused on radiologic differential diagnosis [7] [8] [9] . Definitive surgery is the cure for feasible diseases with preserved liver function [4, 6] . Accordingly, preoperative estimation of postoperative outcomes in targetoid primary liver malignancies is likely to influence therapeutic decision-making, potentially modifying the extent of the surgical field or, in patients with HCC, switching to liver transplantation. Studies have shown a poor prognosis for targetoid lesions regardless of the pathologic diagnosis [10] [11] [12] [13] [14] , but further prognostic stratification within heterogeneous subsets of targetoid primary liver malignancies has rarely been reported. Risk stratification may be possible if other poor prognostic MRI features are added, such as a non-smooth tumor margin [15] , corona enhancement [16, 17] , peritumoral hypointensity on the hepatobiliary phase (HBP) [11, 18] , and HBP hypointense nodules without arterial phase hyperenhancement (APHE) [19, 20] . In this study, we aimed to assess the radiologic and clinical factors associated with recurrence and survival after curative surgery for targetoid primary liver malignancies, as well as establish and validate scoring systems for risk stratification. This study was approved by the Institutional Review Boards of the three participating centers. The requirement for informed consent was waived owing to the retrospective study design (IRB No. KC21RIDI0483, GDIRB2021-455, and AJIRB-MED-MDB-22-221). Consecutive adult patients with chronic liver disease who underwent curative surgery for suspicious liver lesions between January 2010 and December 2017 were recruited from three centers. The inclusion criteria were: 1) a single primary liver malignancy confirmed by surgical pathology, and 2) a preoperative gadoxetic acid-enhanced MRI examination within three months of surgery. The exclusion criteria were: 1) prior treatment, including resection, locoregional treatment, or systemic chemotherapy, 2) benign pathology, 3) synchronous or metachronous nonhepatic malignancy, 4) invisible lesions on MRI, and 5) suboptimal MR image quality. Data from centers 1 and 2 (Seoul St. Mary's Hospital and Gil Medical Center) were used to develop the scoring system, and data from center 3 (Ajou University Hospital) was used for the external validation. Clinical and laboratory data, including age at liver surgery, sex, etiology of liver disease, preoperative Child-Pugh score, serum alpha-fetoprotein (AFP) levels, protein induced by vitamin K absence or antagonist II (PIVKA-II), and type of liver surgery, were collected. Pathological data included the histopathologic diagnosis of the lesion, the Edmondson-Steiner grade, a meta-analysis of histological data in viral hepatitis (METAVIR) score, microvascular invasion (MVI), a satellite nodule, and the resection margin status. The diagnosis of cHCC-CCA was made according to the 2010 World Health Organization classification [21] . Liver MRI was performed using 1.5T (Magnetom Avanto, Siemens Healthineers; SignaHDxt, GE Healthcare) and 3T scanners (Verio and Skyra, Siemens Healthineers; Discovery 750w, GE Healthcare). The MRI protocol commonly encompasses axial T2-weighted images, diffusion-weighted images (DWI; b = 0, 500, and 800 s/mm 2 ), and dual gradient-echo images. Late hepatic arterial, portal venous, transitional phase (TP), and HBP images were acquired for a dynamic enhancement study. Detailed MRI parameters and dynamic enhancement study protocols are listed in Supplementary Table 1 . Two abdominal radiologists (with more than nine years of experience in liver MRI) prescreened the MRI examinations to select targetoid liver lesions. After obtaining a consensus on discrepancies, the final targetoid lesions were included in further image analysis ( Fig. 1 ). Three abdominal radiologists with different levels of experience in liver MRI (two with more than nine years and one with more than three years) independently reviewed the anonymized MR images of the development cohort. The reviewers were blinded to the clinicopathologic information of the patients but were aware that the images were of primary https://doi.org/10.3348/kjr.2022.0560 kjronline.org liver malignancies in patients with chronic liver disease. Targetoid lesions were defined as the presence of at least one of the following features: rim APHE, peripheral washout, delayed central enhancement, or targetoid appearance on DWI, TP, or HBP [2, 22] . Rim APHE was categorized as 1) a smooth, thin rim with a thickness within 25% of the inplane diameter of the tumor throughout the perimeter, and 2) an irregular, thick rim with a thickness partly or entirely exceeding 25% of the tumor diameter (Figs. 2, 3) [7, 23] . Furthermore, corona enhancement, capsule, intralesional fat, peritumoral bile duct dilatation, non-smooth tumor margin, radiologic vascular invasion by a tumor in the vein (TIV), vascular involvement other than TIV (encasement, narrowing, tethering, occlusion, or obliteration) [24] , peritumoral hypointensity on HBP, and HBP hypointense nodules without rim or nonrim APHE [25] were assessed. In the presence of both TIV and vascular involvement other than TIV, given the established prognostic impact of TIV, TIV was prioritized but not vice versa [26] . Therefore, these two features were mutually exclusive. Only HBP hypointense nodules without APHE with a size of ≥ 3 mm that had not been surgically removed were considered. Detailed definitions of the imaging features are provided in Supplementary Table 2 . The MR images of the validation cohort were similarly evaluated by two more experienced readers. A joint review resolved any disagreement in the interpretation. Patient follow-up was performed according to institutional protocols after surgery until April 15, 2021. The followup protocols included multiphasic liver CT covering the pelvis or gadoxetic acid-enhanced MRI, serum tumor marker tests, and clinical evaluations every three to six months. For clinical or radiologic suspicion of recurrence, further assessments, including a chest CT, a bone scan, or F-fluorodeoxyglucose PET-CT, were conducted. Recurrencefree survival (RFS) was defined as the time from surgery to intra-or extrahepatic recurrence or death [27] [28] [29] , while overall survival (OS) was defined as the time from surgery to death. Patients with no recurrence or death were excluded at the last follow-up before April 15, 2021. Continuous variables are expressed as means with standard deviations or medians with interquartile ranges after testing for normality. Wilcoxon rank-sum test, χ 2 test, or Fisher's exact test was used to compare variables between the development and validation cohorts. The binary cutoff values for AFP and PIVKA-II were calculated using the maximum Youden index value to differentiate between patients who had and did not have a recurrence. Cox proportional hazard analyses with backward elimination identified independent predictors of RFS and OS, with variables with p < 0.1 in the univariable analysis transferred for multivariable analysis. Based on multivariable analysis, the risk score was calculated by dividing each correlation coefficient (β) by the smallest β and rounding it to the nearest integer [30] . The sum of the risk scores represented the risk of recurrence or death for each patient. The discriminatory power of the risk score was assessed using Harrell's C-index and the area under the time-dependent receiver operating characteristic area under the curve (AUC) at one, two, and five years. Optimism-corrected C-indices were reported as the primary results [31] . The risk score stratified the risk groups based on the probability of recurrence or death. The Kaplan-Meier method was used to estimate RFS and OS, and differences between groups were compared using the log-rank test. Considering the clinical environment where gadoxetic acidenhanced MRI is unavailable or HBP imaging is suboptimal, we established two RFS models: model 1, excluding radiologic features accessible only on HBP, and model 2, including all significant factors in univariable analysis. Kappa (κ) statistics were used to evaluate the interreader agreement as follows: fair (0.20-0.39), moderate (0.40-0.59), good (0.60-0.79), and excellent (0.80-1.00). All statistical analyses were performed using R software, version 3.6.1 (R Foundation for Statistical Computing), and  Of the 1104 patients with chronic liver disease who had curative surgery for suspicious liver lesions and preoperative gadoxetic acid-enhanced MRI examinations at three centers, 749 patients with single-treatment-naïve primary liver malignancy were selected based on the inclusion and exclusion criteria. After screening for targetoid liver lesions, 197 patients (120 in the development cohort and 77 in the validation cohort) were included in the study (Fig.  1 ). Clinicopathological characteristics of the patients are summarized in Table 1 . Most patients (80.2%; 95 in the development cohort and 63 in the validation cohort) had chronic hepatitis B viral infection or cirrhosis. Additionally, 102 (51.8%) and 95 (48.2%) patients were imaged using 3T and 1.5T MR units, respectively. Of the excluded benign lesions, parasite infestations (n = 1) had a targetoid appearance. Table 2 summarizes the MRI findings of the targetoid kjronline.org In the subgroup analysis by pathological diagnosis, RFS was comparable across all pathological diagnoses, but OS was significantly lower in CCA than in HCC (p = 0.022) ( Supplementary Fig. 1 ). For RFS models, the risk scores ranged from 0 to 3. The risk score showed good discriminatory performance, with a C-index of 0.67 (95% CI: 0.60, 0.75), and 0.62 (95% CI: 0.54, 0.70) for RFS models 1 and 2, respectively, in the validation cohort. The AUCs at one-, two-, and five years for RFS model 1 were 0.69 (95% CI: 0.54, 0.84), 0.72 (95% CI: 0.57, 0.87), and 0.69 (95% CI: 0.54, 0.85), respectively, and those for RFS model 2 were 0.68 (95% CI: 0.57, 0.80), 0.67 (95% CI: 0.56, 0.77), and 0.58 (95% CI: 0.46, 0.70), respectively, in the validation cohort (Supplementary Table 5 ). The models showed comparable performances (all p > 0.05). The risk score for OS ranged from 0 to 3 and similarly showed good discriminatory performance with a C-index of 0.76 (95% CI: 0.65, 0.86), and the AUCs at one-, two-, and five-year were 0.76 (95% CI: 0.65, 0.86), 0.72 (95% CI: 0.54, 0.89), and 0.80 (95% CI: 0.67, 0.92), respectively, in the validation cohort (Supplementary Table 5 ). The patients were stratified into three risk groups by cutoff scores corresponding to two-year RFS and OS  The correlation between the pathological results and radiologic findings was explored (Supplementary Table 7 ). HCCs were associated with thick-rim APHE (odds ratio [OR], 6.7), absence of delayed central enhancement (OR, 3.5), no targetoid appearance on DWI/TP/HBP (OR, 2.7-5.1), and presence of capsule (OR, 9.9) (p < 0.01). MVI was associated with vascular involvement other than TIV (OR, 2.2) and hypointense nodules without APHE (OR, 3.1) (p < 0.05).  Targetoid appearance in primary liver malignancies has been associated with poor surgical outcomes and aggressive histopathologic features [10, 11, 32] . However, further prognostic stratification within targetoid lesions has been neglected. We evaluated the factors associated with recurrence and survival after curative surgery for targetoid primary liver malignancy and developed risk stratification models. On multivariable analysis, tumor size of ≥ 2 cm, thin-rim APHE, hypointense HBP nodules without APHE, TIV, and vascular involvement other than TIV were independent predictors of recurrence and death. The integrated risk scores classified the patients into three distinct risk groups for recurrence and death. Our results may help preoperatively identify targetoid primary liver malignancies at risk of poor surgical outcomes, potentially modifying the extent of surgery or intensity of postoperative surveillance. In our study, thin-rim APHE was associated with poorer RFS and OS than thick-rim APHE. Notably, thick-rim APHE was predominantly associated with HCC (74.0%; 57 of 77), whereas thin-rim APHE was observed in 65.1% (28 of 43) of non-HCC (p < 0.001). This suggests that the arterial enhancing area may reflect favorable pathologic features proportionally. Supporting this finding, a prior radiologicpathologic correlation revealed that hypervascular tumors have a larger proportion of HCC in cHCC-CCA [33] , and quantitative hypovascular areas are predictive of aggressive macrotrabecular-massive HCC [34] . Additionally, rim APHE of uneven thickness is significantly more common in cHCC- kjronline.org CCA than in CCA [7] , suggesting a positive correlation between the arterial enhancing area and the HCC component. Although rim APHE is a known poor prognostic factor in primary liver malignancies [10, 11, 35, 36] , we showed that it might be further classified into reproducible patterns that significantly affect surgical outcomes, underlined by good inter-reader agreement and externally validated discriminatory power. However, given the reduced agreement with less experienced readers, acknowledging the proposed types of rim APHE and their prognostic impact is required for a consistent interpretation. We developed two multivariable models for RFS that either included or excluded features only available on HBP to account for incidences where gadoxetic acid-enhanced MRI was unavailable or HBP images were suboptimal. Moreover, the risk scores from both models demonstrated comparable discriminatory performance, successfully addressing these challenges. Of the HBP features assessed, hypointense nodules without APHE were strong predictors of recurrence. Interestingly, for 28 HBP hypointense nodules in the recurrence group, the primary tumor was not only HCC (71.4%, 20 of 28) but also cHCC-CCA (17.9%, 5 of 28) and CCA (10.7%, 3 of 28). HBP hypointense nodules without APHE in HCC represent a spectrum of advanced HCC, early HCC, and high-grade dysplastic nodules [37, 38] , whereas they indicate intrahepatic metastasis in non-HCC malignancies [39] . Previous studies reported higher rates of early recurrence and shorter disease-free survival for HBP hypointense nodules without APHE [19, 20] in HCC, consistent with our results. We assume that the spectrum of hepatocarcinogenesis or occult metastases without evident arterial enhancement is shown by our study's HBP hypointense nodule without APHE. The apparent disease recurrence most likely reduced RFS and OS. Although we could not reveal the histopathologic nature of these nodules, we have established grounds for a strong argument that in both HCC and non-HCC malignancies, HBP hypointense nodules left unresected are influential risk factors, warranting sensitive radiological detection and consideration for removal. Other than TIV, vascular involvement was an independent predictor of death and related to pathologic MVI. Considering that the definition of MVI is ""tumor emboli in the vascular endothelial space"" [40] , vascular involvement may be an indicator of MVI, but this relationship requires further validation. Aside from TIV, vascular involvement can be a useful prognostic factor in the context of relatively constant inter-reader agreement across reader experiences. Our study had several limitations. First, it was a retrospective study with a selection bias. Second, patients with radiological macrovascular TIV (12.2%; 24 of 197) were included in the study, which could be viewed as a contraindication for surgery. However, the thrombi were located in the peripheral segmental branches and were deemed resectable by surgeons. With increasing surgical attempts to cure patients with TIV, our results reveal that TIV is a poor postoperative risk factor. Third, we did not perform a dedicated retrospective histopathologic review of cHCC-CCAs according to the latest 2019 World Health Organization classification, and some diagnoses may be outdated, although the number of cHCC-CCAs was small. Finally, because our study included patients with chronic liver disease that had heterogeneous etiologies, the proposed model may perform differently in populations exclusively with chronic hepatitis B or cirrhosis. In conclusion, tumor size of ≥ 2 cm, thin-rim APHE, HBP hypointense nodules without APHE, and tumor vascular involvement were predictors of postoperative recurrence and death for targetoid primary liver malignancies in chronic liver disease, and derived and externally validated risk scores may help to predict postoperative RFS and OS in these patients. The Supplement is available with this article at https://doi.org/10.3348/kjr.2022.0560. The datasets generated or analyzed during the study are available from the corresponding author on reasonable request. [1] [2] [3] [4] . However, in daily practice, transarterial treatment is often chosen as a second-line option at all stages via treatment stage migration [1, 5] . Since transarterial embolization (TAE) was first reported in 1974, various types of transarterial treatments have emerged with the development of new devices and the introduction of new treatment concepts, including transarterial chemoembolization (TACE), drugeluting bead (embolics) TACE (DEB-TACE), and transarterial radioembolization (TARE) [6] [7] [8] [9] [10] [11] . Similar to other radiological procedures, transarterial treatments are safe but can result in adverse events (Fig. 1) . The reported incidence varies widely according Complications Related to Transarterial Treatment of Hepatocellular Carcinoma: A Comprehensive Review to the population, type of interventional procedure, and definition [12, 13] . Although most of these complications are not serious, some lead to morbidity and mortality [14] . Some are specific to certain types of procedures, while others can occur regardless of modality (Tables  1, 2) . Complications unfamiliar to both diagnostic and interventional radiologists can be encountered as newer techniques are introduced. Therefore, data from the current literature should be updated [12] [13] [14] [15] . This study aimed to review and organize various complications related to currently available transarterial treatments for HCC. Postembolization syndrome (PES) is not considered a complication by itself but rather a predicted outcome after any type of embolotherapy [16] . Radiological findings specific to PES are unavailable since they are diagnosed solely based on clinical findings. PES is characterized by fever, abdominal pain, and/or leukocytosis within the first few days of transarterial treatment. PES is the most common adverse event (ranging from 15% to 90%) after TACE and is a frequent cause of prolonged hospital stays [17] . Although DEB-TACE is known to have a low incidence of PES since it has better pharmacokinetic features compared to TACE, recent studies show contradictory results [18] [19] [20] [21] [22] .  The minimal embolic effect of TARE is associated with a lower incidence of PES (20%-55%) [3] . A history of PES, tumor burden, number of treated nodules, presence of cirrhosis, and dose of embolic agents have been identified as predictive factors of PES [17, 21, 23] . Symptoms are usually self-limiting and subside within a few days. The treatment is supportive, including analgesics and antiemetics, as needed to control symptoms. The prophylactic use of anti-inflammatory agents (e.g., dexamethasone or parecoxib) to alleviate PES has been suggested in recent randomized controlled trials [24] [25] [26] . However, prophylactic agents should be used cautiously, particularly in patients with viral hepatitis or uncontrolled diabetes mellitus. TARE is based on the local delivery of radionuclides bound to glass or resin microspheres, which minimizes systemic toxicity. A recent prospective study found that up to 1% of 90 Y administered via resin microspheres to the liver is eluted as free 90 Y in the blood [27] . After TARE, more than 95% of patients experience transient lymphopenia, which decreases by approximately 50% and recovers to approximately 60% of baseline at 6 months [28] . However, discernible clinical consequences have been reported to be rare, even after whole-liver radioembolization [29, 30] . Both conventional TACE and DEB-TACE can cause variable degrees of liver failure (Fig. 2) . Liver failure was defined as an increase in serum bilirubin levels, increasing or newly developed ascites, or hepatic encephalopathy within 2 weeks of the procedure [31] . It is a serious complication that can lead to significant morbidity and mortality. TACE is mainly performed in patients with relatively preserved liver function (Child-Pugh stage ≤ B7) [32] ; however, approximately 60% of patients experience at least one episode of liver failure during the course of treatment [33] . kjronline.org TACE is based on a dual blood supply to the liver, and HCCs are supplied exclusively by the hepatic artery. Consequently, portal vein thrombosis has been recognized as a risk factor for postprocedural liver failure [34] . However, microcatheter systems allow TACE for HCCs with main portal vein tumor thrombosis [35] . Ascites, large tumors (> 5 cm), high aspartate aminotransferase, bilirubin, and alpha-fetoprotein levels, and low serum albumin and sodium levels have also been suggested as potential risk factors [36] . Non-selective bilobar chemoembolization is an important technical risk factor for liver failure. Radioembolization-induced liver disease (REILD) is a specific type of liver injury caused by 90 Y microspheres. It typically manifests as jaundice and ascites that develop 4-8 weeks after treatment, without biliary obstruction or tumor progression. The overall incidence of REILD after TARE ranges from 4% to 9% [37, 38] . Its severity ranges from minor changes in biochemical markers to severe liver failure [39] . Risk factors include whole liver treatment, sequential lobar treatment for < 6 weeks, tumor volume > 70% of the liver, radiation dose to the target liver ≥ 150 Gy, , and concurrent use of chemotherapeutic agents (e.g., capecitabine) in the 2 months following TARE [40] [41] [42] . Imaging findings are nonspecific and include heterogeneous enhancement or poorly defined hypointense areas in the liver parenchyma and ascites ( Fig. 3 ) [43] . Imaging  Liver infarction is an uncommon complication due to a dual blood supply consisting of the hepatic artery and the portal vein. Although conservative management can be effective in most patients, secondary infections can result in serious complications, including abscess or sepsis [12] . It is more common with metastasis than HCC [49] . Noncirrhotic patients appear to have a higher risk of developing locoregional complications than patients with liver cirrhosis. This may be due to the hypertrophied peribiliary plexus observed in patients with cirrhosis. Predisposing factors for liver infarction include non-selective embolization, large tumor burden, and frequently repeated treatments [50] . The imaging findings of liver infarction include hypodense areas without enhancement, air bubbles with Lipiodol on dynamic CT, and hypointensity on T1-and hyperintensity on T2-weighted images on MRI ( Fig. 4) [51]. Clinical symptoms and signs can help discriminate between liver and liver infarctions. Liver abscess has been reported as one of the serious side effects of TACE, with an incidence of 0.3%-1.3% [52, 53] . Patients with bilioenteric anastomosis have a higher risk of liver abscess due to the lack of duodenal extensor muscle, which prevents bacterial flow from the intestines to the bile ducts Fever, chills, and abdominal pain are the most frequently reported symptoms [43, 54] . Imaging studies should be considered when patients with a high risk of liver abscess have high-grade fever for 2 weeks or longer after TACE. On contrast-enhanced CT, abscesses typically appear as low-attenuation lesions with or without scattered highattenuation Lipiodol (Fig. 5 ). On ultrasound, they appear as circumscribed heterogeneously hypoechoic lesions. It may be difficult to differentiate liver abscesses from tumor necrosis or liver infarction immediately after TACE [53] . For early diagnosis, gas-containing focal lesions and clinical signs and symptoms may be useful features [59] . Percutaneous aspiration/catheter drainage and antibiotic treatment remain the mainstays of management [55, 60] . Prophylactic antibiotics administered before and after treatment may reduce the risk of postembolization infection and should be considered [16, 61] . HCC rupture after TACE is a rare but life-threatening The mechanism underlying HCC rupture has not been fully elucidated. However, a combination of factors, including increased intratumoral pressure and local vasculopathy associated with malignancy, may be associated with the risk of rupture [63] . The vascular lake phenomenon during DEB-TACE is a common angiographic finding (incidence ranged from 12.1% to 25.5%), which may be caused by the rupture of the tumor microvasculature. It has been reported to be associated with HCC rupture in previous studies [64, 65] . When HCC ruptures, CT can provide valuable information on the focus of bleeding to assist in treatment planning ( Supplementary Fig. 1 ). The hemoperitoneum with the highest attenuation is usually closest to the sources of bleeding, while a hematoma located further from the bleeding site tends to be diluted by pre-existing ascites.  While the liver receives a dual blood supply from the hepatic artery and portal vein, the peribiliary capillary plexus receives blood supply exclusively from the hepatic artery. As bile duct branches commonly arise from the proximal portion of A1 and A4, TACE for HCC in segments 1 and 4 may be a risk factor for postprocedural bile duct injury ( Supplementary Fig. 2) [69]. The risk of biliary complications is higher in non-cirrhotic patients than in cirrhotic patients with hypertrophy of the peribiliary capillary plexus. An increased risk of liver and biliary injury has also been reported following DEB-TACE [19, 54] . To minimize hepatic locoregional complications, DEB-TACE should be performed in a super selective manner [20] . The recommended endpoint of embolization for DEB-TACE is near stasis (i.e., the contrast column should clear within two to five heartbeats) [70] . Imaging features of bile duct injury can be categorized as bile duct dilatation, biloma, or bile duct stricture (Fig. 6) [71]. Dilatation of bile ducts commonly occurs during the early stages of ischemic cholangiopathy. In more severe cases of ischemic insult, necrosis involving the full thickness of the bile ducts results in biloma. Chronic inflammation can eventually lead to fibrotic strictures in bile ducts. Endoscopic retrograde cholangiopancreatography or percutaneous transhepatic biliary drainage is required for bile duct strictures with dilatation. Percutaneous aspiration and catheter drainage should be performed in patients with infected bilomas. Bronchobiliary fistulas are characterized by abnormal communication between the bronchial and biliary trees. Pathogenic mechanisms include the following: 1) TACE-induced ischemia resulting in necrosis of the bile ducts and subsequent strictures and bilomas, 2) elevation of biliary system pressure, and 3) inflammatory reactions in the subdiaphragmatic space and subsequent rupture in the bronchial tree [72] . Early diagnosis and drainage of the biloma near the diaphragm may be a preventive measure. A bilious productive cough following TACE should raise suspicion of a bronchobiliary fistula. Diagnosis can be made based on sputum analysis and/or imaging studies (Fig. 7) . Percutaneous transhepatic cholangiography and endoscopic retrograde cholangiopancreatography can be used to determine the exact anatomy of a fistulous tract. Endobronchial leakage of a high-density contrast agent from the intrahepatic bile ducts confirmed the presence of a bronchobiliary fistula. The first-line treatment involves biliary decompression to decrease pressure gradients in the common bile duct and duodenum. If biliary decompression fails and the fistula remains patent on cholangiography, percutaneous or endobronchial embolization of the fistulous tract may be considered. According to a recent systematic review of 64 published articles, the success rate of percutaneous treatment is approximately 75% [73] . Surgical repair is the definitive treatment option for patients who do not respond to minimally invasive treatment. Cholecystitis may be caused by obstruction of the cystic https://doi.org/10.3348/kjr.2022.0395 kjronline.org artery by embolic material or radiation injury from the accumulation of 90 Y particles ( Supplementary Fig. 3) [44]. The cystic artery usually arises from the right hepatic artery, which divides into superficial and deep branches to supply the free peritoneal surface and gallbladder bed, respectively ( Supplementary Fig. 2) [74]. The deep cystic artery can supply tumors located near the gallbladder. The superficial cystic artery may supply tumors via fine communication channels between the deep and superficial branches. During radioembolization, this complication can be prevented by identifying the cystic artery and positioning the catheter beyond its origin. When this method is not possible, the cystic artery is permanently or temporarily embolized using coils. Superselective chemoembolization or chemoinfusion at the deep branch of the cystic artery is relatively safe [74] . Chu et al. [75] reported that transient or persistent gallbladder wall thickening was the most frequent CT finding following 340 sessions of intra-arterial therapy through the cystic artery. In their study, acute cholecystitis was observed in only two patients, who responded well to conservative management. Clinical presentation can range from asymptomatic to right upper quadrant pain and fever. Surgical interventions may be required in complicated cases, including cholecystectomy or percutaneous cholecystostomy [76] . TARE has been associated with gastrointestinal complications such as gastroduodenal ulcers and pancreatitis [43] . Non-target embolization occurs due to the reflux of embolic material or 90 Y particles into the gastric/ small intestinal vasculature or the presence of undetected anatomic variations. Accessory left gastric arteries arise from the left hepatic artery, and the right gastric artery arises from the proper hepatic artery is a relatively common anatomical variation. The supraduodenal artery supplies the horizontal portion of the first duodenal segment. The duodenal bulb and pancreatic uncinate process are supplied by the retroduodenal artery [77] . Therefore, a careful review of angiograms is recommended to prevent inadvertent reflux. Coil embolization is the most frequently performed preventive measure ( Supplementary Fig. 4) , and anti-reflux microcatheters or micro-balloon catheters have also been used recently. Prophylactic medications (H2 receptor blockers or proton pump inhibitors) may be prescribed before the procedure reported that abdominal pain, nausea, and vomiting are common symptoms that can appear several months after TARE. Chemotherapy or radiation-induced ulceration may be difficult to manage using conventional medical therapies [81] . Endoscopic evaluation is warranted in patients with gastrointestinal bleeding to rule out alternative causes of bleeding, such as varices. Acute pancreatitis is a rare complication resulting from kjronline.org the regurgitation of embolic material from the hepatic artery into the dorsal pancreatic or gastroduodenal arteries. The pancreas has a rich vascular supply from the branches of the celiac trunk and the superior mesenteric artery. However, the pancreatic head and uncinate process are more prone to reflux embolization than the body or tail, as the gastroduodenal artery is one of the terminal branches of the common hepatic artery  Inadvertent embolization of the splenic artery is very rare but can lead to splenic infarction and/or abscess. Conditions that can increase the risk of embolic material reflux include celiac stenosis with hepatofugal blood flow in the common hepatic artery, increased blood flow through the splenic artery due to underlying liver cirrhosis and splenomegaly, and catheter-induced spasm of the proper hepatic artery [50] . Selective embolization with a microcatheter and meticulous procedures may prevent iatrogenic complications. The most typical clinical feature is acute left upper-quadrant abdominal pain, which subsides within 3-10 days [12] . Percutaneous drainage is indicated in rare cases of large splenic abscesses. Pulmonary Lipiodol embolism occurs when intrahepatic arteriovenous shunting between the hepatic artery and the hepatic vein or transpleural communication between the inferior phrenic artery and the pulmonary circulation. The azygoesophageal branch is the most common feeder of a systemic-to-pulmonary shunt, which may mimic tumor staining on inferior phrenic angiography ( Supplementary  Fig. 5 To prevent fatal pulmonary Lipiodol embolism, Lipiodol at a dose of 14.5-20 mL has been recommended as the maximum safe dose in previous studies [50, 87] . The use of DEBs may also be responsible for pulmonary infarction. The size threshold of these beads has not been established; however, fatal pulmonary infarction has been reported following the use of 40-120 μm beads [14] . The treatment of pulmonary infarction is essentially supportive and similar to that of fat embolism syndrome. In a previous study, hypoxemia and chest radiographic abnormalities gradually improved over 10-28 days [50]. A major concern of TARE is the shunting of 90 Y microspheres to the lungs. Pulmonary infarction manifests as radiation pneumonitis when excessive arteriovenous shunting is present. The incidence of radiation pneumonitis associated with TARE is < 1%. To prevent this serious complication, a lung shunt study should be performed, and dosimetry must be conducted before TARE. The recommended lung dose should be < 30 Gy per session and no more than 50 Gy per person [89] . Radiation pneumonitis typically occurs 1-6 months after treatment and is characterized by restrictive ventilatory dysfunction accompanied by exertional dyspnea and dry cough. Classic imaging findings are bilateral, symmetric patchy opacities, and ground-glass nodularity with relative hilar or perihilar sparing (bat-wing appearance) (Fig. 8 ). These findings may resolve or progress to fibrosis, traction bronchiectasis, or focal honeycombing [43] . Steroids are the mainstay of treatment for reducing inflammatory processes [90] . The inferior phrenic artery is one of the most common extrahepatic collateral arteries supplying HCCs. TACE https://doi.org/10.3348/kjr.2022.0395 kjronline.org kjronline.org through the inferior phrenic artery is usually considered a safe procedure without serious complications. Potential minor complications include shoulder pain, hiccups, pleural effusion, and basal atelectasis [91] . However, the inferior phrenic artery is a major source of blood supply to the diaphragm, predominantly in the central region. Ischemic injuries may cause diffuse or focal diaphragmatic weakness and dysfunction. The incidence of diaphragmatic weakness after TACE through the inferior phrenic artery ranges from 18.7% to 40% [91]. Diaphragmatic weakness may resolve spontaneously or may be permanent in more than half of the patients [92] . Diaphragmatic perforation has been reported to be a rare but fatal complication of TACE through the inferior phrenic artery (Fig. 9) [93,94]. To reduce diaphragmatic injury, every effort should be made to selectively embolize the tumor feeders instead of sacrificing the entire inferior phrenic artery. The frequency of TACE-related cerebral embolism has been reported to be 1. (Fig. 10) . Old age, female sex, and TACE through both the right inferior phrenic and right hepatic arteries may be associated with poor clinical outcomes [96] . Most of the causes are unavoidable, but a careful review of the medical history is needed. The main blood supply to the spinal cord originates from single anterior and paired posterior spinal arteries. The spinal arteries anastomose the segmental medullary and radicular arteries, derived from the cervical, lumbar, and intercostal arteries. These anatomical characteristics account for the association between spinal cord injury and TAE/TACE via extrahepatic collaterals. Therefore, the vertebral column should be included in the field of view of intercostal or lumbar angiograms. During TACE of the intercostal artery, the microcatheter should be advanced beyond the diaphragmatic insertion site (U-turn point) to prevent spinal infarction or skin necrosis [97, 98] . Clinical symptoms usually appear 6-8 hours after the procedure as paresthesia, impaired sensory function, paraplegia, and urinary retention [99] . MRI findings are usually normal in the acute phase; however, spinal cord edema and T2 abnormalities may appear after 1-2 days (Fig. 11) [100]. Skin injury occurs due to non-target embolization of the cutaneous branches of the hepatic and extrahepatic feeders. The falciform ligament artery is known to be responsible for epigastric skin rash after TACE ( Supplementary Fig.  6 ). It arises from the left or middle hepatic artery, runs through the falciform ligament and distributes around the umbilicus. Skin injury has also been reported following TACE via the internal mammary, intercostal, and lumbar arteries. Doxorubicin is a vesicant chemotherapeutic agent that binds to tissue DNA and may cause severe skin necrosis (Fig. 12) [101]. Radiation dermatitis is a specific form of skin injury associated with 90 Y microspheres. To avoid complications, prophylactic embolization of the cutaneous branches may be required. Wang et al. [102] reported that the topical application of ice decreased skin complications after TACE and TARE by causing vasoconstriction. Common iatrogenic complications of transarterial treatment include vascular spasm, dissection, and occlusion, while puncture site problems such as hematoma, pseudoaneurysm, and lymphorrhea occur less frequently. Hepatic artery spasm is a transient, focal increase in vascular tone, which causes the lumen to narrow and blood flow to decrease ( Supplementary Fig. 7 ). Nitroglycerine can be injected via a catheter to manage transient spasms during the procedure. Dissection of the hepatic artery may kjronline.org resolve without treatment; however, it may cause significant stenosis and, eventually, obstruction [15] . Consequently, subsequent transarterial treatment or liver transplantation can be challenging. Iatrogenic aortic dissection is a rare but the most fatal complication associated with the procedure ( Supplementary Fig. 8 ). To avoid complications, physicians should always gently manipulate the wires and catheters. Transarterial treatment can cause various complications in the vessels and organs involved during the procedure. Non-target organs such as the skin, lungs, gastrointestinal tract, and even neurological systems can also be affected. Symptoms, signs, and postprocedural imaging findings play a key role in the evaluation and management of adverse events. Procedural details are also important when interpreting postprocedural imaging findings, as newer treatment modalities are frequently used. The type and location of a microcatheter, embolization extent, and presence of the cutaneous or spinal branches on angiograms are closely associated with complications for TACE. The lung shunt fraction, lung dose, and normal liver dose are critical values for TARE. Familiarity with various transarterial treatment procedures can help radiologists discriminate between treatment-related changes and complications, eventually leading to better patient management during the course of HCC treatment. The Supplement is available with this article at https://doi.org/10.3348/kjr.2022.0395. Data sharing does not apply to this article as no datasets were generated or analyzed during the current study.  Spinal stenosis is a common disease in the elderly population and its incidence has been gradually increasing with an aging society [1] . Magnetic resonance imaging (MRI) is a standard imaging technique for the diagnosis of spinal stenosis, and the demand for spinal MRI is steadily rising every year [2] . Although MRI has been used as the gold standard for diagnosing spinal stenosis, well- The North American Spine Society has provided guidelines for diagnosis and treatment of degenerative lumbar spinal stenosis [3] . Ironically, the literature does not contain any detailed specifications of the radiologic criteria or parameters to describe the degree of lumbar spinal stenosis. Moreover, researchers have used various radiologic criteria for classifying the severity of lumbar spinal stenosis in patients included in different therapeutic clinical trials [4, 5] . Therefore, Lee et al. [6] [7] [8] [9] suggested a practical grading system (the Lee grading system) for central canal and neural foraminal stenosis of the cervical and lumbar spine, which are now widely accepted in clinical practice, included in web-based radiology resources, and cited in many studies. In this review, we revisited the Lee grading system for cervical and lumbar spinal stenosis. Spinal stenosis can be quantitatively or qualitatively assessed. A quantitative parameter is a measurable value, such as the diameter or cross-sectional area.  Lumbar central stenosis is narrowing of the spinal canal due to degeneration and progressive hypertrophy of the surrounding osseocartilaginous and ligamentous structures. The most common symptom associated with lumbar central stenosis is neurogenic claudication, a clinical condition in which patients experience lower leg pain, cramps, and weakness after walking for a certain distance [18] . Quantitative parameters, such as the anterior-posterior diameter and cross-sectional area of the dural sac, are commonly used radiologic measurements to determine central canal stenosis in patients with neurogenic claudication. These parameters can be helpful in assessing upper lumbar spine level or for modality that cannot visualize the cauda equina within the dural sac such as computed tomography. An anterior-posterior diameter of less than 10 mm or a crosssectional area of less than 100 mm 2 suggests stenosis [19] . Classification based on quantitative measurements has limitations because the number of rootlets decreases at the lower lumbar level as the rootlets exit through the neural foramen sequentially at each level [20] . For instance, at the upper lumbar level, a decrease in the dural sac crosssectional area of less than 100 mm 2 can result in a significant compromise of the cauda equina inside the dural sac. In contrast, at the lower lumbar level, such as at L5/S1, the cauda equina would not be compromised at a cross-sectional area of 100 mm 2 because a small number of rootlets remain at that level. Many authors have reported that these quantitative radiological findings alone cannot be the major criteria for predicting clinical severity and outcomes [21, 22] . The Lee grading system for lumbar central canal stenosis is described in Table 1 and Figure 1 . Stenosis can be graded as mild, moderate, or severe, depending on the degree of CSF space obliteration and cauda equina clumping. Axial T2weighted images were examined for grading purpose. In ""mild"" central canal stenosis, each nerve rootlet remains separated inside the dural sac without clumping. In ""moderate"" central Semiquantitative or qualitative parameters are evaluated via visual assessment. The word ""stenosis"" means ""narrowing or constriction of the diameter of a bodily passage or orifice."" [10] For blood vessels, any degree of luminal narrowing can cause alterations in fluid dynamics, blood flow, and pressure [11, 12] . However, because the spinal cord or cauda equina floats in ample cerebrospinal fluid (CSF) within the dural sac or central canal, a certain degree of central canal narrowing does not significantly compromise the spinal cord or nerve rootlets [13] . However, significant symptoms may occur in cases of close contact with or direct compression of the cauda equina by degenerative spinal structures. The nerve root passing through the neural foramen is surrounded by perineural fat that protects the nerve root from compression due to adjacent osseous, ligamentous, or discal structures, and it functions like the CSF in the dural sac [14, 15] . Similar to central canal stenosis, a minor decrease in the crosssectional area of the neural foramen does not always result in significant radiculopathy symptoms [16] . Considering these pathophysiological characteristics of spinal stenosis, quantitative parameters, such as anterior-posterior diameter or cross-sectional area, seem to have a limited role in the diagnosis of clinically significant central canal stenosis. The consensus meeting of the Lumbar Spine Outcome Study Working Group Zurich identified the criterion, ""relationship between the CSF and cauda equina,"" as an essential parameter for evaluating lumbar central canal stenosis, which is reflected in the Lee grading system [17] . The Lee grading systems is based on qualitative assessment and was developed to establish criteria that could meet the essential requirements of a grading method, such as reproducibility and reliability, high sensitivity, ease of learning and understanding, ability to account for individual anatomical variations, and correlation with symptoms and outcomes [6] [7] [8] [9] . kjronline.org canal stenosis (grade 2), there is some clumping of the nerve rootlets inside the dural sac. If the cauda equina appears as a single bundle due to marked clumping, without any separation of the nerve rootlets, that would indicate ""severe"" central canal stenosis (grade 3). Determining grades 0 and 1 can sometimes be confusing. In such cases, sagittal T2-weighted images may be helpful. Obliteration of the ventral CSF space on consecutive sagittal images can be used to distinguish ""mild"" stenosis (grade 1) from ""no"" stenosis (grade 0). Considering the underlying morphological and anatomical variations in individuals, this rapid visual assessment may contribute to the strength of this grading system. In fact, this grading system showed excellent to perfect intraobserver reliability, excellent to perfect interobserver agreement, and was significantly correlated with clinical manifestations [6, 23, 24] . Although it would not be difficult to follow this grading system, readers may encounter confusing cases. The first case concerns flow-related artifacts in the ventral CSF space. When there is a flow-related artifact, the CSF space shows heterogeneous hypointensity or inhomogeneous signal intensity on axial T2-weighted images, which might appear as crowding of the cauda equina [25] . This finding might lead to an overestimation of central canal stenosis ( Fig. 2A, B ). The other cases are those with ample hyperintensity within the bony central canal (Fig. 2C, D) . Although the dural sac is severely collapsed in both cases due to prominent epidural fat or synovial cysts, there is sufficient hyperintensity area ventral or dorsal to the dural sac, which can be misjudged as visible CSF. These cases should not be overlooked and should be considered severe central canal stenosis because the cauda equina appears as a single bundle due to severe compression of the dural sac. A qualitative grading system proposed by Schizas et al. [26] focused on the CSF/rootlet ratio and effacement of the dorsal epidural fat, sharing the basic concept of the Lee grading system [23] . The Schizas et al. [26] grading system additionally described the inhomogeneous distribution of the cauda equina within the dural sac in cases with no or minor central canal stenoses.  Lumbar neural foraminal stenosis occurs when the nerve root at the neural foramen is compromised because of a combination of degenerative changes in the lumbar spine, including decreased height of the intervertebral disc, osteoarthritis of the facet joint, associated cephalad subluxation of the superior articular process, buckling of the ligamentum flava, or protrusion of the annulus fibrosus [27] . Similarly, in lumbar central canal stenosis, a minor decrease in the cross-sectional area of the neural foramen does not represent neural foraminal stenosis. The Lumbar Spine Outcome Study Working Group Zurich considered the presence of perineural intraforaminal fat a reliable finding in neural foraminal stenosis [17] . A few radiologic criteria or parameters have been reported for the evaluation of lumbar neural foraminal stenosis. The grading system proposed by Wildermuth et al. [28] focuses only on the degree of epidural fat obliteration. Another classification proposed by Kunogi and Hasue [29] defines stenosis according to the direction of obliteration of perineural fat. However, a major difference from the Lee grading system criteria is that neither of these systems considers the morphological change or deformity of the nerve root as a factor in determining severity, which is a major strength of the Lee criteria for diagnosing lumbar neural foraminal stenosis. The Lee grading system showed good reproducibility and perfect interobserver agreement, and was significantly correlated with clinical manifestations [7, 30, 31] . The Lee grading system for lumbar neural foraminal stenosis is presented in Table 2 and Figure 3 . This system graded lumbar neural foraminal stenosis in terms of perineural fat obliteration and morphological changes in the nerve root. To diagnose lumbar neural foraminal stenosis, perineural fat in the neural foramen should be obliterated in at least one direction by the surrounding structures during the degenerative process. To clearly define neural foraminal stenosis, we suggest that at least one direction (i.e., one side and its opposite side) of the perineural fat should be obliterated. If perineural fat obliteration is observed only on a single side of the nerve and if the opposite side is preserved, the condition is not defined as neural foraminal stenosis. ""Mild"" lumbar neural foraminal stenosis (grade 1) is defined as perineural fat obliteration occurring in one opposing direction, such as the anterior-posterior (transverse) or superior-inferior (vertical) direction, without any morphological changes in the nerve root. ""Moderate"" kjronline.org lumbar neural foraminal stenosis (grade 2) is defined when perineural fat obliteration occurs in two or more directions but without morphological changes in the nerve root. ""Severe"" lumbar neural foraminal stenosis (grade 3) is defined when compression/collapse or morphological changes of the nerve root are observed. In some cases, especially those with spondylolytic spondylolisthesis, the nerve root can severely collapse in only one direction, and perineural fat can be visible. These cases are defined as having ""severe"" lumbar neural foraminal stenosis because of the presence of morphological changes in the compressed nerve root (Fig. 4) . The narrowing of the cervical spinal canal is caused by degenerative changes in several elements of the spinal architecture. As intervertebral disc degeneration progresses, the disc loses its ability to bear axial loads. These axial loads are transferred to the uncovertebral and facet joints, leading to joint space narrowing, subchondral sclerosis, and osteophyte formation at the joints [32] . These changes subsequently narrow the cervical spinal canal along with neural foramina, resulting in cervical spondylotic myelopathy or cervical spondylotic radiculopathy. Common symptoms of cervical spondylotic myelopathy are gait disturbances and [34, 35] . The cross-sectional area and dural sac diameter were measured on MRI. These measurements are a better assessment of spinal canal stenosis than that of the lumbar segment, but it still cannot represent a compromise of the spinal cord. Muhle et al. [36] proposed a qualitative classification system based on the degree of obliteration of the subarachnoid space and cord compression. However, according to our experience over the years, there are several limitations to their system: 1) the description of the degree of stenosis, such as partial or complete, was ambiguous or impractical and 2) the system did not account for signal alteration of the spinal cord, which is a hallmark of compressive myelopathy, the most severe stage of central canal stenosis. The Lee grading system for cervical central canal stenosis takes into consideration the following obvious findings: CSF obliteration, spinal cord deformity, and intramedullary signal change, which reflect the mechanism and natural prognosis of spinal canal stenosis. Based on these findings, and with the aim of providing a clearer description, we proposed a grading system for cervical central canal stenosis. The Lee grading system for cervical central canal stenosis showed excellent intraobserver reliability and excellent to perfect interobserver agreement, and was significantly correlated with clinical manifestations [8, 37] . The Lee grading system for cervical central canal stenosis is shown in Table 3 and Figure 5 . The diagnosis of cervical central canal stenosis can be made based on a quick visual assessment of sagittal T2-weighted images. If more than 50% obliteration of the anterior or posterior subarachnoid space is observed, cervical central canal stenosis is considered present in that segment. Specifically, in ""mild"" central canal stenosis (grade 1), narrowing of the central canal induces > 50% obliteration of the anterior and/or posterior subarachnoid space around the spinal cord without any spinal cord deformity or signal change. If a deformity or compression of the spinal cord is observed without any medullary signal change on T2-weighted images, it is defined as ""moderate"" central canal stenosis (grade 2). If a signal change in the spinal cord is observed on T2-weighted images, it is defined as ""severe"" central canal stenosis (grade 3). As mentioned above, this system emphasizes the direct effect on the spinal cord; therefore, several factors should be considered when determining the grade. When the spinal cord is compressed by a bulging disc or thickened ligament, it should be graded as moderate stenosis (grade 2) and not mild stenosis (grade 1), even though the CSF cleft is still preserved between the spinal cord and the compressing structures. Likewise, if a signal change is observed in the spinal cord on T2-weighted images at a level, it should be graded as severe stenosis, regardless of the spinal cord deformity or CSF cleft obliteration. Such cases of severe central canal stenosis (grade 3) are occasionally encountered in dynamic compression setting ( Fig. 6) [38] . Cervical neural foraminal stenosis is a mechanical distortion of the cervical nerve roots due to neural foraminal narrowing caused by degenerative structural changes such as hypertrophied facet or uncovertebral joints, spurring of the vertebral body, lateral disc herniation, or a combination of these factors [39] . These structural changes cause kjronline.org nerve root compression and subsequent radiculopathy. The symptoms of cervical spondylotic radiculopathy include neck pain, radiating pain, and paresthesia in the arms. Several attempts have been made to establish a method to grade cervical neural foraminal stenosis. These systems are mostly based on axial CT or MRI [40] . Park et al. [41] suggested a grading system based on oblique sagittal T2weighted images. In this system, the basic rule of grading is similar to that for lumbar neural foraminal stenosis on sagittal T1-weighted images. A basic assumption in this system is that the oblique sagittal image shows the true foraminal view. However, the orientation angle of the cervical neural foramen varies from C2-3 to C7-T1 [42] . Therefore, obtaining images in a plane perfectly perpendicular to all levels of the cervical neural foramina course is impossible. The Lee grading system for cervical neural foraminal stenosis suggests the use of axial T2-weighted images to avoid overestimation of stenosis. Nevertheless, it might still be difficult to determine the degree of neural foraminal narrowing because the original widths of the neural foramen and nerve root are difficult to define. As spondylotic changes progress, the neural foramen becomes structurally narrowed, and the root is already compressed within the foramen. Therefore, we developed an internal reference, that is, the width of the extraforaminal nerve root, to kjronline.org assess neural foraminal narrowing. The extraforaminal nerve root, which is located between the superior articular process and vertebral artery, is often unaffected by neural foraminal narrowing because cervical neural foraminal stenosis is commonly induced by uncovertebral osteophytes. Based on our clinical experience, we used the width of the extraforaminal nerve root, including the ipsilateral or contralateral side, as a reference to define and grade the neural foraminal stenosis. This grading system showed fair to good reproducibility (intraclass correlation coefficient ranged from 0.68 to 0.73) and perfect interobserver agreement [9] . Moreover, a clinical validity study of this grading system concluded that this system demonstrated a high correlation with clinical manifestations and could be useful in clinical settings [43, 44] . The Lee grading system for cervical neural foraminal stenosis is shown in Table 4 and Figure 7 . The narrowest width of the neural foramen is narrower than that of the extraforaminal nerve root, which indicates the presence of cervical neural foraminal stenosis. If the width of the neural foramen is less than half the width of the extraforaminal nerve root, it indicates ""severe"" neural foraminal stenosis (grade 2). If the width of the neural foramen is more than half, but narrower than the width of the extraforaminal nerve root, it indicates ""non-severe"" neural foraminal stenosis (grade 1). Occasionally, the extraforaminal nerve root is not clearly visible. In such cases, the width of the contralateral extraforaminal nerve root or the distance between the posterior margin of the vertebral artery and anterior margin of the superior articular process can be used as an alternative (Fig. 8) . This review highlights the structured qualitative MRI grading system, the Lee grading system, for lumbar central canal stenosis, lumbar neural foraminal stenosis, cervical central canal stenosis, and cervical neural foraminal The narrowest width of the neural foramen is greater than the width of the extraforaminal nerve root at the level of the anterior margin of the superior articular process. Grade 1 Non-severe The narrowest width of the neural foramen is 51%-100% of the width of the extraforaminal nerve root at the level of the anterior margin of the superior articular process. The width of the neural foramen is the same as or less than 50% of the width of the extraforaminal nerve roots.  Joon Woo Lee who is on the editorial board of the Korean Journal of Radiology was not involved in the editorial evaluation or decision to publish this article. Other author has declared no conflicts of interest. kjronline.org [3] . There is no definitive imaging technique that can accurately differentiate between these two entities [4, 5] . Because both RN and tumor recurrence may coexist in SRStreated tissue comprising a viable tumor, capillary damage, ischemia, and chemotherapy damage [4, [6] [7] [8] , a combination of diffusion-and perfusion-weighted MRI can provide useful information. Diffusion-and perfusion-weighted MRI have been confirmed as effective tools that can increase the diagnostic confidence [4, 6, 9, 10] , depict angiogenesis and necrotic tissue, and improve the diagnostic accuracy better than conventional MRI alone [11] [12] [13] . A tumor habitat analysis can distinguish subregions within a heterogeneous tumor by identifying similar voxels with common tumor biology [14, 15] . A recent habitat analysis using structural MRI [16] showed that a habitat defined by low T2 and low T1 contrast-enhancing signal intensity was associated with viable tumors after SRS for brain metastases. Such a quantitative tumor habitat analysis may be helpful for assessing the residual tumor burden of metastatic tumors after treatment and determining the target for additional SRS. Nonetheless, this study was limited to cross-sectional anatomical MRI data. A previous radiological-pathological correlation analysis of 11 brain metastases treated with SRS revealed that a single MRI examination could not sufficiently determine pathological failure, but that serial MRI was practical for predicting the treatment response [17] . A longitudinal study using diffusion-weighted and dynamic susceptibility contrast (DSC) perfusion-weighted imaging, which reflect tumor cellularity and vascularity, may reveal effective tools that can predict treatment resistance and local recurrence sites. We hypothesized that an evaluation of brain metastases after SRS using serial diffusion-and perfusion-weighted physiological MRI would be useful for predicting the treatment response by identifying subregions of recurrent tumors and treatment-induced changes, and that a spatial tumor habitat analysis would enable the identification of the recurrence site by clustering similar apparent diffusion coefficient (ADC) and cerebral blood volume (CBV) values. This study aimed to predict tumor recurrence (i.e., the treatment response) after SRS of brain metastases by performing a longitudinal tumor habitat analysis using MRI. After receiving approval from the Institutional Review Board of Asan Medical Center (IRB No. 2021-4701), this singlecenter, retrospective, clinical study was conducted according to the United States Health Insurance Portability and Accountability Act (HIPAA) regulations and the Declaration of Helsinki. The need for written informed consent was waived. Additionally, it was conducted in accordance with the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement [18] . Using our center's Redcap database of brain metastases, we identified 301 patients treated during January 1, 2014 to November 30, 2020; of those 301 patients, 212 who fulfilled the following criteria were first identified and evaluated: age older than 18 years; initially diagnosed with brain metastasis and underwent subsequent SRS; brain metastasis with a size of at least 1 x 1 cm 2 ; and a contrast-enhancing lesion (CEL) in the brain metastasis that could be analyzed. Their eligibility for study inclusion was further evaluated using the following criteria: the tumor was enlarged by more than 20% or at least 5 mm after SRS, resulting in clinical suspicion of tumor recurrence according to the response assessment in neuro-oncology brain metastases (RANO-BM) criteria; underwent follow-up MRI including diffusion-weighted imaging (DWI) and DSC perfusion-weighted imaging at least twice; the first followup MRI was performed within 6 months after SRS; and adequate follow-up examination results were available for the assessment of the treatment response. We excluded 129 patients for the following reasons: 39 patients had brain metastases that did not show a sufficient increase in size; 43 patients underwent the first follow-up MRI more than 6 months after SRS; 36 patients did not undergo follow-up MRI including DWI and DSC perfusion-weighted imaging at least twice; and 11 patients did not have adequate followup examination results to allow an assessment of the treatment response. Finally, 83 patients (mean age, 59.0 years; range, 27-82 years; 44 male and 39 female) with a total of 103 brain metastases were included. A flowchart of the patient inclusion process is shown in Figure 1 . Clinical data were collected from the database of the Asan Medical Center. When multiple SRS-treated metastases were present, up to three of the largest lesions of each patient were included. At our institution, patients with brain metastases underwent follow-up assessments involving brain MRI every 2 or 3 months after the initial SRS for 1 or 2 years https://doi.org/10.3348/kjr.2022.0492 kjronline.org during regular outpatient visits under the supervision of a multidisciplinary team [1, 19] . If a patient developed a new symptom or if the neurological symptoms deteriorated, then MRI was performed regardless of the scheduled followup period. When clinically indicated, surgery was performed to confirm the final diagnosis of a viable tumor or RN. If surgery was not possible, then the viable tumor was determined using MRI in accordance with the RANO-BM criteria and serial follow-up examinations with intervals of at least 3 months were performed. Supplemental imaging examinations, such as 3,4-dihydroxy-6-[ 18 F]fluoro-Lphenylalanine) ( 18 F-DOPA) PET/CT, 11 C-methionine PET/ CT, and 18 F-fluorodeoxyglucose ( 18 F-FDG) PET/CT, were also performed for individuals with equivocal MRI results. The clinicoradiological diagnosis was determined by a consensus reached during a multidisciplinary meeting involving three neurosurgeons (all with at least 15 years of experience with neuro-oncology) and two neuroradiologists (with 21 and 9 years of experience with neuro-oncologic imaging, respectively) who reviewed all imaging and medical records. When a CEL exhibited a steady increase in size during two or more successive follow-up MRI examinations within a 2-to 3-month interval and necessitated a change in treatment, the patient was classified as having tumor recurrence. The date of recurrence was recorded and the MRI examination was considered the confirmatory scan. In contrast, when a CEL subsequently regressed or became stable without a change in treatment within 6 months of the index imaging, the patient was categorized as having RN. The time to recurrence was defined as the time from SRS to the first local recurrence event. A 3T scanner was used for all MRI examinations (Ingenia 3.0 CX; Philips Healthcare). The following structural and physiological MRI sequences were performed: T2-weighted imaging (T2WI); fluid-attenuated inversion recovery (FLAIR) imaging; T1-weighted imaging (T1WI); DWI; DSC perfusionweighted imaging; and three-dimensional (3D) contrastenhanced (CE) T1WI. The DWI parameters included the following: repetition time (TR)/echo time (TE), 3000/56 ms; diffusion gradient, b = 0 s/mm 2 and b = 1000 s/mm 2 ; field of view (FOV), 250 x 250 mm 2 ; matrix, 256 x 256; and slice thickness/ gap, 5 mm/2 mm. The ADC values were calculated using DWI images with b = 1000 s/mm 2 and b = 0 s/mm 2 . DSC perfusion-weighted imaging was performed using a gradient-echo echo-planar imaging protocol. A preload of 0.01 mmol/kg gadoterate meglumine was administered, followed by a dynamic bolus of a standard dose of 0.1 mmol/kg gadoterate meglumine (Dotarem; Guerbet) delivered at a rate of 4 mL/s using an MRI-compatible power injector (Spectris; Medrad). The contrast bolus was followed by 20 mL of saline at the same injection rate. The kjronline.org imaging parameters were as follows: TR/TE, 1808/40 ms; flip angle, 35°; FOV, 240 x 240 mm 2 ; slice thickness/gap, 5 mm/2 mm; matrix, 128 x 128; and total acquisition time, 1 minute and 54 seconds. Dynamic acquisition was performed at a temporal resolution of 1.5 seconds, and 60 dynamics were acquired. Brain extraction was performed for 3D CE-T1WI and FLAIR imaging using an algorithm (https://github.com/MIC-DKFZ/ HD-BET). Lesion segmentation was performed based on the images obtained using 3D CE-T1WI and FLAIR imaging and the 3D nnUNet-based algorithm (https://github.com/MIC-DKFZ/nnUNet) [20] of the PyTorch package version 1.1 of Python 3.7 (https://www.python.org). Because the CEL, necrosis, and peritumoral edema were segmented, only the CEL was included in the subsequent analysis. Hemorrhagic lesions were automatically excluded from the analysis if they showed similar hyperintensities on T1WI and CE-T1WI. The process was validated by an experienced neuroradiologist. During T2WI and CE-T1WI, the signal intensity was normalized using kernel density estimation-based white matter segmentation [21] in R (version 4.1.1; Institute for Statistics and Mathematics; https://www.r-project.org/). To perform the DSC analysis, a pharmacokinetic map was computed using Nordic ICE (NordicNeuroLab). The quantity of blood (mL per 100 mL of tissue) was determined using the integrated DSC module, which combines a leakage correction algorithm of the relative CBV (rCBV) and manual noise thresholding. The Weisskoff-Boxerman method, which is based on the time-dependent deviation of the pixel-wise concentration-time curve from a reference curve, indicated that the leakage did not affect the estimations [22] . Normalized CBV (nCBV) maps were created by normalizing the rCBV maps in accordance with normal white matter. To assess the changes in the follow-up examination results, the 3D CE-T1WI images of each patient in the dataset were co-registered and resampled into isometric voxels. Next, using rigid transformations with six degrees of freedom in the SPM package (version 12; https://www.fil. ion.ucl.ac.uk/spm/), the T2WI, nCBV, and ADC images were co-registered and resampled as isovoxel CE-T1WI images. The k-means clustering algorithm in scikit-learn (https://github.com/scikit-learn/scikit-learn) in Python 3.7 (https://www.python.org) was applied to aggregate the voxel clusters based on the signal intensities of T2WI and CE-T1WI or the values of nCBV and ADC reflecting functionally coherent subregions of the CEL. Using k-means clustering, samples from the dataset were classified as a given number of clusters with equal variances. Because the optimal number of clusters in a dataset is crucial to k-means clustering, three, four, and five clusters were initially evaluated ( Supplementary Fig. 1 ). Regarding the structural habitats, three clusters showed differences considering both T2WI and CE-T1WI results, whereas four and five clusters were identified by emphasizing the T2WI and CE-T1WI results, respectively. The four and five clusters displayed narrow ranges. Similarly, regarding the physiological habitats, three clusters demonstrated differences in both ADC and nCBV results, whereas four and five clusters with constrained ranges were identified by emphasizing the ADC and nCBV results, respectively. Therefore, based on the voxel-wise differences, three clusters were chosen to avoid overly parameterized models [16, 23] . Structural habitats were defined as follows: an enhancing tissue habitat with high CE-T1 signal intensity irrespective of T2 signal intensity; a solid low-enhancing habitat with low T2 and CE-T1 signal intensity; and a nonviable tissue habitat with high T2 and low CE-T1 signal intensity. Low and high values were interpreted using the results of a data-driven analysis of k-means clustering without a specific threshold. The ADC and CBV feature maps were used to define the following physiological habitats: a hypervascular cellular habitat with relatively low ADC and relatively high CBV values compared with other habitats; a hypovascular cellular habitat with relatively low ADC and CBV values; and a nonviable tissue habitat with relatively high ADC and relatively low CBV values. The establishment of the tumor habitat is shown in Figure 2 . For the longitudinal tumor habitat analysis, the differences in voxels in each habitat observed during the first and second examinations were calculated. The recurrence site was analyzed using the tumor habitats established by the second follow-up examination and the confirmatory scan (MRI on the date of recurrence). The CEL at the recurrence site shown by the confirmatory scan was compared with the tumor habitats defined during https://doi.org/10.3348/kjr.2022.0492 kjronline.org the second follow-up examination. The images obtained during the confirmatory scan were registered on the images obtained during the second follow-up examination. The region of interest of the CEL on the image obtained during the confirmatory scan was transferred to the tumor habitat observed during the second follow-up examination. The overlap of each habitat with the CEL at the time of recurrence was calculated using the Dice similarity coefficient ( 2|H∩R| ________ |H| + |R| ) [24] , where H indicates each tumor habitat and R indicates the CEL at the time of recurrence. Briefly, the calculation is performed as follows: 2 (overlapped area between each tumor habitat at the second follow-up and CEL at the time of recurrence)/(sum of the tumor habitat at the second follow-up + CEL at the time of recurrence). The Dice similarity coefficient ranged from 0 (no overlap) to 1 (perfect agreement). Tumor habitats observed using structural MRI and physiological MRI to evaluate brain metastasis. To construct habitats using structural MRI, k-means clustering was applied for T2-weighted and contrast-enhanced T1-weighted images. To construct habitats using physiological MRI, k-means clustering was applied for ADC and CBV images. These images are of a 60-year-old male with colon cancer who was treated with stereotactic radiosurgery for metastasis in the left occipital lobe. Enhancing, solid low-enhancing, and nonviable tissue habitats are indicated by red, green, and blue subregions in the structural habitats, respectively. Similarly, hypervascular cellular, hypovascular cellular, and nonviable tissue habitats are represented by red, green, and blue subregions in the physiological habitats, respectively. ADC = apparent diffusion coefficient, CBV = cerebral blood volume https://doi.org/10.3348/kjr.2022.0492 kjronline.org The demographic characteristics of the patients were compared using the chi-square test or Fisher's exact test for discrete variables and the Student's t test for continuous variables. A univariable analysis using Cox regression or the Kaplan-Meier method (log-rank test) was performed to analyze the associations of tumor habitats with the time to recurrence. The hazard ratios (HRs) indicate the relative change in the hazard incurred by a 1-unit increase in each parameter; during this study, 5000 voxels were considered one unit. A multivariable analysis was not performed because each tumor habitat was derived from a given CEL volume, resulting in mutual dependency among the tumor habitats and leading to multicollinearity in the regression analysis. For the significant predictors identified by the univariable Cox regression, an optimal cutoff for stratifying groups at low risk and high risk for recurrence was estimated using maxstat in R (version 4.1.1; Institute for Statistics and Mathematics) with 10-fold cross-validation, which ensured unbiased prediction within the sample [25] . Because the z-score is the ratio of each regression coefficient to its standard error, the Wald statistic is the asymptotically standard normal when it is hypothesized that the corresponding β is zero [26] . These data were used to demonstrate the statistical significance of each spatiotemporal habitat type. The R Statistical Package (version 4.1.1; Institute for Statistics and Mathematics) was used for all statistical analyses. Statistical significance was defined as P < 0.05. Eighty-three patients (mean age, 59.0 years; range, 27-82 years; 44 male and 39 female) with a total of 103 brain metastases who underwent longitudinal followup including MRI after SRS were enrolled in the study. Table 1 lists the characteristics of the patients and their brain metastases. The tumor recurrence and RN subgroups were not statistically significantly different in terms of age, sex, primary cancer origin, time interval between the detection of brain metastasis and SRS, time from SRS to the first and second imaging follow-up examinations, additional radiation therapy, combined chemotherapy, targeted therapy, steroid use, mean number of times SRS was performed, and metastasis size before and at the time of SRS. The time from SRS to the confirmatory scan was longer in the RN subgroup (mean ± standard deviation [SD], 508.2 ± 349.4 days) than in the tumor recurrence group (mean ± SD, 350.9 ± 150.9 days) (P = 0.016). The results of the univariable analysis performed to evaluate the associations between structural and physiological habitats and time to recurrence are summarized in Table 2 . At the time of the first MRI examination, a solid low-enhancing habitat (low T2 and CE-T1 signal intensity) was associated with recurrence. Furthermore, a high number of voxels showing a solid lowenhancing structural habitat (HR, 1.54; 95% confidence interval [CI], 1.01-2.35; P = 0.045) were associated with recurrence. At the time of the second MRI examination, a  The results of the longitudinal analysis of the tumor habitats are presented in Table 3 . During the longitudinal analysis, an increase in the hypovascular cellular habitat was strongly associated with recurrence (HR, 2.68; 95% CI, 1.46-4.91; P < 0.001). The C index was 0.71 (95% CI, 0.62-0.80) after considering the changes in the hypovascular hypercellular habitat and all statistically significant tumor habitats at a single time point. Representative habitats of patients with SRS-treated metastasis with recurrence evaluated using longitudinal physiological MRI are shown in Figure 3 and Supplementary Figure 2 . The optimal cutoff for the longitudinal physiological MRI evaluations of the habitats of groups at low risk and high risk for recurrence was an increase of more than 1345 voxels in the hypovascular cellular habitat. This cutoff separated the low-and high-risk groups, which were significantly different according to the log-rank test (P < 0.001). Supplementary Figure 3 shows the Kaplan-Meier survival curves of the groups at low risk and high risk for recurrence based on hypovascular cellular habitats. Thirty-seven lesions (35.9%; 37/103) were classified as tumor recurrence in 34 patients (41.0%; 34/83). The mean Dice similarity coefficient for the hypovascular cellular habitat observed using physiological MRI was the highest (0.423; range, 0.004-0.969; SD, 0.259), followed by the mean Dice similarity coefficient for the solid low-enhancing habitat observed using structural MRI (0.298; range, 0.015-0.942; SD, 0.247). Figure 4 shows the relationship between temporal changes in the hypovascular cellular habitats and the recurrence site. We demonstrated that brain metastasis recurrence after SRS could be predicted by performing a longitudinal analysis involving diffusion-and perfusion-weighted physiological MRI of the tumor habitat. An increase in the hypovascular cellular habitat, which exhibits both low ADC and CBV values, was significantly associated with the time kjronline.org to recurrence of SRS-treated metastasis. A tumor habitat analysis can identify distinct tumor subregions and cell populations that can be correlated with the biological state of the tissue by co-registering the images with histologic specimens [14, 27] . We longitudinally analyzed tumor habitats using both physiological MRI and structural MRI for brain metastasis after SRS and compared their predictive values for recurrence. Structural MRI was found to be useful for the initial follow-up examination after SRS, during which a solid low-enhancing habitat (low T2 and CE-T1 signal intensity) was associated with recurrence. However, physiological MRI was helpful for predicting recurrence during the follow-up examinations and identified the tumor habitat that most closely matched the recurrence site. It was suggested that defining tumor subregions is helpful in radiation therapy planning, and the understanding of the spatial distribution of physiological tumor subregions could help optimize local radiotherapy [27, 28] . Therefore, the hypovascular cellular subregion on images obtained with physiological MRI should be considered a target for further SRS or other local therapies. When brain metastasis regrows after SRS, it is important to identify viable tumors that require follow-up imaging. Our study identified tumor habitats that could have viable tumors based on the findings of structural MRI and physiological MRI. These tumor habitats were solid kjronline.org low-enhancing with enhanced tissue on structural MRI and hypervascular cellular and hypovascular cellular on physiological MRI. Among them, the following habitats were associated with tumor recurrence at a single time point: solid low-enhancing habitat on structural MRI during the first and second follow-up examinations and hypervascular cellular on physiological MRI during the second follow-up examination. This suggests that viable tumors have inherent cellularity and a certain degree of vascularity. Accordingly, the aforementioned habitats may be potential prognostic factors for tumor recurrence. However, the predictive power for tumor recurrence cannot be guaranteed [29] . From the perspective of the longitudinal analysis, only changes in the hypovascular cellular habitat were associated with tumor recurrence, indicating that the cellularity of the viable tumor is an important factor that can determine tumor recurrence. Moreover, viable tumors can capture existing vessels or generate new ones [30, 31] . However, the vasculature remains relatively low until vessel invasion [32] . Consequently, an increase in the hypovascular hypercellular habitat during longitudinal follow-up examinations might indicate a surge in viable tumors before vascular invasion. kjronline.org Therefore, it could be used as a predictive biomarker to help determine the optimal additional therapy before overt tumor recurrence. Importantly, we performed a habitat analysis of the CEL with both a solid low-enhancing habitat and a hypovascular cellular habitat within it. When the CEL and the solid portion and/or cellular portion with low T2 signal intensity were matched, tumor recurrence was indicated; however, when the CEL and solid portion and/or cellular portion were not matched, RN was indicated. Previous studies that used this interpretation found similar results. Using structural MRI, a T1/T2 mismatch, defined as nonmatching lesion boundaries on T2WI and CE-T1WI, showed 83.3% sensitivity and 91.1% specificity for RN [33] . Using physiological MRI, a layered appearance (without matching) consisting of outer, middle, and inner layers of high CBV, low ADC, and high ADC values, respectively, was suggestive of RN [34] , with sensitivity and specificity rates of approximately 100% for 16 patients. Nonetheless, the visual analysis of enhancement patterns comprising T1/T2 signal intensity mismatch [35] or a layered appearance of high CBV, low ADC, and high ADC values with brain metastasis [36] is limited because it is a subjective assessment. In contrast, a quantitative tumor habitat analysis using k-means clustering applied to co-registered isometric voxels during our study provided objective and robust measurements that could be used to assess RN and viable tumors. The hypovascular cellular habitat observed with physiological MRI had the highest mean Dice similarity coefficient (0.423; range, 0.004-0.969; SD, 0.259). The number of voxels of the CEL tended to change between the second follow-up examination and recurrence. Parametric response mapping [37] , which monitors changes in a single voxel, provided an evaluation of the Dice similarity coefficient of the second follow-up examination and recurrence. Furthermore, parametric response mapping can be used to monitor each tumor habitat and determine the region matching the CEL at the time of recurrence, despite changes in tumor volume. As a result, rather than focusing on the actual number, a mean Dice similarity coefficient of 0.423 was utilized to determine the best tumor habitat corresponding to the recurrence site. The number of patients with recurrent brain metastasis after SRS is likely to increase with improvements in systemic therapy [38] . The recent guidelines of the American Society of Clinical Oncology and the European Society of Clinical Oncology [1, 38] recommend follow-up at 3-month intervals to diagnose brain metastasis recurrence, and that treatment should be continued according to the patient's performance status, neurological function, and prior treatment. A longitudinal analysis using a combination of diffusionand perfusion-weighted MRI can predict [29] the timing of recurrence and stratify patients into groups at low risk and high risk for recurrence by defining hypovascular cellular habitats. The results of this assessment could be helpful in planning the next treatment option, especially localized therapy, surgery, or further SRS. This study has several limitations. First, the strict pathological confirmation of image-based segmentation is difficult. Only a few patients underwent surgery for the recurrence of brain metastasis. Accurate localization of brain metastasis recurrence is limited because of the surgical difficulty. Nonetheless, we attempted to demonstrate that the recurrence site matched the tumor habitat by analyzing serial MRI examination results. It is essential to establish biologically validated habitat imaging as a promising research field [28, 39, 40] by continuing to perform research and applying those results to solid tumors [41, 42] . Therefore, future studies are necessary to confirm the radiological and pathological correlations. Second, regarding structural MRI, the assignment of voxels to the enhancing habitat, solid low-enhancing habitat, or nonviable tissue habitat is based on logical assumptions. A tumor habitat analysis is a data-driven analysis that groups similar voxels within the CEL; however, this type of colocalization could be difficult to determine in clinical practice. In conclusion, an increase in the hypovascular cellular habitat observed using longitudinal physiological MRI was associated with the risk of recurrence (i.e., treatment resistance) and was indicative of the recurrence site. These results may be helpful for monitoring patients after SRS and determining future localized therapeutic targets. The Supplement is available with this article at https://doi.org/10.3348/kjr.2022.0492. The datasets generated or analyzed during the study are available from the corresponding author on reasonable request. Supplementary Fig. 1 . Determination of the optimal number of clusters for K-means clustering. The samples from the dataset were divided into groups with equal variance using k-means clustering. Structural MRI of habitats using three clusters showed differences in both T2WI and CE-T1WI results. However, four and five clusters showing narrow ranges were identified by emphasizing the T2WI and CE-T1WI results, respectively. Similarly, three clusters demonstrated differences in both ADC and nCBV values, whereas four and five clusters with constrained ranges were identified by emphasizing the ADC and nCBV results, respectively. Therefore, to prevent overparameterized models, the use of three clusters was considered ideal for identifying voxel-wise differences. ADC = apparent diffusion coefficient, CE = contrast-enhanced, nCBV = normalized cerebral blood volume, T1WI = T1-weighted imaging, T2WI = T2-weighted imaging Supplementary Fig. 2 . Prediction of recurrence using the hypovascular cellular habitat. A 60-year-old male with brain metastasis attributable to colon cancer was treated with SRS. A, B. The longitudinal physiological MRI analysis shows that the hypovascular cellular habitat increased (from 3972 voxels to 5857 voxels) whereas the other habitats decreased. C. Tumor recurrence was confirmed using kjronline.org aphasia, pain, hemichorea, parkinsonism, impaired decisionmaking, memory, freezing of gait, criminality, coma, and free will [15] . Reproducibility and specificity of lesion network mapping has been verified and confirmed accordingly [16, 17] . In our study, we intended to localize the neuroanatomical substrate of RBD by applying lesion network mapping to multiple focal brain lesions causing symptomatic RBD and to investigate the neuroanatomical locational relationship between RBD and α-synucleinopathy neurodegenerative diseases. In our study, PubMed was searched for articles including human RBD participants, which were written in English. The search was done in March 2021 using the following search terms: (Rapid eye movement (REM) sleep behavior disorder (RBD) OR Rapid eye movement sleep behavior disorder (RBD) OR REM sleep behavior disorder) AND (disease OR injury OR lesion OR tumor OR tumour OR stroke OR infarct OR hemorrhage OR haemorrhage OR bleeding OR traumatic) AND (case report OR case series). Initially, 139 studies were found in PubMed. Inclusion criteria were patients with RBD caused by a focal intraparenchymal lesion. Exclusion criteria included: 1) No CT or MRI; 2) extrinsic lesions oppress brain tissue without clearly delineated brain parenchyma damage; 3) poor image resolution and the location or boundary of the lesion could not be determined; 4) RBD without responsible lesions; 5) whole brain lesions and the responsible lesions could not be determined; and 6) genetic diseases leading to extensive brain lesions. After applying these criteria, 13 studies remained and three additional studies were found from a review of their references. Finally, a total of 19 cases were identified from 16 studies (Supplementary Table 1 ). All brain lesions were mapped by hand onto a standardized human brain atlas (2 x 2 x 2 mm 3 MNI space) according to the CT or MRI images in published studies using MRIcron software (https://people.cas.sc.edu/rorden/mricron/index. HTML). The location of the lesions in the standardized human brain atlas were determined by the anatomical landmarks on the original publication images. include laughing, gesturing, crying, or singing. Reported complex motor behaviors range from nonspecific repetitive twitching or jerking movements, to violent behaviors, including grabbing, punching, biting, kicking, or leaping from the bed, which can lead to injury or death of self or bedpartner. RBD can be categorized into idiopathic RBD (iRBD) and symptomatic (also known as secondary, such as brainstem tumors, stroke, vascular malformation, etc.) RBD. iRBD is characterized by a lack of definite neurological conditions, and multiple prospective studies have reported that most patients with iRBD will develop α-synucleinopathy neurodegenerative diseases, such as Parkinson's disease (PD), dementia with Lewy bodies (DLB), and multiple system atrophy (MSA) [2, [5] [6] [7] . The conversion rate increases significantly with the follow-up duration [8] . Additionally, RBD symptom is frequent in patients with α-synucleinopathy [9] . To date, why iRBD will convert into α-synucleinopathy has not been clearly defined. Multiple studies have been carried out to identify the neuronal network of REM sleep and the pathogenic mechanisms of RBD [10, 11] . In rodents, researchers found that many brain regions might be involved in REM sleep regulation, including the locus coeruleus (LC), sublaterodorsal nucleus (SLD), dorsal raphe nucleus, pedunculopontine nucleus, laterodorsal tegmental nucleus (LDTN), posterior lateral hypothalamus (PH), dorsal paragigantocellular reticular nucleus, ventrolateral periaqueductal gray (VLPAG), thalamus, substantia nigra, basal forebrain, and frontal cortex [3] . Based on animal models in cats and rats, Boeve et al. [4, 12] proposed that the SLD nucleus and its afferent or efferent pathways are the most likely pathophysiological basis for RBD, and found that dysfunction of this nucleus or its pathways caused by lesions, neurodegeneration, or pharmacologically-induced dysfunction can result in RBD. In humans, multiple studies reported that patients with lesions, including encephalitis, infarct, hemorrhage, and arteriovenous malformation, in the brainstem and other areas were associated with RBD [13, 14] . However, the specific pathogenic mechanisms of RBD in humans are still not clear. Recently, Fox [15] proposed a technique called lesion network mapping, which can be used to localize neural networks through multiple focal brain lesions causing neurological symptoms. This technique avoids the need to perform functional brain imaging on the patients themselves, and only brain lesion images are needed therein. Lesion network mapping has been applied to a variety of neuropsychiatric symptoms, such as auditory hallucinations, https://doi.org/10.3348/kjr.2022.0712 kjronline.org In the present study, lesion network mapping was applied to investigate the neuroanatomical substrate of RBD. Figure 1 shows the specific experimental process. The specific steps of data analysis refer to previous literature [18, 19] . Briefly, the brain lesion of each patient was used as a seed region of interest to calculate the functional connectivity (FC) of the lesion to all brain voxels by calculating the correlated time course between each lesion location and every other brain voxel in a resting-state FC MRI analysis using 1083 healthy subjects' resting-state functional magnetic resonance imaging (fMRI) data from the open access Human Connectome Project (HCP) S1200 data release [20, 21] . In our study, the minimizedpreprocessing resting-state fMRI data from 1083 healthy subjects were further analyzed including detrend, bandpass filter and global signal regression before calculating FC. In each brain lesion, these correlations for all 1083 subjects were then combined to calculate a T-score value for every individual voxel using a one-sample t tests. Binarized connectivity maps (positive and negative correlations separately) for each lesion were thresholded at a T value of ± 5 (uncorrected P < 6 × 10 -7 ). Finally, binarized connectivity maps from each brain lesion were overlaid to form the lesion network mapping to identify voxels connected to all or most lesion locations associated with RBD. Due to lack of MRI brainstem nuclei template, the positions of brainstem nuclei in this paper were manually drawn on the MRI standard brain template, by referring to the human brainstem atlas [22] . To test the specificity of lesion network mapping for RBD, we compared the lesion network mapping results of lesions causing RBD to two 'control' datasets of lesions causing criminal behavior and alien limb syndrome. Seventeen lesions causing criminal behavior, and 50 lesions causing alien limb syndrome, were separately obtained from previously published studies [16, 23] . A two-sample t test in Statistical Parametric Mapping (SPM12; http://www.fil. ion.ucl.ac.uk/spm/software/spm12/) was used to identify voxels significantly more likely to be connected with lesions causing symptomatic RBD compared to the two control lesions. Voxel-wise family-wise error (FWE) corrected P values less than 0.05 were considered significant group differences in the lesion network. The neuroimaging findings in iRBD were searched in PubMed through articles written in English using the search terms (Rapid eye movement (REM) sleep behavior disorder (RBD) OR Rapid eye movement sleep behavior disorder (RBD) OR REM sleep behavior disorder) AND (MRI or SPECT or PET) in April 2021, by identifying 227 studies. Abnormal brain structure, blood flow or metabolism in iRBD patients compared with healthy controls using PET, SPECT, or structural MRI, such as whole-brain cortical thickness, voxelbased morphometry, or diffusion-tensor imaging analyses, were included accordingly. In each study, functional lesions in iRBD were defined as injury, atrophy, or hypoactivity on functional neuroimaging compared to healthy controls, and the coordinates for functional lesions were extracted therein. A total of 13 studies met the requirements (Supplementary Table 2 ). All reported coordinates for each individual study were defined as 4-mm seeds and added together to create a combined seed [23] . Then, the combined seed for each study as a lesion was applied to calculate network mapping of iRBD using the identical procedure of lesion network mapping. We also tested the specificity of this network localization to regions involved in iRBD by comparing our results with neuroimaging findings in 13 studies of patients with free will [23] . Two-sample t tests in SPM12 were used to assess the group differences in network connectivity using an FWE-corrected P value less than 0.05. In addition, we investigated whether there were potential brain pathological alterations in iRBD by searching PubMed for articles with human subjects, written in English, using the search terms (autopsy OR histopathologic examination OR postmortem OR post-mortem OR immunohistochemistry OR neuropathological examination) AND (Rapid eye movement (REM) sleep behavior disorder (RBD) OR Rapid eye movement sleep behavior disorder (RBD) OR REM sleep behavior disorder) in April 2021 and found 67 studies. The inclusion criteria were patients with iRBD but with no other neurologic signs or symptoms. Finally, 2 cases met the inclusion criteria. We collected brain pathological sites in these studies (Supplementary Table 3 ) and verified the relationship between brain pathological alterations in iRBD and lesion network mapping for RBD. We further investigated the relationships between lesion network mapping for RBD and the brain pathological sites at preclinical stages in α-synucleinopathy, such as PD and DLB. Brain pathological sites at different clinical stages in PD and DLB were obtained from previous studies [5, 24] . Then, we detected the match degree of brain pathological sites at preclinical stages in α-synucleinopathy with lesion network mapping of RBD. https://doi.org/10.3348/kjr.2022.0712 kjronline.org in multiple brain sites in these patients. More importantly, these sites were also located at lesion network mapping for RBD (Supplementary Table 3 ). We detected the locational relationship between the lesion network mapping for RBD and the brain pathological sites at different clinical stages in PD and DLB by overlapping the brain network defined by connectivity to the pons and brain pathological sites at preclinical stages in PD and brainstem Lewy body disease in DLB. In PD, we found that all brain pathological sites (vagal dorsal motor nucleus, lower raphe nuclei, and LC) at preclinical stages (Braak stages 1-2) were involved in the brain network defined by connectivity to the pons (Fig. 7) . Similarly, in DLB, we found that all brain pathological sites (vagal dorsal motor nucleus, raphe nuclei, LC, substantia nigra, and pars compacta) at brainstem Lewy body disease were involved in the brain network defined by connectivity to the pons (Fig. 7) . In this study, we investigated the brain network of RBD using patient data obtained from systematic literature search and lesion network mapping, which can localize the brain network of lesion-induced symptoms and which has proven useful in the localization of multiple neurological syndromes [15] . Our results showed that more than 89% of the lesions were connected to the pons. By searching the Human Brain Stem Atlas, we found that the positive brain https://doi.org/10.3348/kjr.2022.0712 kjronline.org regions in the pons were located in the LC, dorsal raphe nucleus, central superior nucleus, and VLPAG. To verify the specificity of this result, we compared the FC of lesions causing RBD with that of the two control lesions causing other neurological syndromes. The results showed that these pontine-positive brain regions also survived. In addition, we validated the literature-based RBD lesion network mapping with data from an independent cohort of functional lesions in iRBD relative to healthy controls. Although these patients did not have focal brain lesions, the regions of focal injury, atrophy or hypoactivity on structural or functional neuroimaging in groups of patients with iRBD were defined as functional lesions. This method conformed to lesion network localization of free will [23] . We found that the sites of pons derived from focal brain lesions aligned well with the results from functional lesions. We further studied whether all the lesions causing RBD were located in the brain network defined by connectivity to the positive pons regions, including the LC, dorsal raphe nucleus, and VLPAG. We used positive pons regions as a seed to calculate whole-brain FC using resting-state fMRI data from 1083 HCP healthy subjects. We found the FC network defined by positive pons regions matched the brain network connectivity to more than 50% of lesions causing RBD. At the same time, all the lesions causing RBD are included in the brain network defined by positive pons regions. In animal experiments, damage to the LC, LDTN, and SLD have been reported to reproduce RBD in humans [11, 25, 26] . In addition, through experimental studies in rats and cats, the potential pathological circuit of RBD has been proposed [3, 12, 27] . During REM sleep, γ-aminobutyric acid (GABA)-ergic neurons located in the PH, the dorsal paragigantocellular reticular nucleus, and the VLPAG inactivate REM-inhibiting monoaminergic neurons in the tuberomammillary nucleus, LC, and dorsal raphe nucleus, and GABAergic neurons in the VLPAG to induce REM sleep. SLD glutamatergic/GABAergic neurons stimulate inhibitory spinal interneurons or glycinergic and GABAergic premotor neurons in the ventromedial medulla, resulting in skeletal muscle atonia. SLD neurons may be activated by cholinergic LDTN and pedunculopontine tegmental nucleus neurons. kjronline.org Cortical activation during REM sleep is restricted to a few limbic structures, including the retrosplenial cortex, medial entorhinal cortex, anterior cingulate cortex and dentate gyrus. In the present study, we found that all the positive pons regions, including the LC, dorsal raphe nucleus, and VLPAG, are involved in the key brain areas for RBD reported in animals. To further confirm reliability of lesion network map for RBD, we collected the pathological changes in brain sites reported in iRBD post-mortem by a literature search. We identified only two patients with iRBD who underwent autopsy [28, 29] . Pathological alterations, including neuronal loss, gliosis, Lewy bodies, and Lewy neurites, were detected mainly in the brain stem nucleus (such as LC, subceruleus nucleus, substantia nigra, dorsal raphe nucleus et al.). As expected, the brain sites of pathological alterations found in two patients with iRBD who underwent autopsy were also involved in lesion network mapping for RBD. Therefore, our findings suggested that the regulatory network loop of RBD in humans may be the brain network defined by connectivity to positive pons regions, including the LC, dorsal raphe nucleus, central superior nucleus, and VLPAG. Taken together, based on the lesion network mapping, we have deepened the understanding of the potential neuroanatomical substrate of RBD, and also made it possible to develop effective The most important implication of iRBD is its high phenoconversion to α-synucleinopathy neurological disease, including PD, DLB, and MSA. However, the underlying cause is still unclear. In the present study, based on the finding of regulatory network loop of RBD by lesion network mapping, we investigated the locational relationship between network loop of RBD and the brain location of pathological changes in the preclinical stage of α-synucleinopathy. We found that all brain pathological sites at preclinical stages (Braak stages 1-2) in PD and at brainstem Lewy body disease in DLB fell within the brain network defined by connectivity to the pons. In DLB staging, the determination of preclinical stage is controversial, but pure brainstem pathological changes cannot lead to the typical clinical manifestations of DLB [30] . In addition, in an autopsy study of multiple studies, with a large sample of PD patients, researchers found that PD patients with probable RBD may have a greater density and range of synuclein pathology in the LC, substantia nigra, cranial nerve nuclei IX/X, and basal amygdala, all of which fall within the brain network defined by connectivity to the pons [31] . To summarize, we determined that pathological changes in the early stage of α-synucleinopathy neurodegenerative diseases were located in the regulatory network loop of RBD, thus resulting in iRBD. This may explain why iRBD is highly transformed into α-synucleinopathy. With the development of brain pathological changes, the clinical features of PD, DLB, MSA, or other neurodegenerative diseases will gradually appear. Clinically, iRBD should be diagnosed early, and its etiology should be clarified subsequently. Patients with iRBD caused by α-synucleinopathy neurodegenerative diseases should be treated early to delay or block the progression of brain pathological changes in them. Our study is limited since several potential limitations of the lesion network mapping technique have been identified and addressed in previous studies [16, 18, 32, 33] . First, all lesion information comes from published images, which may be biased due to the impact of image quality when drawing lesion maps. Second, we do not have our own patient queue to further verify our experimental results. Furthermore, in the present study, specific positive nuclei or regions in the brainstem could not be reported due to the lack of a human brainstem nuclei atlas in MRI. To identify specific nuclei or regions in the brain stem, we compared the positive regions at the different brainstem levels with the human brainstem template, which may have some deviations. In conclusion, the brain network defined by connectivity kjronline.org to positive pons regions may be the regulatory network loop inducing RBD in humans. In addition, our results suggest that the underlying cause of high phenoconversion rate from iRBD to neurodegenerative α-synucleinopathy may be pathological changes in the preclinical stage of α-synucleinopathy located at the regulatory network loop of RBD. Chest radiograph (CR) is essential for the initial evaluation of acute respiratory diseases [1] [2] [3] [4] • E-mail: jmgoo@snu.ac.kr This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (https:// creativecommons.org/licenses/by-nc/4.0) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited. department (ED), where they pose a significant burden [5] . Although the number of CRs in the ED has increased significantly [6] , An expert radiologist may find it challenging to interpret CRs promptly [7] . Consequently, a computer- kjronline.org biased because of a lack of comparability between before and after implementation. Moreover, improving the accuracy of CR interpretation does not necessarily result in improvements in patient management, patient outcomes, or workflow efficiency [23] . Therefore, prospective, parallel, randomized clinical trials are necessary to determine the true impact of AI-CAD [24] . Therefore, this pragmatic, parallel, randomized controlled trial aimed to report the sensitivity and false-positive rate (FPRs) of chest radiograph interpretations with and without assistance from AI-CAD for diagnosing acute thoracic diseases in patients with acute respiratory symptoms who presented to the ED. Additionally, we aimed to investigate the effects of implementing AI-CAD on patient management in the ED. We conducted a parallel, open-label trial at an academic aided detection (CAD) device that assists physicians in identifying abnormalities in CRs has the potential to enhance the quality and efficiency of ED practice. Recent studies have reported that deep learningbased artificial intelligence (AI) algorithms can improve physician's interpretation accuracy [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] . Eventually, these AI algorithms were implemented as CAD devices in clinical practice [18] . In a previous retrospective study [19] , reinterpretation of CRs obtained in the ED using an AI algorithm enhanced the radiologist's sensitivity, indicating the potential of an AI-based CAD (AI-CAD) device. However, the performance and efficacy (i.e., enhancing the accuracy of physicians' interpretation) of AI-CAD have been evaluated primarily in retrospective, experimental settings, which cannot fully replicate the conditions of daily practice [12] [13] [14] [15] [16] [17] 20] . Although several studies have reported an increase in the accuracy of interpretation following the implementation of AI-CAD [21, 22] , the results of such ""before-and-after"" studies may be Fig. 1 . Flow diagram. A total of 3576 participants who met the eligibility criteria were enrolled in the trial. As a result of random allocation, 1761 and 1815 participants were allocated to the intervention group and control group, respectively. We also conducted three post-hoc subgroup analyses for participants with and without acute thoracic diseases (post-hoc subgroup analysis 1), participants with positive and negative artificial intelligence-based computer-aided detection (AI-CAD) results (post-hoc subgroup anslysis 2), and participants with chest radiographs from fixed and portable scanners (post-hoc subgroup analysis 3). https://doi.org/10.3348/kjr.2022.0651 kjronline.org tertiary referral hospital in South Korea (registered at the Clinical Research Information Service [https://cris.nih. go.kr]; registration number: KCT0005007). The Seoul National University Institutional Review Board (approval number: D-2002-169-1107) approved this trial and waived the participants' required informed consent. Participants were enrolled according to the following inclusion criteria (Fig. 1) : 1) patients aged ≥ 19 years who presented to the ED between June 15, 2020, and December 31, 2021; 2) patients with one of the following chief complaints at the time of the ED presentation: chills, cough, chest pain, dyspnea, fever, hemoptysis, and sputum; and 3) patients referred for CR using a dedicated examination protocol created for the trial. Patients who met the following criteria were excluded from the study: 1) severely ill patients with a Korean Triage and Acuity Scale (KTAS) level 1 [25] , 2) patients who visited the ED due to trauma, and 3) patients who were previously enrolled in the trial. The participants were randomly assigned to the intervention and control groups in a ratio of 1:1 (CR interpretation with and without AI-CAD, respectively). The radiologists, ED physicians, and outcome evaluators were aware of the assigned groups. The AI-CAD used in the trial (Lunit INSIGHT CXR, version 2.0.2.0; Lunit Inc.) was approved by the Korean Ministry of Food and Drug Safety of Korea as a tool to assist physicians with CR interpretation. AI-CAD analyzed a single frontal CR to determine the presence of pulmonary nodules, infiltration, and pneumothorax. The AI-CAD provided a heat map overlaid on the input CR to visualize the location of the identified abnormality, in addition to providing a probability score (0%-100%) for the presence of the identified abnormality (Figs. 2-4 ) [11] [12] [13] [14] [15] [16] [17] [18] [19] . A dedicated examination protocol was developed for the participants' systematic selection and distribution. Before the start of the trial, ED physicians were instructed to request CRs for eligible patients using a specific protocol. Randomization of the examination was automatically performed when CR was obtained and transferred to the institutional picture archiving and communication system (PACS, Infinitt M6, Infinitt Healthcare). PACS generated a five-digit random number for each CR automatically. CRs with random numbers that were odd and even were assigned to the intervention and control groups to conceal the allocation sequence. Subsequently, the PACS automatically processed the AI-CAD analysis for the CRs assigned to the intervention group. Consequently, the original CRs and AI-CAD results were uploaded to the PACS for the intervention group, while only the original CRs were uploaded for the control group. The random assignment and AI-CAD evaluations were completed within a few minutes of image acquisition, allowing the radiologists and ED physicians to compare AI-CAD results with the original CR images without requesting additional AI-CAD analyses (Fig. 5) . During the study period, all CRs were interpreted in the ED by duty trainee radiologists in their third year of the residency, with each exam read by a single reader. CR interpretation used a standardized reporting form (Fig. 6 ). kjronline.org any abnormality indicating the presence of acute thoracic disease. The duty trainee radiologist can access the electronic report template directly from the PACS, and the generated standardized report can be transferred to the PACS. Before the start of the trial, radiology residents were instructed to use the standardized report for the trial-specific examinations and to review the AI-CAD results for CRs of the intervention group participants. As with the current process in the ED, duty trainee radiologists provide immediate interpretation if the ED physician requests formal interpretation. Otherwise, duty trainee radiologists interpreted the CRs at their own pace before the duty shift. ED physicians could evaluate CR images (with AI-CAD results for the intervention group) even before obtaining the radiologist's interpretation to make clinical decisions regarding participants' management. Workflow in the ED and participants' management adhered to the ED's standard procedure. Patients who visited the emergency department (ED) with acute respiratory symptoms and underwent chest radiographs (CRs) with the dedicated exam protocol were systematically enrolled for the trial. After the transfer of the CR image to the institutional picture archiving and communication system (PACS), a random number for allocation of the CR was automatically generated by the PACS. For the CRs allocated to the intervention group, artificial intelligence-based computer-aided detection (AI-CAD) analyses were automatically processed. All CRs in both the intervention and control groups were evaluated by duty trainee radiologists and or ED physicians, and other patient managements followed existing practice in the ED. After at least 30 days after discharge from the ED, a thoracic radiologist reviewed medical records to confirm the diagnosis of any acute thoracic disease. CT = computed tomography https://doi.org/10.3348/kjr.2022.0651 kjronline.org The primary outcome was the sensitivity of CR interpretation by duty trainee radiologists for any acute thoracic disease that could explain the participants' chief complaints during their ED visits. The FPR of the CR interpretation was investigated as a secondary outcome. One investigator E.J.H (a thoracic radiologist with 11 years of experience), reviewed the participant's medical records at least 30 days after their ED visit to define the reference standard for the presence of any acute thoracic disease. The ED medical records, and any follow-up records, radiological, and laboratory test results, were comprehensively evaluated to determine whether acute thoracic disease could explain the participants' chief complaints during ED visits. The process of defining the standard of reference is described in details in (Supplementary Material 1) . The following participant management efficiency and effectiveness outcomes were investigated: 1) turn-around time (TAT) of CR interpretation, 2) frequency of chest CT acquisition in the ED, 3) TAT to decide on CT acquisition, 4) TAT to decide on antibiotic administration, 5) TAT to refer participants to departments other than the emergency medicine department, 6) length of stay in the ED, and 7) rate of revisiting the ED within 30 days with the same complaint. Each study's endpoint is described in Supplementary Material 2. Based on the results of our previous retrospective study, a sample size estimation was conducted before participant enrollment [19] . The target sample size was 4862 participants (2431 participants in each group). The procedure for estimating sample size is described in Supplementary Material 3. We intended to enroll participants Fig. 6 . Template for preparing standardized reports for chest radiographs (CRs). CRs were interpreted using a standardized reporting format for both the intervention and control groups. A duty radiologist could call a simple dedicated program to enter the standardized report from the picture archiving and communication system (PACS). The standardized report had the following components: 1) presence versus absence of any abnormality suggesting acute thoracic diseases; 2) description of an abnormality suggesting acute thoracic diseases in three subcategories: pulmonary parenchymal abnormalities, pleural abnormalities, and other abnormalities; and 3) any recommendations for emergency department physicians. The radiologist could easily transfer the generated report from the program to the PACS. ID = identification, RN = random number, CT = computed tomography https://doi.org/10.3348/kjr.2022.0651 kjronline.org until the sample size was reached or until December 31, 2021, whichever came first. We did not conduct any intermediate analysis. To compare study outcomes between the intervention and control groups, we first compared the crude outcome values using the chi-square test and t-test. We used mixed-effect models to evaluate the association between CR interpretation using AI-CAD and study outcomes while adjusting for confounding variables. Radiologists who interpreted CR were included as a random effect; however, participants' age and sex, chief complaint of visiting the ED, triage results by the KTAS [25] , time of ED visit (weekdays vs. weekends [Saturday, Sunday, national holidays, and closed days of the institution], daytime [8:00 AM to 6:00 PM] vs. nighttime), and type of scanner (fixed vs. portable scanner) were included as fixed effects. We performed post-hoc subgroup analyses to investigate the study outcomes in subgroups of participants divided according to the reference standard (with and without thoracic disease), AI-CAD results (positive and negative results), and CR scanner types (fixed and portable). We compared the sensitivity and FPR of standalone AI-CAD to those of radiologists' interpretations using McNemar's tests. After stopping participant enrollment, the AI-CAD results of the CRs of the control group participants were obtained for post-hoc analyses and outside participant management. R software (version 3.6.3, R Project for Statistical Computing) was used to perform all statistical analyses. P < 0.05 was considered to be statistically significant. In this trial we enrolled 3576 patients (male-to-female ratio, 1966:1610; mean age, 64 years) between June 15, 2020, and December 31, 2021. Of the 3576 patients, 1761 and 1815 were allocated to the intervention and control groups, respectively (Fig. 1) . Table 1 shows the demographic and clinical information of the participants. The participants' CRs were interpreted by one of the 20 trainee radiologists. The median number of CRs, each radiologist, interpreted was 243 (range, 1-328). Table 1 shows abnormalities suggesting any acute thoracic diseases were noted in 32.1% and 31.3% of the CRs in the intervention and control groups, respectively. According to the reference standard, acute thoracic diseases were present in 26.8% and 27.1% of participants in the intervention and control groups, respectively. The most common acute thoracic disease was pneumonia (n = 669) (Supplementary Table 1 ) The sensitivities of CR interpretation, the primary outcome of the trial, was 67.2% (317/472) and 66.0% (324/491) in the intervention and control groups, respectively. After adjusting for potential confounding variables, there was no association between the use of AI-CAD for interpretation and sensitivity (adjusted odds ratio [OR], 1.02; 95% confidence interval [CI], 0.70-1.49; P = 0.917). The FPRs for CXR interpretations were 19.3% (249/1289) and 18.5% (245/1324) in the intervention and control groups, respectively. The FPR was not significantly associated with the use of AI-CAD (adjusted OR, 1.00 [95% CI, 0.79-1.26]; P = 0.985) ( Tables 2, 3 ). Supplementary Table 2 shows the sensitivity and FPR of each radiologist on duty. Approximately 44.7% and 46.8% of the participants in the intervention and control groups underwent chest CT, respectively (adjusted OR, 0.90 [95% CI, 0.76-1.06]; P = 0.194). The TAT to decide on CT acquisition was slightly longer in the intervention group (159 vs. 138 min; P = 0.043 [for comparison of crude values]); however, the association with AI-CAD use was not statistically significant (P = 0.090) after adjustment for confounding variables. AI-CAD was not associated with TATs to decide on antibiotic administration and refer participants to other departments (Table 2) . After ED visits, 42.5%, 39.1%, and 17.8% of participants were discharged home, admitted to the hospital, and transferred to other institutions, respectively (Table 1 ). AI-CAD was not associated with the length of stay in the ED (968 [intervention group] vs. 972 min [control group]; P = 0.919) and the rate of revisiting the ED within 30 days (6.7% [intervention group] vs. 6.6% [control group]; adjusted OR, 1.02 [95% CI, 0.78-1.32]; P = 0.912) ( Table 2 ). In the subgroup of participants with acute thoracic diseases (472 vs. 491 participants in the intervention and control groups, respectively) No study outcome was associated with using AI-CAD, while the crude TAT to decide on CT acquisition (167 vs. 130 min; P = 0.027) and to refer participants to other departments (347 vs. 296 min; P = 0.034) https://doi.org/10.3348/kjr.2022.0651 kjronline.org were slightly longer in the intervention group. No study outcome was associated with using AI-CAD in the subgroup of participants without acute thoracic diseases (n = 1289 and 1324 participants in the intervention and control groups, respectively) (Supplementary Table 3 ). AI-CAD was significantly associated with a longer TAT than conventional interpretation to decide on CT acquisition (162 vs. 138 min; P = 0.047) in the subgroup of participants with positive AI-CAD results (1252 and 1277 participants in the intervention and control groups, respectively). No study outcome was associated with using AI-CAD In the subgroup of patients with negative AI-CAD results (509 and 538 participants in the intervention and control groups, respectively) ( Supplementary Table 4 ). In the subgroup of participants who underwent CRs with fixed scanners (1220 and 1227 participants in the *Numbers indicate mean ± standard deviation, † Numbers in parentheses indicate the number of participants, ‡ Includes respiratory difficulty and dyspnea on exertion, § Includes chest wall pain and pleuritic chest pain, ǁ Includes blood-tinged sputum, ¶ Potential threats to life, limb, or body function, and quick intervention is needed, **Conditions that can lead to serious problems that potentially require emergency intervention. Significant discomfort or influence on physical function that affects work or everyday life, † † Patient age, condition associated with the possibility of pain or worsening, and complications, ‡ ‡ Conditions caused by chronic diseases, § § Daytime indicates 8:00 AM to 6:00 PM. Weekends include Saturday, Sunday, national holidays, and the official closed day of the institution. AI-CAD = artificial intelligence-based computer-aided detection; CR = chest radiograph https://doi.org/10.3348/kjr.2022.0651 kjronline.org intervention and control groups, respectively), using AI-CAD was significantly associated with a longer TAT than conventional interpretation to decide on CT acquisition (176 vs. 149 min; P = 0.018). In the subgroup of participants who underwent CRs with portable scanners (541 vs. 588 in the intervention and control groups, respectively), no study outcome was associated with using AI-CAD, although the crude length of stay in the ED was slightly shorter in the intervention group (690 vs. 829 min; P = 0.034) (Supplementary Table 5 ). kjronline.org Stand-Alone Performance of the AI-CAD AI-CAD identified abnormal findings in 70.8% of the CRs. Positive AI-CAD results demonstrated a sensitivity of 95.3% and an FPR of 61.7%. The sensitivity and FPR of AI-CAD were significantly higher than those of radiologists on duty (sensitivity, 66.6% [P < 0.001]; FPR, 18.9% [P < 0.001]), respectively. The differences between AI-CAD and radiologists were consistent in the intervention and control groups and in the CRs from the fixed and portable scanners (Supplementary Table 6 ). In this single-center pragmatic randomized controlled trial, we found no association between using AI-CAD for CR interpretation and the sensitivity (67.2% [intervention group] vs. 66.0% [control group]; odds ratio, 1.02; P = 0.917) or FPR (19.3% vs. 18.5%; OR, 1.00; P = 0.985) of duty trainee radiologists' interpretations for the diagnosis of acute thoracic diseases in patients who presented at the ED with acute respiratory symptoms. Furthermore, although ED physicians were provided with AI-CAD results, using AI-CAD was not associated with workflow efficiency and clinical decision-making outcomes. Several retrospective studies have suggested that using AI-CAD can improve the diagnostic accuracy of physicians' interpretations [12] [13] [14] [15] [16] [17] 20] . In our previous study, reinterpretation of CRs using AI-CAD significantly increased sensitivity from 65.6% to 73.4% for detecting referable abnormalities in consecutive baseline CRs obtained in the ED [19] . However, in this prospective, pragmatic clinical trial, conducted in the same institution with the same AI-CAD, the sensitivity and FPR of CR interpretation by radiologists on duty did not differ between interpretation with and without AI-CAD. CR interpretation environments could be the primary cause of this difference. In a retrospective reader test, AI-CAD tended to influence the reader's interpretation, particularly when they were informed that they were participating in a study investigating the efficacy of AI-CAD. However, in realworld practice, radiologists may tend to maintain their own opinions because they are accountable for the outcomes of their interpretations [26] . The diminished performance of AI-CAD in real-world practice may be another reason for its reduced efficacy. In our trial, AI-CAD showed a high FPR (61.7%), which was higher than that in the retrospective study (9.7% or 30.4% according to the threshold definition) [19] . This high FPR may have negatively impacted the interaction between AI-CAD and radiologists despite the high sensitivity (95.3%) [27] . Because patient management in the ED and patient outcomes are influenced by factors other than CR results [28] , it may be challenging to demonstrate an improvement in workflow efficiency or patient outcomes by using AI-CAD for CR interpretation alone [21] . In our study, most workflow efficiency secondary outcomes did not differ between the intervention and control groups. In the subgroup of participants with positive AI-CAD results and those who underwent CRs with fixed scanners, the TAT to decide on CT acquisition was slightly longer in the intervention group than in the control group ( Supplementary Tables 4, 5) . Further studies are required to confirm the impact of AI-CAD on clinical decision-making and its efficacy. There are some limitations to this study. First, because this was a single-center trial conducted at an academic tertiary referral institution, the generalization of our findings remain uncertain. Second, our trial was conducted during the coronavirus pandemic when the emergency department's workflow was significantly impacted. Consequently, the reproducibility of our results in the ED workflow following the end of the pandemic is uncertain. Thirdly, the medical record defined the reference standard for the presence of acute thoracic disease, which might have been influenced by the practice of ED physicians and the subjective opinion of radiologists during the medical record review. Fourth, the CRs were interpreted by trainee radiologists on duty. Therefore, the reproducibility of the results when the CRs are interpreted by readers with various years of experience remains uncertain. Finally, the number of participants included in our trial fell short of the targeted sample size (3576/4862; 73.5%), thereby reducing the statistical power of the study. In conclusion, using AI-CAD for interpretating chest radiographs did not improve the sensitivity and FPR for diagnosing acute thoracic diseases in patients who presented to the ED with acute respiratory symptoms. Furthermore, the use of AI-CAD by ED physicians did not affect workflow efficiency and clinical decision-making in the ED. To enhance the value of AI-CAD in real-world practice, a more specific real-world optimized strategy for implementing AI-CAD in practice and an improvement in the performance of AI-CAD may be required. *Includes pulmonary tuberculosis, pulmonary fungal infection, and coronavirus disease with pneumonia, † Includes hemoptysis due to bronchiectasis, tuberculosis sequelae, lung cancer, and diffuse alveolar hemorrhage, ‡ Includes pleural empyema, tuberculous pleurisy, autoimmune-disease-related pleuritis, and chylothorax after thoracic surgery, § Includes drug-related pneumonitis and acute eosinophilic pneumonia, ǁ Includes rib fracture, ruptured thoracic aortic aneurysm, esophagitis, esophageal rupture, mediastinitis, endobronchial foreign body, cardiac tamponade due to malignant pericardial effusion, superior vena cava obstruction, and pulmonary artery pseudoaneurysm. ILD = interstitial lung disease, COPD = chronic obstructive pulmonary disease Complications after Transarterial Treatment of HCC [31] 84/M Locus ceruleus, substantia nigra, mesencephalic reticular formation, dorsal raphe nucleus, central superior nucleus, pedunculopontine nucleus, caudal and oral pontine reticular nuclei in the pons, dorsal vagal nucleus, gigantocellular reticular nucleus, ventral reticular nucleus of the medulla oblongata, nucleus basalis of Meynert, hypothalamic nuclei, and mamillary bodies M = male",
Publication,PUBLICATION_SEARCH_SNIPPET,Unlocking the power of generative AI models and systems such as GPT-4 and ChatGPT for higher education: A guide for students and lecturers,"['H Gimpel', 'K Hall', 'S Decker', 'T Eymann', 'L Lämmermann']",2023,NA,"Besides ChatGPT, other conversational agents and applications using large language models   relevant for large language models and other generative AI systems in higher education.",False,28,https://www.econstor.eu/handle/10419/270970,"['931NpjQAAAAJ', '', 'uhVkSswAAAAJ', '_3iS3B8AAAAJ', '']",/scholar?q=info:Ox1RPm1C2L4J:scholar.google.com/&output=cite&scirp=27&hl=en,"/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522large%2Blanguage%2Bmodels%2522%2B%252B%2522higher%2Beducation%2522%26hl%3Den%26start%3D20%26as_sdt%3D0,33%26as_ylo%3D2000%26as_yhi%3D2023&citilm=1&update_op=library_add&info=Ox1RPm1C2L4J&ei=zxeNZOtT5NSxAtLEl6AD&json=",3,"/scholar?cites=13751814499140181307&as_sdt=5,33&sciodt=0,33&hl=en",https://www.econstor.eu/bitstream/10419/270970/1/1840457716.pdf,"""large language models"" +""higher education""",Ox1RPm1C2L4J_2023_Unlocking the power of generative AI models and systems such as GPT-4 and ChatGPT for higher education: A guide for students and lecturers,362d971314c74169a973df0c32ca6e27,"A Guide for Students and Lecturers This is where this whitepaper comes in. It looks at ChatGPT as a contemporary example of a conversational user interface that leverages large language models. The whitepaper looks at ChatGPT from the perspective of students and lecturers. It focuses on everyday areas of higher education: teaching courses, learning for an exam, crafting seminar papers and theses, and assessing students' learning outcomes and performance. For this purpose, we consider the chances and concrete application possibilities, the limits and risks of ChatGPT, and the underlying large language models. This serves two purposes: • First, we aim to provide concrete examples and guidance for individual students and lecturers to find their way of dealing with ChatGPT and similar tools. • Second, this whitepaper shall inform the more extensive organizational sensemaking processes on embracing and enclosing large language models or related tools in higher education. We wrote this whitepaper based on our experience in information systems, computer science, management, and sociology. We have hands-on experience in using generative AI tools. As professors, postdocs, doctoral candidates, and students, we constantly innovate our teaching and learning. Fully embracing the chances and challenges of generative AI requires adding further perspectives from scholars in various other disciplines (focusing on didactics of higher education and legal aspects), university administrations, and broader student groups. Overall, we have a positive picture of generative AI models and tools such as GPT-4 and ChatGPT. As always, there is light and dark, and change is difficult. However, if we issue clear guidelines on the part of the universities, faculties, and individual lecturers, and if lecturers and students use such systems efficiently and responsibly, our higher education system may improve. We see a great chance for that if we embrace and manage the change appropriately.  About the Projects ABBA, DeLLFi, and S3G ABBA stands for ""AI for Business | Business for AI."" It is a publicly funded joint project to establish a cross-university, modular offer for developing AI competencies of students in management, business administration, economics, information systems, and related fields. Using artificial intelligence (AI) technologies in business requires specific skills. In addition to technical expertise, the business world requires knowledge to embed AI technologies in business processes, work systems, products and services, design and evaluate business cases, and manage AIbased information systems in the long term. This bridge-building role falls primarily to managers as the central decision-makers in the company. Therefore, the joint project's target group includes business administration, information systems, and other courses of study relating to socio-economic and socio-technical topics. The goals of the joint project are developing and providing a modular teaching toolkit for AI, which teaches business students interdisciplinary AI competencies in a scientifically sound and practiceoriented manner. The modular toolkit supports teaching for bachelor, master, executive master, and doctoral students at research universities and universities of applied sciences. To achieve that goal, the joint project unites twelve professorships from three research universities and one university of applied sciences, who share the focus on supporting the development of AI competencies: University of Hohenheim, University of Bayreuth, Frankfurt University of Applied Sciences, Karlsruhe Institute of Technology. Fraunhofer FIT is an associated partner. Teaching contents and formats are jointly developed, mutually used, and in part made publicly available. Compared to individual creation by each university and professorship, this substantially strengthens the breadth and depth of the offering and the efficiency and quality of teaching. The German Ministry of Education and Research and the State ministries for science in Baden-Württemberg, Bavaria, and Hesse support ABBA financially. DeLLFi is a project at the University of Hohenheim funded by the Foundation for Innovation in University Teaching. It stands for integrating digitalization along teaching, learning, and research. The project integrates three departments of the Faculty of Business, Economics and Social Sciences, the CareerCenter Hohenheim, and, with the Office for University Didactics and Humboldt reloaded, two organizational units that support teaching. ""Would ChatGPT get a Wharton MBA?"" This headline circulated in the media at the beginning of 2023, causing universities worldwide to sound the alarm, but also justified? On March 14, 2023, OpenAI launched GPT-4 as a model that can power ChatGPT. This substantially improves performance over what has been discussed regarding ChatGPT over the last months. GPT-4 markedly outperforms the previous model GPT-3.5, for example, by scoring a higher approximate percentage among test takers on the uniform bar exam (OpenAI, 2023b) . This underscores the relevance of whether ChatGPT based on GPT-4 would get a Wharton MBA or other degrees. ChatGPT is an artificial intelligence (AI)-based conversational agent that can write college-level essays. ""Conversational agent"" is an umbrella term for software that uses natural language to interact with its user, either text-based (as chatbots) or speech-based (as virtual assistants) (Gnewuch, Morana, & Mädche, 2017; McTear, Callejas, & Griol, 2016) . Due to recent technological advances in AI, conversational agents are already used in some contexts (Feidakis et al., 2019) . Even before the release of ChatGPT, higher education has been an emerging application area for the deployment of conversational agents (Al Muid et al., 2021) . These tools can provide the advantages of being permanently available, scalable, and location-independently accessible, leveraging the potential to address multiple learners' concerns simultaneously while adapting to their individual needs (Elshan & Ebel, 2020; Hobert, 2019) . Then came ChatGPT. OpenAI launched ChatGPT as a research preview on November 30, 2022. ChatGPT has already reached a new level of conversation between humans and conversational agents since it was introduced with GPT-3.5 as the underlying model. Now GPT-4 further expands this. Despite the general knowledge of the potentially disruptive power of conversational agents in higher education, ChatGPT brought the discussion to a new level for several reasons. The quality of results produced by the underlying large language models exceeds what most people thought possible. ChatGPT, as a user interface to these models, is very easy to use for most people. OpenAI offered access to ChatGPT for free. In effect, many people who had not interacted with conversational agents before or perceived them as relatively unsophisticated machines could get first-hand experience with an advanced conversational agent generating stunningly high-quality texts. This swirled up the field of higher education and many other domains within just a couple of weeks. Much of higher education is teaching and learning how to apply state-of-the-art knowledge and create meaningful, valuable new knowledge. Both application and creation of knowledge frequently manifest in text, images, or other representations that can be easily communicated, stored, processed, and the like. Generative AI systems can generate text, images, or other representations with relatively little human input. Hence, it is not surprising that the advent of generative AI fundamentally challenges accepted knowledge, assumptions, and behaviors in higher education. Questions arise regarding the division of labor between humans and machines, learning goals, and forms of assessing student performance. Large language models are a specific machine learning approach with superior performance on NLP tasks (OpenAI, 2023c; Vaswani et al., 2017) . GPT-4 is an example of such large language model. Such models and the systems built on top of them, like ChatGPT, are impressive but disputed. After its release, ChatGPT became the fastest-growing consumer application in history, reaching over 100 million monthly users just two months after launch (Hu, 2023) . The media has dubbed ChatGPT as part of ""the generative-AI eruption"" (Benson, 2023) that may revolutionize the way we work, think, and approach human creativity (Benson, 2023) . However, opinions from the context of higher education demonstrate a sharp divide between those who are enthusiastic about the technology and those who are heavily concerned. Professor Ute Schmid from the University of Bamberg pointed out that the GPT-3 model has a deeper problem: the inability to trace the sources of each statement and the process used to create them (Schmidt, 2023) . Professor Jochen Schiller from the Free University of Berlin further highlighted that the program sometimes produces nonsensical output (Schiller, 2023) . Decker (2022) suggested: ""If people using the generated material are not careful and responsible (and let us be honest, not everyone is), we may be flooded with a barrage of half-truths, misrepresentations, and simply falsehoods, all of which seem plausible and are written using perfect language."" Despite these concerns, there is a broad consensus that ChatGPT can potentially transform how we learn and teach, as it can be utilized for various applications, including writing, translation, professional communication, and personalized learning (Atlas, 2023) . This whitepaper is relevant beyond ChatGPT. ChatGPT is a specific user interface for specific large language models. We frequently refer specifically to ChatGPT, which is at the forefront of the current debate among students, lecturers, and other higher education stakeholders. Besides ChatGPT, other conversational agents and applications using large language models have similar or complementary text processing and generative capabilities. Further, numerous other AI tools support other aspects of teaching and learning. An excellent overview of tools for text generation, text translation, audio-to-text transcription, image generation, image manipulation, slide generation, audio and music generation, audio and music processing, video generation and processing, programming, mathematics, and other elements of learning and teaching is provided by Professor Albrecht Schmidt from LMU Munich at https://www.hcilab.org/ai-tools-directory/. The frequent and specific discussion of ChatGPT in this whitepaper should not obscure the consideration that many of the aspects and recommendations we discuss here are more broadly relevant for large language models and other generative AI systems in higher education. A brief look at the history of higher education and experience from other domains shows that expected innovations are often exaggerated in the short run (Rudolph, Tan, & Tan, 2023) . A recent example are MOOCs (Massive Open Online Courses). Although they have been called ""the death of higher education"" (Rudolph, 2014) , the present shows that university courses and certificates continue to be highly valued by students (Rudolph et al., 2023) . So, what does the rise of AI tools, as another relevant digital innovation step, mean to higher education? First and foremost, we should not make either of two possible mistakes: For one, we should not panic in light of questions about whether such systems would pass university entrance tests, whether they would get an MBA, or whether they annul the relevance of university lectures, exams, or master theses. Further, we should not neglect their importance for higher education and prohibit their use. It is good that students no longer write their theses using pen and paper or a typewriter. It is good that they do not calculate all statistics by hand or with a pocket calculator. Spell check and grammar support or auto-completion of words by Microsoft Word's built-in editing functions are standard. Likewise, using advanced, machine learning (ML)-based translation programs such as DeepL Translator or Google Translate is standard. Grammarly, DeepL Write, Hemingway, and other NLP-based services improve linguistic quality. Google Scholar algorithmically supports navigating the scholarly literature. Software such as R, Stata, and SmartPLS support data analytics. Software libraries, software development environments, and online discussion forums support students in developing software code. Both students and lecturers routinely use these tools, anddespite some potential downsidesthe net effect of using such IT tools in higher education is overwhelmingly positive. Some stakeholders in higher education discuss whether the use of ChatGPT by students should be prohibited. Others counter that it should not be prohibited because universities cannot monitor and enforce the ban. The latter is true, but it is not the primary reason why ChatGPT should not be banned. The primary reason is that ChatGPT and other generative AI tools can improve higher education. They have become part of the everyday life for lecturers and students in their domains of life beyond higher level education. Therefore, we should all join forces to ensure these students are as prepared as possible for their future careers. At the university, students need to learn how to use ChatGPT and similar tools purposefully, productively, and responsibly. We should neither panic nor wait calmly and prevent innovation. Instead, we should focus on how we can innovate education to harvest the potential of AI in teaching and learning. In this whitepaper, we reflect on the tremendous opportunities of generative AI tools in higher education and the potentially harmful effects of their increasing use. The whitepaper can guide students and lecturers to reflect on their learning and teaching to make sense of the generative AI disruption in higher education. To this end, we focus on the ""teaching-learning trifecta"" between students, lecturers, and technological tools. We focus on teaching courses, learning for exams, writing seminar papers and theses, and assessing student learning and performance. Further potential for using large language models exists throughout the student lifecycle and in other areas of higher education administration and operations. Overview on Generative AI, Large Language Models, and ChatGPT 2. Overview on Generative AI, Large Language Models, and ChatGPT One of the most relevant conversational agents right now is ChatGPT, a tool released by the US company OpenAI on Nov. 30, 2022. Before we go into more detail about why ChatGPT has gained so much attention in a relatively short time, we will first go into the technical basics of ChatGPT and clarify terms and key constructs accordingly. The relation of these constructs is sketched schematically in Figure 1 . Artificial intelligence (AI) is a broad field encompassing various techniques and approaches to create intelligent machines that perceive their environment and take actions. Machine learning is a subfield of AI that allows computers to learn and improve their performance on a task without being explicitly programmed using algorithms that can identify patterns and make predictions based on data. Generative AI refers to AI systems that generate new data or outputs, such as images, music, or text, rather than classify or process existing data. Typically, generative AI uses machine learning. Large language models (LLMs) are a type of machine learning model that can process and generate natural language text. LLMs are a type of generative AI because they can produce novel text outputs based on patterns and learn from large amounts of input data. Conversational agents, also known as chatbots or virtual assistants, are AI systems designed to engage in natural language conversations with humans. Conversational agents can use LLMs as a component to generate text responses that mimic human-like language and style. ChatGPT is a conversational agent that uses the LLM GPT-3.5 or GPT-4. GPT stands for Generative Pre-Trained Transformer. It is OpenAI's acronym used in the name of large language models trained on data available on the Internet. The earliest of such models, GPT-1, was published by OpenAI in 2018; the most recent one -GPT-4on March 14, 2023. ChatGPT is a user interface to the models GPT-3.5 and GPT-4. The free ChatGPT research preview allows access to GPT-3.5. Since March 14, 2023, the fee-based premium version ChatGPT Plus additionally provides access to GPT-4. The GPT models are also available via an application programming interface (API). In Machine learning technology is used in software systems to develop models which are embedded in other software systems, such as conversational agents or word-processing software. Innovation in higher education does not come from technology or models in general but from using software systems built on top of technologies and models. Figure 2 provides a rough sketch of this interrelation of technologies, models, and systems. The specific software systems, like ChatGPT, are essential for students and lectures. Hence, we frequently refer to ChatGPT as a specific example of a generative AI system. ChatGPT is impressive and topical. However, it is neither the only nor the last generative AI system. Hence, university policies should not clarify the use of ChatGPT specifically but generative AI systems in general. From technology over IT systems to IT use Gimpel, H., Hall, K., Decker, S., Eymann, T., Lämmermann, L., M ädche, A., Röglinger, R., Ruiner, C., Schoch, M ., Schoop, M., Urbach, N., Vandirk, S. (2023 (Fried, 2023) . One main advantage of large language models such as GPT-3.5 and GPT-4 underlying ChatGPT is their ability to process and contextualize text information and generate appropriate responses (Susnjak, 2022) . GPT-3.5 is purely text-based: it accepts text input and produces text output. This text can be natural language or computer code. Beyond that, GPT-4 also accepts images as part of the input prompt. That could be documents with text and photographs, diagrams, or screenshots (OpenAI, 2023a). Hence, GPT-4 includes elements of computer vision and is more than a pure large language model. The models' performance and accuracy are significantly affected by the difference in the number of model parameters and the training data size. A larger training dataset leads to a more extensive and diverse language model, resulting in enhanced proficiency. According to OpenAI, GPT-3.5 is based on a deep neural network model with 175 billion parameters, which are adjusted through machine learning (Vogelgesang, Bleher, Krupitzer, Stein, & Jung, 2023 ). In contrast to the previous models from OpenAI, GPT-1 and GPT-2, which aimed to generate human-like conversations, GPT-3 was already considered the most advanced and capable of the models due to its significantly larger size and the scaling up of data and parameters used in its training (Shreya, 2023) . GPT-3.5 is the successor of GPT-3. GPT-4 is the next evolutionary step. Both models work in English, German, and many other languages. According to OpenAI (2023a), they applied GPT-3.5 and GPT-4 to bar exams designed for human test takers. GPT-3.5's score was around the bottom 10% of humans typically taking the exam. GPT-4's score is more around the top 10% of test takers. However, as any IT system (and any human), ChatGPT and the underlying models are not perfect. One fundamental limitation to keep in mind is that while the output might sound convincing, it is not necessarily factually correct. The GPT models and, hence, ChatGPT sometimes ""hallucinate."" Natural text, academic references and the like might look perfect at first sight but lack truth or refer to non-existent objects or prior texts. For example, it may make up fake academic papers using new configurations of existing titles, outlets, and authors (Smerdon, 2023) . While this concern applies to all GPT models, our initial tests suggest that GPT-4 has substantially fewer hallucinations than GPT-3.5. One of the essential features of GPT-3.5 and GPT-4 is their capability to consider contextual information of a conversation when generating the response. This allows ChatGPT to maintain a conversational flow, yet its ability to maintain that flow continuously is limited. This is possible using a socalled ""self-attention mechanism"" (OpenAI, 2023c; Vaswani et al., 2017) , meaning that the models can weigh the importance of different words and phrases in the input text based on their perceived relevance. The extent of the models' context is given by the number of so-called input tokens. GPT-3.5 has a token limit of around 4,000 tokens (relating to about 3,000 words in the prompts and the model's answers), GPT-4 an impressive 32,000 tokens. Hence, GPT-4 is substantially more robust in considering context affecting the length of text that can reasonably be generated. Based on GPT-3.5, ChatGPT candepending on the topic and the promptreasonably produce a paragraph of text or a few paragraphs. Leveraging GPT-4, ChatGPT can potentially produce entire chapters. It is easy to foresee that such models will eventually be able to create text in the length of a whole bachelor's or master's thesis. However, even if the text is linguistically perfect, its content does not necessarily show the same quality. Furthermore, ChatGPT cannot fully appreciate the nuances of subtleties of a conversation since it is still a machine learning model and is just trained on large amounts of input data (Azaria, 2022) . A benefit of ChatGPT is its easy application, which is possible through a simple user interface that does not require knowledge of using an API ( Figure 3 ). ChatGPT is a ready-to-use service made available as a dialogue system with which one can easily interact. Immediately after prompting ChatGPT, the user is presented with relevant information about the topic of interest. Currently, OpenAI provisions ChatGPT based on a freemium pricing model: ChatGPT usage is free of charge if the user accepts GPT-3.5 as the underlying model, somewhat tardy replies, and non-availability at times of high demand. A premium version with higher capacity is now available for a fee to handle a large volume of requests while ensuring fast response times. Further, the premium version allows access to GPT-4 with its advanced ability to consider context and the option for image-based prompts. Microsoft and others use the API provided by OpenAI to integrate the large language models in other software systems beyond ChatGPT. The potential applications of ChatGPT are extensive. Particularly in higher education, its capability to comprehend and react naturally to language input renders it valuable for various tasks. ChatGPT can be helpful for students in various tasks, such as writing assignments, summarizing, paraphrasing text, making grammatical corrections on text, and translating text. For lecturers, ChatGPT can help collaborate on written work, engage in intellectually stimulating conversations, conduct research, and assist with administrative tasks such as report writing (Atlas, 2023) . As a student and lecturer, there are various factors to consider when incorporating ChatGPT into higher education, including productivity and efficiency benefits, learning objectives and didactics, as well as ethical considerations and concerns about the impact on human job roles and intellectual property. It is essential to approach the integration of ChatGPT with thoughtful consideration and a holistic perspective, considering all relevant factors. In this sense, it is crucial to consider the limitations and risks of using ChatGPT in higher education, such as data bias, plagiarism, or quality of the produced text. In the following sections, we will provide guidance for effectively using ChatGPT and identifying areas for innovation in education. Conversational agents are valuable tools for university students, aiding with academic work, saving time, offering accessibility, improving critical thinking skills, and improving language skills (Atlas, 2023) . In this section, we critically reflect on how students can (and should) use ChatGPT, an example of a tool based on large language models, to maximize its potential benefits and avoid risks. This includes us also highlighting the limitations and dangers of ChatGPT. In summary, we have nine recommendations for students, as summarized in Figure 4 . In the following, we detail these recommendations.  Before discussing the possibilities of working efficiently with ChatGPT or other AI-based tools, we would like to highlight the need to respect the relevant national and regional legislation and the individual examination regulations of each university, school, and course of study. Students must comply with these and observe any instructions in the examination regulations on using AI-based tools. Furthermore, students must follow the rules regarding quotations and good scientific practice. Eventually, they need to indicate whether a text is created by AI or even which information was given to the AI. Recommendations for Students Gimpel, H., Hall, K., Decker, S., Eymann, T., Lämmermann, L., M ädche, A., Röglinger, R., Ruiner, C., Schoch, M ., Schoop, M., Urbach, N., Vandirk, S. (2023) . Unlocking the Power of Generative AI M odels and Systems such as GPT-4 and ChatGPT for Higher Education: A Guide for Students and Lecturers. University of Hohenheim. Higher education is more than acquiring domain-specific skills. It also includes cultivating and enhancing essential skills such as critical and structured thinking. Generative AI increases the need for these skills and affects the chances of developing them during your studies. Critical thinking refers to the ability to evaluate information, ideas, and arguments systematically and rationally. It involves questioning assumptions, analyzing evidence, and considering multiple perspectives to arrive at well-reasoned conclusions. Given that generative AI systems like ChatGPT produce large volumes of linguistically polished text, which may need to be revised in content, critically engaging with texts is more important than ever. Using ChatGPT as a writing partner (see recommendation 3 below) requires critically inspecting your partner's contributions before further processing them. Structured thinking refers to the process of organizing and categorizing information logically and coherently. It involves breaking down complex concepts into smaller components, identifying patterns and relationships, and using this framework to generate new insights and solve problems. ChatGPT is good at elaborating short text of a few sentences or a paragraph on a given topic. ChatGPT is not (yet) good at developing a long text that builds up an argument step by step or analyzes an issue from multiple perspectives in detail. Here, structured thinking is required for developing the scaffolding (potentially with support by generative AI), which can be filled step by step with ChatGPT. Since ChatGPT makes it easier to put clear thoughts into beautiful text and increases the linguistic quality, students can focus more on the thoughts and structure and less on formulating prose. In addition, the skillful use of tools such as ChatGPT requires that you know which prompts will get you valuable results. Skillfully interviewing people so that you get the information you are looking for is an art. Optimizing individual search terms and entire search strategies for an Internet search is an art. Likewise, it is crucial to understand how to properly prompt ChatGPT and other generative AI tools so that they effectively assist you in each task. On that account, prompt engineering emerges as a new, valuable skill. In short, with the advent of generative AI, critical thinking, structured thinking, the evaluation of text and other media, and prompt engineering gain in importance, the initial creation of text and other media becomes less important. By reflecting on the desired learning outcomes, students can, in the next step, determine how to integrate ChatGPT into their education best and use it to supplement and enhance their learning experience. Further, their learning goals and the offerings of different courses should guide their selection of specific courses. When promoting ChatGPT and asking if one can use it for writing assignments for students, the AI noted that it could not replace critical thinking and creativity, which are essential components of writing assignments ( Figure 5 ). Therefore, students in higher education should only use ChatGPT as a supplementary tool, such as Wikipedia, Google, or translation programs such as DeepL(Spannagel, 2023). Therefore, ChatGPT will never be the author of a work, and the responsibility for the written content will always lie with the human author, in this case, the student (arXiv, 2023). Since ChatGPT is not an author, ChatGPT cannot be cited as a source. Furthermore, because ChatGPT can always generate new data, the answers it provides are not verifiable. Thus, students should adhere to the principles of good scientific practice issued by each university. We will elaborate more on this issue in the assessment section (see Guidance for Lectures, Assessments, Recommendation 6). Weßels (2022) emphasizes that ChatGPT might be (only) a good writing partner. This means that although ChatGPT provides some topics and perspectives on a given topic, the user is still required to add further knowledge and creativity, which is a large part of creating essays or theses. Further, despite the daily increase in technological advancements in large language models, there are also limitations to the technology. The underlying models of ChatGPT were primarily trained on data up to September 2021. A typical claim is that ChatGPT is not obtaining new training data from the Internet, which restricts it to the data set and information it was trained on and what users feed into it. That is not always comprehensive, as can be seen by, for example, prompting ChatGPT: ""Please tell me a few sentences about the earthquakes in Turkey and Syria in 2023"". ChatGPT is not able to answer with any specifics about the event. Also of concern is that while a text generated by ChatGPT may sound plausible, it may also contain hallucinations, false information, or meaningless information. In addition, ChatGPT can generate sources that seem very realistic in appearance and syntax; however, being entirely fabricated. This can be dangerous for students who rely on it for literature research. Although ChatGPT, with the underlying model GPT-4, is now capable of generating sources with an attached Digital Object Identifier (DOI), there is still plenty of room for erroneous outputs. Partially, the DOIs are also completely fabricated; partially, they exist but refer to a different paper than ChatGPT's text output. Nonetheless, it may only be a matter of time before ChatGPT is connected to Internet search engines (such as Bing, Google), and services providing bibliographic information (such as Google Scholar, Scopus, Web of Science). In fact, Microsoft already combines ChatGPT with Bing and the ChatGPT for Google browser extension for Chrome and Firefox shows ChatGPT answers alongside search results from Google, Baidu, DuckDuckGo and others. Other AI-based language models (e.g., Perplexity) can even aid in literature research, as they link citations to their sources. Consequently, students and lecturers must verify any information they receive from the AI-generated content. Otherwise, there might be the risk that students use incorrect information or false citations to create user-generated content. Further, the AI model could be trained on false information and thus recreate a spiral of misinformation on these platforms. To effectively use AI-based writing tools for scientific topics, students must have a basic understanding of the topic and the limitations of the technology. Once this understanding is achieved, tools such as ChatGPT can assist in providing ideas and a basic text structure (Friedrich, 2023). For this, ChatGPT can be accessed with OpenAI's ChatGPT website or via integration into Google Docs or Microsoft Word (e.g., with docGPT). Table 1 presents exemplary use cases, following Atlas (2023) , where ChatGPT can act as a ""copartner"" for formulating text on a high linguistic level. Recommendation 4: Use ChatGPT as a learning partner Another useful application of ChatGPT is as a learning partner for university students. Since prominent conversational agents such as ChatGPT are accessible 24/7, they provide students with numerous opportunities to help them acquire new knowledge or test existing knowledge. Since many best practices are already circulating on the internet, we compiled and tested what we consider to be the most helpful ones in a short table (Table 2) . A good example of how the integration of AI models such as GPT-4 into existing learning apps can succeed has been shown by the language learning app Duolingo. The app uses the new GPT-4 model to provide the user with new features such as ""Roleplay"" or ""Explain my Answer."" With Roleplay, users can practice real-world conversation skills with fictitious characters. ""Explain my answers"" offers learners the opportunity to receive an explanation of why their answer was right or wrong. Further, they can ask for further clarification or examples (Duolingo Team, 2023) . These feedback mechanisms might also be possible with ChatGPT if students choose the right prompts to convert with ChatGPT (notice the prompt on ""Self-testing of specific knowledge""). When using ChatGPT, it is sometimes unclear how to use it effectively. Providing ChatGPT with accurate and specific information is crucial to obtain the desired text and information. Since ChatGPT relies solely on prompts and words, providing additional information and context, including the intended purpose and information on the target audience, unique position, and intended tone, is essential. If the text or result is unsatisfactory, users can request more information and provide detailed feedback to improve the model's response and generate a better match for their requirements (Atlas, 2023) . Possible prompts from Atlas (2023) that are consistent with these principles include: ""Summarize this text and highlight why [X] has a relevant role"" Further, ChatGPT offers a ""Regenerate Response"" option. If one is unsatisfied with the result, this option produces a new response for the same prompt. In addition, one can manually adapt the prompt or continue conversations with prompts like: ""Please shorten the summary to 150 words"" ""Please elaborate the second point"" ""Tell me more about the last argument in your previous answer"" Recommendation 6: Summarize learning material with ChatGPT You may use ChatGPT's functionality with videos and texts, like lengthy notes from a lecture or a difficult-to-read, lengthy paper. This may be a helpful way to skim learning materials and identify important aspects of the material. In doing so, one should be aware that a summary always misses details and that these details might be necessary. Therefore, this functionality should be used with caution. A nice gimmick is automatically summarizing the automatically generated transcript from a (YouTube) video. Several third-party browser plug-ins (e.g., YouTube Summary with ChatGPT) provide students with an opportunity to generate summaries of YouTube videos based on ChatGPT. The plug-in accesses and exports the standard YouTube transcript and transmits it to ChatGPT, requesting a summary which is then presented to the user via the browser plug-in. The browser plugins are available for Chrome, Safari, and Firefox. After installation, the plug-in enables students to access the transcript of the video and utilize ChatGPT to create a summary. The extension also facilitates easy navigation to the current time frame of the video and permits the copying of transcripts. The plug-ins support multiple languages and allow for the customization of prompts to improve the accuracy of the summary, as shown in Figure 6 .  ChatGPT can be used not only as a learning or writing partner but also as a partner to generate or correct codes. With the right prompt, ChatGPT can give students suggestions on coding. In Figure  7 , we depict a potential prompt with code as the response, which we retrieved and modified from an expert talk at HCUM Munich (Hauck-Thum et al., 2023) . These code snippets can then be used as a starting point for a project or task. ChatGPT can be an excellent tool to assist in debugging code. Students can share their code with ChatGPT, and the model can help identify errors and suggest possible solutions. Furthermore, ChatGPT can assist in optimizing code to make it more efficient by suggesting better data structures and algorithms. Table 3 provides examples of prompts that students can use to improve their code. Additionally, OpenAI has developed a more advanced tool called GitHub Copilot, which can help write code faster and with less effort than ChatGPT. GitHub Copilot is an AI pair programmer that utilizes a generative pre-trained language model created by OpenAI. By analyzing the comments and code, it instantly suggests individual lines and entire functions to improve the code. Recommendation 8: Beware of risks when using ChatGPT In addition to the advantages of utilizing ChatGPT for creating scientific text, users should be aware of potential sources of error and misconduct. Thus, although we recommend using AI-based tools, such as ChatGPT, for creating scientific text (if there is no explicit prohibition by the examination regulations or the university), we encourage students to reflect on each AI-generated outcome. This applies not only to text but also to code generated by ChatGPT. Rademacher 2023and others discovered issues with accurate citation of ChatGPT-generated sources. In some instances, ChatGPT created non-existent sources, posing a risk of propagating false information. Thus, students must verify each statement made by ChatGPT, which is a considerable workload. Further, there are substantial risks relating to accidental plagiarism and copyright infringements. Please see our discussion relating to recommendation 6 for lectures in section 4 below for details. One is responsible for writing if one submits a work under one's name (e.g., a seminar paper or a thesis). One is still responsible for the work if one uses content generated by ChatGPT or similar tools and includes them in one's work. One accepts the praise if the work gets praise (e.g., a good grade). One must accept the blame and other negative consequences if the work triggers blamee.g., for plagiarism, copyright infringement, unethical discrimination, unlawful content, or errors. For good or for bad, the author is responsible for her or his use of tools. ChatGPT and other tools based on generative AI will change how students learn, write exams, and study for tests. In the following, we summarize example recommendations that should be considered while working with ChatGPT: • Review the university's rules and regulations regarding generative AI, Large Language Models, and ChatGPT (considering policies for usage, acknowledgments, citations, etc.). • Check if the use of ChatGPT is clever or if the task requires the learning of basic knowledge • Verify that the results given by ChatGPT are trustworthy and accurate and reflect the findings (Atlas, 2023) • Consider which topics could be cleverly linked to produce novel insights. The variety of smart use cases of ChatGPT is enormous, and with time new ways of using it are sure to come. Students should empower themselves to use ChatGPT responsibly so that the first reflex of the (public) perception is not the possibility of cheating but the possibility of learning new things that will lead to mature students being prepared for digital work. Guidance for Lecturers The emergence of new educational technologies often arouses strong emotions, ranging from doomsday predictions to endless euphoria (Rudolph et al., 2023) . In the case of ChatGPT, experts also speak of an ""educator's dilemma"" between banning these technologies or promoting their use (Teubner, Flath, Weinhardt, van der Aalst, & Hinz, 2023) . Although the use of conversational agents and ChatGPT, particularly in higher education, is diverse, we aim to examine two main areas of application for teachers and lecturers in more detail: (1) the teaching process and the (2) the assessment process. There are numerous potentials for the teaching side across all stages of teaching-related activities, from planning and implementation to evaluation. In the following, we present different recommendations where generative AI systems, and especially ChatGPT, can support lecturers in their teaching activities. We illustrate this with five recommendations for lecturers regarding teaching, as summarized in Figure 8 . In the following, we detail these recommendations. Before considering how to use ChatGPT to support your teaching, it is essential to determine the actual learning objectives of your course. As mentioned earlier in the student section, learning objectives in higher education may vary depending on the field of study and subject matter. While critical thinking and structured thinking are considered essential goals in higher education, you can utilize ChatGPT to develop these skills in your students by utilizing the limitations of generative AI, such as the potential for false information or the potential to receive text of low quality. By reflecting on the output generated by AI tools and providing ChatGPT with purposeful prompts and sufficient information, students can practice structuring their arguments logically, which is an essential component of structured thinking. This interaction with generative AI can effectively develop students' Recommendations for Lecturers -Teaching  ChatGPT can be a valuable tool for personalized learning in higher education. In addition to supporting lecturers with various classroom tasks, ChatGPT can create custom exercises and quizzes, offer feedback, and generate tailored educational materials that align with a student's learning style and progress. Moreover, ChatGPT can assist in developing lecture ideas, drafting seminar plans and module descriptions, and crafting announcement texts. Another possible application of ChatGPT is to assess students' prior knowledge using AI. In Figure 9 , we illustrate a ChatGPT-prompt that can be used to create a lesson plan on a specific topic. Furthermore, as mentioned in the students' section, lecturers can utilize the ""YouTube Summary with ChatGPT"" feature to summarize video transcripts and design classroom elements. YouTube automatically generates transcripts of videos (be it learning videos produced by the lecturer or thirdparty videos). A click on the plug-in button sends the transcript to ChatGPT with a prompt to provide a summary.  Quizzes on a course's contents can support students and assess their level of learning. ChatGPT prompts can help lecturers in creating quizzes. Figure 10 represents an example of a suitable prompt with the ChatGPT answer. To stay close to the lecture's content, some lecturers first provide transcripts of their lectures to ChatGPT (e.g., via ""YouTube Summary with ChatGPT"") and then use prompts such as ""Please generate a single choice exam question about this content with four potential answers, exactly one of them being correct."" Such prompts can (and likely will) also be used to generate exam questions. While this might be an exciting feature to spur ideas regarding exam questions, lecturers cannot rely on the questions and suggested answers being correct. Therefore, they should do more than accept and use them. This is true for all uses of ChatGPT, but it is essential when it comes to exams. ChatGPT cannot just help lecturers in designing course materials but also boost learning by overcoming three challenges that are typically hard to address in classrooms: helping students apply their knowledge to new situations, showing them that they may not know as much as they think they do; and teaching them how to think critically about information (Mollick & Mollick, 2022) . One way to overcome the challenges in teaching is to incorporate ChatGPT as a learning tool. This approach allows for utilizing AI's strengths and weaknesses to enhance the learning experience. In Table 4 , and according to Mollick and Mollick (2022) , we present three ways to integrate ChatGPT into the curriculum. The task of the students is to evaluate the AI's response as it transfers a concept to a different context. Further, students should apply strategies to improve AI's output. ChatGPT can be used to write essays about a particular topic. Although AI is good at simplifying text, it has weaknesses in providing insightful analysis. The task of the students is to continuously improve the AI-created essay by providing further prompts to the AI, adding new information, or clarifying points. Help students to identify and close gaps in their knowledge with ChatGPT ChatGPT can be utilized to outline the steps involved in a specific process. However, the AI-generated process might not be complete. The task of the students is to evaluate and improve the AI's output by adding information from different sources The way teaching is done in higher education should adapt to the technological developments and the various possibilities they offer. In this sense, ChatGPT is seen as a support rather than a threat. Lecturers should encourage students to use ChatGPT creatively and critically to improve, expand or vary their own texts, but not to replace or plagiarize them. This whitepaper might help inform students about the possibilities and risks of using ChatGPT and similar tools. By teaching students how to effectively use these tools, educators can equip them with important skills for their future careers, while also emphasizing the importance of academic integrity and originality. One of the most common concerns with using ChatGPT is the fear that essays will become increasingly obsolete as an assessment method in higher education. Some lecturers are concerned that written assignments are being outsourced to ChatGPT without being detected by a plagiarism detector. Further, lecturers see the challenge that generated text reads naturally. While traditional plagiarism detection tools can identify copied and pasted text from scientific sources, they are not equipped to identify text generated by AI models such as ChatGPT (Khalil & Er, 2023) . Tools such as the OpenAI Text Classifier, which have been developed to address the issue of false claims that a human wrote AI-generated text, are currently improving. However, the current success rate of the tool in recognizing texts generated from large language models is only around 26%. While this is still a remarkable achievement, it highlights the limitations of existing plagiarism detection software in its current state (Wiggers, 2023). Traditionally, some lecturers might have taken the linguistic quality of a text as an indicator of its content quality. However questionable such a shortcut might always have beenwith increasingly advanced language models, the potential link between linguistic quality and content quality is no longer there. These concerns only arise when lecturers do not engage in changing assessment formats and criteria. However, there is already a debate about the suitability of written essays to test students' knowledge. The second fear is related to the inability of ChatGPT to truly understand the context and interpret text since ChatGPT is just predicting the probability of the next word in a sequence that has already been monitored (Arif, Munaf, & Ul-Haque, 2023) . As a result, institutions concerned about AI's output could take this as legitimacy for implementing policies that prohibit the use of AI for quality reasons. Given the rapid technological development of AI applications and their prospects, such as the integration of ChatGPT into widely used Microsoft products, it quickly becomes apparent that there is no alternative to using AI applications in the university context (Salz, 2023) . Universities and lecturers should therefore focus on ensuring responsible use by addressing potential challenges related to ChatGPT rather than implementing policies that restrict use (Brown et al., 2020; Vogelgesang et al., 2023) . Below, we present several ways teachers can turn the challenges associated with ChatGPT and assessment formats into opportunities to adapt to emerging changes in higher education. Exams, seminar papers, and bachelor or master theses are the assessment formats mainly concerned about. In summary, we have eight recommendations for lecturers regarding assessments, as summarized in Figure 11 . In the following, we detail these recommendations.  Closed book exams, where the students write by hand, using only pen and paper, or using a computer in a controlled environment and a kiosk mode without Internet access, might be the easiest way to test the student's knowledge in the future. ChatGPT is no more of a threat to the assessment process in such a setting than traditional paper-based cheat sheets. However, such an assessment approach might be antiquated since students acquire much knowledge shortly before the exam that is subsequently forgotten. Thus, we notice a trend in higher education, not least driven by the Covid-19 pandemic, from ""penand-paper-only"" exams to ""open exams"" or ""take at-home exams"". When creating open exams where technical aids are also allowed, care should be taken to test the exam questions in advance with ChatGPT. In case of excellent results, the questions should be discarded; in case of not good results, ""regenerate"" if there is still room for improvement, keep the question. The following are additional items to consider when administering exams that can help prevent student misconduct (Koenders & Prins, 2023) . • Ask for personal reflection in your exam. • Focus your exam questions on very recent events. ChatGPT, in its current version, was trained on data up to September 2021. Thus, it is not informative on more recent events. • State on the exam which tools are allowed (e.g., Stata) and which are not (e.g., ChatGPT). All these suggestions have limitations. Assessing the correctness or quality of personal reflections takes much work and is only possible to a certain degree. It is easy to foresee that their limits not Recommendations for Lectures -Assessment Gimpel, H., Hall, K., Decker, S., Eymann, T., Lämmermann, L., M ädche, A., Röglinger, R., Ruiner, C., Schoch, M ., Schoop, M., Urbach, N., Vandirk, S. (2023) . Unlocking the Power of Generative AI M odels and Systems such as GPT-4 and ChatGPT for Higher Education: A Guide for Students and Lecturers. University of Hohenheim. being up-to-date will be annulled in the future with continuous updates of the models or integration of Internet search and language models. Despite these limitations, the general recommendation to critically rethink exams in light of generative AI remains. Recommendation 2: Require students to declare how ChatGPT and other advanced tools were used Monitoring which tools are used in a take-home exam is impossible, and not all students might be truthful. However, explicit declarations about whether special tools were used or not increase the binding nature and the consequences in case of misconduct, as is also standard practice in declarations of independence in, for example, theses. Cambridge University Press and other publishers have already implemented guidelines that require authors to disclose their use of AI-based tools, such as ChatGPT, when writing articles. The publisher has announced that these guidelines protect authors who wish to utilize ChatGPT and similar AI-based programs, encouraging them to do so (Forschung & Lehre, 2023) . Hence, we suggest that universities develop such declarations of independence that explicitly address the usage of generative AI tools. At best, such declarations are not binary regarding using tools such as ChatGPT (e.g., ""I used ChatGPT"") but are differentiated like author contribution statements in some academic journals. The statements should highlight which steps in the research and writing process ChatGPT and other tools were used for (e.g., developing an outline or proofreading). Further, such declarations should include a statement of student responsibility regarding potential errors, copyright violations, or plagiarism that technical tools inserted in their work. Further, lectures might require students to provide a list of prompts used. Even further, they might require students to provide a full transcript of the conversations with ChatGPT that informed the student's work. Browser plug-ins exist that allow to export and share a conversation with ChatGPT. ChatGPT has raised many concerns about its potential to undermine the effectiveness of assignments as an assessment method. This concern has been present since the early days of its implementation. ChatGPT has the potential to be a significant innovation in higher education by enabling lecturers to use assessment as a tool for their teaching. However, few lecturers currently possess the necessary skills, making AI a potential educational milestone to take the assessment as a learning (Earl, 2012) . One possibility to innovate assessment formats arises from the fact that ChatGPT has a restricted capacity for creativity. ChatGPT is trained on specific patterns and existing text, limiting its ability to generate original content or ideas. As a result, ChatGPT can only replicate what it has been trained on and what already exists and needs to be more capable of thinking creatively (Susnjak, 2022) . Consequently, there is potential for lecturers to explore innovative assessment formats that demand thinking beyond traditional boundaries. These assessment formats could lead to new outcomes through students' creative linking of topics. Therefore, our recommendation is to steer clear of standardized assessments that could quickly be completed by a computer, as suggested by Herman (2022) , and instead design assessments that promote students' abilities to think creatively and critically, as advocated by Brookfield et al. (2019) . Here are some examples to innovate your assessment formats: • Administer specific assessments only during class (Rudolph et al., 2023) . • Encourage oral presentations to assess students' public speaking skills, as well as their understanding of the material (McCormack, 2023). • Encourage collaborative group projects where students work in small teams to complete a specific task or project (McCormack, 2023) . • Promote critical thinking by requiring students to reflect on their learning through written or oral reflection. • Let students prepare other forms of materials, for example, webpages, videos, and animations that express critical thinking (McCormack, 2023) . None of these formats is a silver bullet. In one form or the other, they favor students being able to participate in person in the classroom, deal well with high time pressure, or have good oral communication skills. Assessing individual contributions in group work is challenging, as is evaluating individual reflections. Further, ChatGPT and other AI tools can also support creating webpages, videos, and animations. Nevertheless, lectures should consider innovating their assessment formats in light of students' ability to use generative AI tools and in light of the potentially changes learning goals to account for the diffusion of generative AI tools. In changing the assessment formats, lecturers must consider the time required for the assessments. Potentially, the staffing needs to be increased to allow for meaningful assessments. Since ChatGPT is particularly good at formulating text, it is almost impossible to detect whether AI or students wrote specific text passages of assignments. Thus, we encourage teachers to emphasize the supervision process more than the written assignment. Thus, teachers can better evaluate how the assignment was created and whether students acquire specific expertise during the creation process. We thus align with the suggestions of Frölich-Steffen (2023) and propose to consider the following steps: • No assignments without supervision process. • Require information on work steps during the process. • Place significant emphasis on study design and the careful execution of the study in empirical works. • Require the use of ChatGPT as a work step including a clear indication of what ChatGPT was used for. • If possible, add a presentation and oral defense of the results, as this shows how far the student has mastered the contents. As with recommendation 3 above, improving the supervision process might require additional time and, thus, staffing. Given AI tools' exceptional ability to generate and compose a text, higher education must establish novel assessment criteria that surpass the mere formulation of text for evaluating assignments. Although ChatGPT occasionally makes mistakes in its content, its writing is often convincing. Therefore, students can assess the content of the text while placing less emphasis on the structure and writing style, which are areas where language models tend to excel. Hence, the following evaluation criteria should be considered more seriously in cases where ChatGPT is not explicitly forbidden (Frölich-Steffen, 2023). • Quality and individuality of the research question as well as fit to the assigned topic Recommendation 6: Implement guidelines for avoiding plagiarism and copyright infringements One of the most significant challenges in higher education will be detecting plagiarism. In 2000, The Guardian warned of a ""plagiarism epidemic"" and raised concerns that Google, Wikipedia, and Co. will make students ""stupid."" Over 20 years later, we all know that none of these technology-driven developments made students stupid but brought innovations to higher education's teaching and learning process. However, with easy access to electronic texts at a massive scale, plagiarism became easier (e.g., copy & paste). Many universities use plagiarism detection software that matches a newly submitted text against previously known texts to fight that. This is good for detecting blunt, direct plagiarism. Recent advancements in automatic translations and large language models ease the task of wrongdoers and complicate plagiarism detection. Automated translations (e.g., using tools such as DeepL or Google Translate) of preexisting texts into the language of the assignment evades direct text comparison. For some years, some students have used translation chains to paraphrase text. An example: You take an English text from literature, and automatically translate it to German, then to Spanish, then to Russian, and back to English. Even within a single service, the resulting text paraphrases the original. The discrepancy between original and paraphrased text likely increases when switching between translation services. This task could be more convenient for students. Large language models such as ChatGPTunfortunatelyease this task. Students may, for example, prompt ChatGPT, ""Please paraphrase the following text: ""Even if not direct but paraphrased: If the source is not credited, this is plagiarism. However, it is more difficult to detect. A more fundamental concern regarding plagiarism is whether ChatGPT might provide it without disclosing it or the user noticing it. ChatGPT was trained on pre-existing texts and learned typical flows of text. It can quickly happen that text generated by ChatGPT is in parts identical to pre-existing text. With human writers, it can happen by chance that one writer produces a short piece of text fully independent of the other, just by chance. However, with language models trained on the text and then reproducing some of that text, this is not by chance a type of plagiarism. Likely, this will not recreate large portions of a single text but may lead to what is known as patchwork plagiarism or mosaic plagiarism, where multiple different sources are interwoven without adequately referencing them. Further, ChatGPT is accused of copyright infringements. Thus, copying text generated by ChatGPT into a document one draft puts one at risk of plagiarism and copyright infringement. Responsibility for such violations of legal regulations or good scientific practice lies with the human author(s) of a work (arXiv, 2023). Even if one might argue that this is accidental plagiarism from the users' perspective, users of tools such as ChatGPT should be aware of the risks and not be negligent. A new legal framework called ""learningright"" is already being discussed as an alternative to ""copyright"" (Malone, 2023) . This legal concept aims to balance the need to protect creators' intellectual property rights while still allowing AI systems to learn from and build upon existing knowledge. This responsibility of the human user relates not only to plagiarism and copyright infringement but also to ""biased content, errors, mistakes, incorrect references, or misleading content"" (arXiv, 2023). Lecturers should inform their students about the risks and their responsibility for texts they submit under their names. Further, to prevent plagiarism, lecturers can implement guidelines to encourage students to deal responsibly with literature sources, for example, by forcing them to provide detailed notes or screenshots/photos of the literature base (Frölich-Steffen, 2023) . In summary, the handling of plagiarism should be consistent with the regulations of the university policy and their guidelines. Finally, some consider the use of text generated by ChatGPT as plagiarism, as not the student developed the text, but someone else, namely ChatGPT. Instead, we take the perspective that using ChatGPT and other tools is not a problem per se. However, using advanced tools such as ChatGPT requires transparency on tool use. Various ""ChatGPT Content Dectors"" or ""AI Content Detectors"" are already available to distinguish between human-written and machine-written text. Like plagiarism detection software, they analyze text, highlight dubious sections (in this case, likely computer generated), and typically provide a percent value of how much of the text is computer generated or how likely it is computer generated. Currently, these detectors are far from perfect. They will improve in the future just like other systems try to avoid correct classifications. These imperfect content detector tools may be used to check the plausibility of the students' disclosure. Incorporating AI tools such as ChatGPT in higher education is not merely a threat to conventional assessment methods but can also aid in enhancing students' academic performance. As not all learners possess strong writing skills or might encounter linguistic obstacles, utilizing large language models such as ChatGPT can promote equity and fairness in the educational setting. By providing learners with a tool to generate well-composed texts, students can demonstrate their knowledge and comprehension of a subject matter rather than being handicapped by writing deficiencies or language barriers. Therefore, AI technology can be pivotal in promoting inclusivity and excellence in higher education. Although AI can assist in creating substantial and insightful content, it is not a simple task and demands proficiency in both technical skills and knowledge of ethical considerations. Students need to be made aware of, for instance, stereotypical ChatGPT answers. As ChatGPT is trained on a large dataset of text, it is very likely that the data used to train ChatGPT may contain societal biases (Dahmen et al., 2023) . Consequently, the model will reflect these biases in the output data and, thus, reinforce existing societal issues and discrimination (Atlas, 2023) . Therefore, when using ChatGPT in higher education, students should be aware of this potential bias and critically reflect on each statement created by ChatGPT. Further issues of copyright and intellectual property need to be discussed with students. The media recently reported that leading AI developers such as Microsoft, OpenAI, StabilityAI, and Midjourney are increasingly facing lawsuits over alleged copyright infringement in their programs' outputs and the data they are trained on (Wiggers, 2023). Students and lecturers who reuse AI-generated texts or other content risk infringing the original authors' copyright if the AI was trained on data and information subject to copyright, leading to incalculable legal consequences. To help students master the use of AI, lecturers can redefine their curriculum and, thus, explicitly teach the use of AI. This may include: • Include subject-specific reflection on the impact of AI into the curriculum. • Develop study programs focused on AI in science, ethical implications of AI use, and knowledge creation through AI systems. Recommendation 8: Implement ""Rules for Tools"" AI tools such as ChatGPT have immense potential for uncovering novel approaches to pedagogy. Nonetheless, while proficiently generating plausible information, AI risks disseminating false data, fabricated quotes, inaccurate information, plagiarism, and the like. Learners must possess adequate knowledge of the subject under scrutiny to achieve satisfactory outcomes. Establishing a transparent policy governing AI implementation in higher education represents a crucial stride toward fostering a learning setting wherein AI is embraced with accountability and candor. Thereby, ""Rules for Tools"" can help build an AI policy (Spannagel, 2023) . Based on Spannagel (2023) and in line with what we describe in other parts of this whitepaper, rules for tools may include: • In general, students may use all types of media and tools, with the use of said tools subject to the course requirements. • Students are accountable for their achievements, as AI tools, such as ChatGPT, while capable of generating well-composed texts, can still contain mistakes and violate regulations or norms. • It is mandatory for students to report the aids used during a course, for example, listing the tools, the fields of application of these tools, and recording, for example, the prompts when using AI tools such as ChatGPT. • Exceptions can be made to the rules outlined, such as prohibiting tools in specific learning or assessment situations, which will be communicated to the students in advance. As AI becomes more prevalent in daily life, it will be impossible to ignore that students will use AIbased tools to succeed in higher education (Jacobsen, 2023) . Furthermore, they should use AI tools to be productive and acquire important digital skills. Although higher education is not the fastestmoving field, it is forced to innovate its inherent educational structures as technological improvements are rapid and vast. Consequently, there is no doubt that teaching and learning will change drastically. The media coverage has mainly focused on ""cheating"" and how universities can put policies and procedures in place to manage ""the AI problem."" We argue for a more positive view on technological advancements such as generative AI. The debate and the innovation should focus on the potential benefits of generative AI, such as improved learning, teaching, and the creation of equal opportunities for different groups of students. On the side of technologies and generative AI systems, it is straightforward to assume further rapid developments. Ever more potent GPT-x models by OpenAI, comparable models by other vendors, more multimodel input and output to generative AI models, different interfaces to such models beyond conversational agents, and integration with other classes of IT systems are clear paths ahead. OpenAI, Microsoft, and many others in academia and industry are working in these directions. Hence, what we see with the current version of ChatGPT is likely only the first small step on a big road towards increasingly powerful generative AI tools in higher education and beyond. Conversational agents are an essential resource that lecturers and students can and should use in teaching and learning already today. However, innovating teaching, assessing, and learning is only one field in a more complex higher educational landscape. As the technology develops, the potential of generative AI goes beyond the ""teaching-learning trifecta"" between students, lecturers, and technical tools. It will transform the entire student lifecycle, including admissions, enrollment, career services, and further areas of higher education management, as exemplified in Figure 12 . The easy access and fast dissemination of ChatGPT, along with the associated challenges in learning, assessing, and teaching, have shown how quickly traditional patterns can be disrupted by technology. As we deliberately focus on the impact of ChatGPT and related tools on teaching and learning in this whitepaper, we consciously exclude other parts of higher education. However, we believe that we should seize the opportunity presented by technological developments in AI to rethink the world of higher education as a whole. In this context, we should be aware that ChatGPT may change the expectations of future AI technologies, especially conversational agents, whether in terms of interaction or information quality. On a macro level, universities must watch out for potential social inequality when tools such as ChatGPT are only available for a service fee. On the other hand, we should not expect that every IT-based service provided via the Internet is for free. From a societal perspective, it is crucial to ensure that all students can access the same tools and resources to complete their education successfully. However, it is uncertain how long a free version of ChatGPT will be available. In addition to the free version of ChatGPT, OpenAI released the premium version -ChatGPT Plusfor 20 USD per month (OpenAI, 2023c). It promises improved availability, unrestricted usage, and access to GPT-4. As this new AI model boasts advantages over its predecessor, GPT3.5, we conclude that users who can afford the premium version will enjoy advantages in utilizing ChatGPT. Thus, it is questionable whether this premium version's availability is already compromising the principle of equal opportunities for all students. To ensure equal access to education, universities might consider providing fee-based tools, such as the premium version of ChatGPT, free of charge or at a significantly reduced rate for students. This may require substantial financial funds for the campus license. With ChatGPT Plus at 20 USD per month before academic discounts, the monthly fees for a university of 10.000 students might add up to 200.000 USD, summing up yearly to over 2,4 million USD. With a growing number of necessary cloud-based tools requiring license fees rather than open-source software installed on-premise in the University's data centers, ChatGPT adds to an ongoing discussion about funding digital transformation in higher education. Another key question beyond the individual course is which competencies students should develop in higher education. Domain-specific skills always have been important and remain important. From our point of view, transferable skills such as cognitive, metacognitive, and socio-emotional skills as well as digital skills are becoming increasingly important. These skills include logical reasoning, structured and critical thinking, problem-solving, collaboration, and emotion regulation. Not least, students should have the ability to develop and use AI-based tools responsibly. Such skills will help students succeed in an interconnected and fast-paced digital world. Students will succeed in an interconnected and fast-paced digital world. Aoun (2018) describes the necessary mindset as ""robotproof,"" focusing on unique cognitive human capabilities like critical thinking, systems thinking, entrepreneurship, and cultural agility. As generative AI continues to advance, it is crucial to explore how it impacts the development of these skills in higher education. With AI's ability to generate and provide information, there is a risk that students may become passive recipients of information rather than active thinkers. For instance, to ensure that critical thinking remains an essential education component, higher education must actively develop strategies to foster critical thinking in their classes. Thus, expanding the current curriculum by including lectures on how AI can be used to support critical thinking is crucial. Higher Potential application fields of generative AI in higher education Gimpel, H., Hall, K., Decker, S., Eymann, T., Lämmermann, L., M ädche, A., Röglinger, R., Ruiner, C., Schoch, M ., Schoop, M., Urbach, N., Vandirk, S. (2023) . education must incorporate tasks and activities that promote critical thinking and develop assessment methods that measure the student's development of critical thinking skills in the context of generative AI. Ultimately, the challenge is to ensure that students continue to develop the skills they need to make informed decisions and solve complex problems in a world where AI is increasingly prevalent, as these skills are highly appreciated in the business context and highly needed in society. The focus of this whitepaper is on students and lecturers. Nevertheless, we see a clear need for action beyond the level of individual students and lecturers. Universities should encourage broad, multi-perspective dialogue among many stakeholders in higher education. • They should include all faculties and disciplines since different fields have different traditions, requirements, and opportunities, which should be reflected in any university's approach to generative AI. • They should involve their own experts from information systems, computer science, data science, and related disciplines, who have been researching IT-based innovations and digital transformation for years and decades and, in many cases, also research generative AI. They can contribute to the knowledge of the technologies and the transformation process and have first-hand experience in teaching at their university. • They should involve their career centers and representatives from industry and society to inform the dialogue with perspectives on the required educational profiles and skills. • They should involve students who contribute their perspectives on learning objectives, formats, and study conditions. • They should involve experts on university didactics, who bring important perspectives on learning objectives, teaching-learning formats, assessments, and the like. • They should involve legal experts to examine the legal possibilities offered by the current legislation and university regulations and the changes required to make the desired use of generative AI tools possible and legally sound. • They should involve the university's divisions that administrate study and teaching. These are important to the processes that should deliver fair, efficient, and high-quality teaching. • They should involve the university's IT department, which can consult on access, infrastructure, licenses, IT security, and the like. Together with all these stakeholders, universities should engage in a dialogue on how to promote and leverage ChatGPT in the short term and other generative AI tools in the medium term. The results of the dialogue should lead to multi-perspective insights that result in regulations, guidelines, handouts, tutorials, and implementations. If appropriate, it may be helpful to talk to external experts, exchange experiences with other universities, speak to the responsible supervisory authority and politics, and demand the necessary resources for excellent university education. To summarize, integrating generative AI tools such as ChatGPT in higher education requires a significant educational transformation that cannot be achieved overnight. While there are plenty of ideas and discussions on managing and leveraging such tools, lecturers should first learn how ChatGPT and comparable tools operate and modify their teaching methods, contents, and processes accordingly. Additionally, changes to examination formats cannot happen immediately but rather require careful development and adaptation following examination regulations. As such, integrating ChatGPT into higher education will require patience and careful planning to ensure its successful implementation. Students should not wait for the university-level discourse to end and for the lecturers to have adapted. Instead, we suggest that students actively engage with generative AI. If they did not use ChatGPT yet, they should get a free account and gain first-hand experience with the possibilities and limits. They should reflect on their learning goals, methods, and processes and engage with other stakeholders in higher education to shape the dialogue on AI-powered higher education. As we call lecturers and students to action regarding ChatGPT and provide recommendations for them, it is important to stress that their use of ChatGPT should comply with legislation, university regulations, good scientific practices, and OpenAI's terms and conditions. If this is the case, this whitepaper hopefully provides food for thought regarding using generative AI, large language models such as GPT-4, and tools such as ChatGPT in higher education. Wiggers, K. (2023). OpenAI releases tool to detect AI-generated text, including from ChatGPT. Retrieved March 12, 2023, from https://techcrunch.com/2023/01/31/openai-releases-tool-to-detectai-generated-text-including-from-chatgpt/ Gimpel, H., Hall, K., Decker, S., Eymann, T., Lämmermann, L., M ädche, A., Röglinger, R., Ruiner, C., Schoch, M ., Schoop, M., Urbach, N., Vandirk, S. (2023). Unlocking the Power of Generative AI M odels and Systems such as GPT-4 and ChatGPT for Higher Education: A Guide for Students and Lecturers. University of Hohenheim.",
Publication,PUBLICATION_SEARCH_SNIPPET,Large Language Models and Text Generators: An Overview for Educators.,['R Morrison'],2022,Online Submission,"Large Language Models – Large language models are the  As a note, the name Large  Language Models is still  and transformation are functions of large language models, and they are",False,39,https://eric.ed.gov/?id=ED622163,[''],/scholar?q=info:oDAmyDtDyGwJ:scholar.google.com/&output=cite&scirp=38&hl=en,"/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522large%2Blanguage%2Bmodels%2522%2B%252B%2522higher%2Beducation%2522%26hl%3Den%26start%3D30%26as_sdt%3D0,33%26as_ylo%3D2000%26as_yhi%3D2023&citilm=1&update_op=library_add&info=oDAmyDtDyGwJ&ei=0ReNZMb1BZ6Sy9YPifqyyAM&json=",0,,https://files.eric.ed.gov/fulltext/ED622163.pdf,"""large language models"" +""higher education""",oDAmyDtDyGwJ_2022_Large Language Models and Text Generators: An Overview for Educators.,99207007cd8648908889a99803755b3e,"In February 2019, when the existence of GPT-2 and ""better language models"" were exhibited by OpenAI-a non-profit Silicon Valley organization with the mission to keep powerful algorithms out of the exclusive hands of governments and corporations --it was apparent that there were certain inevitabilities of this Artificial Intelligence (Radford et al., 2019) . Now, some of these inevitabilities have already come to fruition at the time of writing. Text-based education will be impacted -no doubt --and student outcomes that we have long valued, particularly in language arts, are becoming automated. Academic integrity issues may become pervasive and the effect on assessment could be significant. On the flipside, this class of AI, which has become known as Large Language Models (LLM), could be used to address the problem of languages, i.e. facilitate better communication between speakers of different languages. LLM can serve to automate rudimentary communication and provide models and interaction for language practice. This does not mean that we will have to stop teaching our current outcomes nor teaching languages, rather we need to change how we are teaching and assessing themthis sentiment has been echoed by many of educators in various discussions. As of the time of writing, the ""Write My Essay"" button has yet to be invented -this could be a matter of time as the citation generators have been commonplace for some time, and theoretically, integrating an LLM interface into a platform that automatically writes an essay is not an absurd proposition. When combining a variety of the currently available tools including citation generators, it is possible to produce a passable essay in short order. The hope is that by the time someone publishes a platform that is singularly able to automate traditional text-based assessments such as essays and short answer tests, most of educators will have started in earnest to move away from assessing outcomes in these vague perfunctory modes in favour of more meaningful and authentic assessments. Beyond the horizon, LLM stand to revolutionize communication; they appear to be the near end-game tool of Natural Language Processing (NLP), the branch of computer science concerned with input and output of communication between humans and computers. However, written and spoken communication between humans may be assisted by this technology, but students will always need the skills that we impart in our classes. In fact, it is probable that we will need to begin integrating discussions of our relationships with algorithms with our students sooner rather than later and training teachers to be able to identify and discuss algorithms and algorithmically generated language (Abd-Elaal, et al., 2022) . This document was created with three purposes. The first is to increase awareness of large language models in education, the second is to offer a primer in identifying algorithmically generated and transformed text, and the third is to encourage continued discussion of the intersection of modern algorithms and humanity at the educational level. I hope you find it useful. • https://inferkit.com/ -A basic text generator that includes slider options like ""temperature"" that control the 'randomness' of GPT-3. • https://www.writefull.com/ -Targeting post-graduate academics, this site has several functions to explore, including creating abstracts for publishing in academic research journals. • https://speedwrite.com/ -A summarizing platform targeted at students, this site summarizes, spins (paraphrases) and creates text based on inputs of 100 words or more, and includes a Wikipedia plug-in. Since these are all powered by the same LLM, it costs money for the platform to generate text --$10 USD for 300,000 words . Thus, each site offers some variation of a limited free trial or a free/premium option to cover their costs. It is important to note that these are only five of the hundreds of platforms using this this technology to generate text in some form. Source Text -LLM are based on open-source text from compiled into a database. The most commonly used database is from Eleuther and is referred to as 'the Pile'. It is half a trillion words and is 800 GB in size (Gao, et al., 2020) . The exact sources and their categorization is represented visually in the diagram below. (Image: Gao et al., 2020) Parameters -The parameters are the connections that are made by 'training' the algorithm. To visualize this, think of phrase ""it has come to…"", and then think of the common completions: ""our attention"", ""fruition"", ""pass"", etc. The largest large language models have hundreds of billions of parameters, and the output is the result of these parameters, which can be customized depending on the platform. For instance, InferKit provides a 'sampling temperature' slider, which ""Controls the randomness of sampling-the 'creativity'"" (InferKit, 2022) . Turing Test -Named for one of the founders of computer science, Alan Turing, a Turing test is the measure of a computer's ability to imitate a human. If the observer cannot identify that an output is computer generated, the computer has passed the Turing test. This is a hallmark of AI, and text generated by large language models consistently pass Turing tests. OpenAI -Created by Silicon Valley magnates with the intention of keeping AI technology available to everyone --keeping an even playing field for all nations and corporations -OpenAI pioneered large language model technology. The Generative Pre-Trained Transformer series (GPT-2 and GPT-3) were released less than a year apart and have served as the base for most other large language models. You'll notice that all of the generated and transformed text in this document was created on platforms that use GPT-2 and GPT-3, and therefore those programs are included as authors in this document. This was done purposefully as the question of the nature of authorship is one of the possible impacts of text generating technology. The branch of computer science concerned with input and output of communication between humans and computers. How do text generators/ transformers operate? When the user inputs a prompt, most platforms take a few moments to produce results. In these moments, the large language model algorithms are making word selections based on the common associations with the input. The grammar and mechanics are not actually programmed into the algorithm; rather, they have been trained to follow the patterns of natural language in the source text. This training works by identifying themes and following patterns that are common in those themes from the source text. For example, if the input follows patterns of conversational quoted speech, the output will follow in this same mode (granted the settings don't negate this), repeating the speakers' names and continuing the conversation. The resulting text can be curated and altered by the user, as well as re-generated to get the text 'back on track' should it drift away from the desired result. In this document, moments where the curator has had to re-generate are noted, and thematic drift is also noted as it follows some noticeable patterns. No --since the text is novel, it won't show up in text-matching database like Turn-it-in or SafeAssign. The only chance to automatically detect algorithmically generated text would be to create a detection algorithm could identify patterns used in large language models. Researchers attempted this with GPT-3's predecessor, GPT-2 in 2019. GPT-2 had much fewer parameters and produced less sophisticated text (See 'GPT-2 Paragraph Examples and Analysis' section). Therefore, a detection algorithm was feasible, and NLP researchers at MIT and Harvard were able to produce a functioning platform (GLTR from MIT-IBM Watson AI Lab and Harvard NLP, 2019). However, there is no functioning version for this GPT-3, for a few reasons. For one, the algorithm would have to account for all large language model parameters and their source material, and so, this theoretical detection algorithm, at the time of writing, would be very expensive to run and require constant updates (each time a new LLM is publicly published). It would be very expensive because it would require the combined energy costs of all currently available LLM, which is significant (Bender et al., 2021) . GPT-3, for example, has a per-word price point attached to their API to cover their computing costs . The detection program would likewise also require a per-word fee associated to it. It took slightly more than a year for OpenAI to release GPT-3 after its ground-breaking predecessor, and it took less than one year after that for Microsoft and Nvidia announce they had trained a large language model with three times the parameters of GPT-3, which also includes ""common sense reasoning"" (Wiggers, 2021) . Another reason why automatic detection is virtually impossible is that there would need to be a word count threshold for the theoretical detection algorithm to work. One of the most apparent applications of text generators, based on the number of purpose-built platforms, is for copywriting, i.e. creating short slogans and content for marketing and advertising. A simple phrase or sentence created by a text generator is not identifiable as such; it could just as easily have been created by a human. For the copywriter's purpose, generated text may be off-topic, or it may be brilliant. Either way, the curated text of the copywriter won't appear as generated to a detection or algorithm because there is nothing noticeably divergent from human generated text in isolated sentences. Perhaps, beyond a small paragraph, a detection program could determine with some probability whether or not a text was generated by a specific algorithm, but again, there are many of these algorithms with their own idiosyncrasies, so accounting for this would be profoundly difficult to create at the time of writing. It is very difficult to tell the difference between human and algorithmically generated text. Anecdotally, I've done modified Turing tests with several participants and there have been few unanimous identifications of whether a text was algorithmically generated, though there are some patterns that many participants identify (expanded on later). That being said, the examples used in the modified Turing tests are curated examples with the express purpose of creating compelling Turing tests -they are the best versions of outputs which are still random at times. Another anecdotal finding is that when two texts are compared, one being algorithmically generated and the other human generated, the results skew towards humans being able to identify the algorithmically generated text. However, when an algorithmically generated paragraph is integrated into a longer, human generated text, it is much more difficult to differentiate. This parallels preliminary studies being done elsewhere. A group of community college teachers were tasked blind marking assignments and although GPT-3 based text achieved a B average in writing historical essays, it failed to create creative narrative pieces that achieved above a failing grade (Macaulay, 2021) . A few caveats to this study were that it was informal, and the customization tools were not documented -GPT-3 might be better at creative writing if the curator was more familiar with customization tools. Some of the first instances of algorithmically generated text appearing in publication and preliminary studies demonstrate that there are still some language tasks that GPT-3 are not proficient at completing. The GPT-3 Guardian article (Porr, 2020) explicitly acknowledges the role of the curator. Other examples show that GPT-3 generated text is good at creating 'thinkpiece' style content. An example of this was a GPT-3 generated piece which was submitted to Hackernews.com, and was then upvoted to the top of a list of user-submitted articles (Lyons, 2020) . The caveat here is that members of this site could have agreed to upvote the article for whatever reason. Google's former Head of Ethics Timnit Gerbu co-wrote the seminal and now infamous criticism of current Large Language Models (Bender, et al., 2021) , which lays out the ethical issues of LLM quite thoroughly, and the following explanation is a largely selective summary of that paper. Energy and cost are key issues that come along with LLM. If the servers are not on a sustainably sourced electrical grid, there would be a sizable amount of carbon produced because of ubiquitous use of LLM. This is part of a broader issue with AI level computation and modern energy heavy processes, like that of mining Bitcoin (Bender, et. al., 2021) . The confluence of these demands has resulted in the need for increased production of powerful processing chips that were, until recently, mainly used commercially in the video gaming community. As a result of this cost, OpenAI sells words produced by GPT-3 on a per-word basis to cover costs . This creates an access barrier for people who do not have the means to pay for these platforms. However, there is still the question of the effects of technology companies' integration of LLM into their existing products in the form of autocomplete suggestions, translation and search. While the new in-house versions of LLM claim to be more powerful and accurate than GPT-3 (Wiggers, 2021) , they remain behind the curtain of corporate intellectual property, and are thus subject to less scrutiny than the publicly available versions. Although Gerbu was unceremoniously terminated from her position as a result of not withdrawing the paper (Simonite, 2021) , her stance is vindicated by some of the text generated by GPT-3 in this document (See Text 3.1). This problematic text follows the axiom of 'garbage in, garbage out' associated with NLP, and in this case, since some of the open-access texts in the Pile are racist, sexist, homophobic, classist, etc., there are occasional instances where text of this nature is generated -remember that its source content is text from the broad internet, which can be admittedly toxic. However, this is rare as GPT-3's creators have added filters and trained it to create text that is aligned with socially acceptable content, though this type of work needs to be continuous (Ouyang et al., 2021) . Case in point, when one tries to create toxic and problematic text intentionally, it is often the case that the text drifts rather quickly to more 'comfortable' adjacent topics. Though with the technology being open-access as per Meta's announcement of their competing GPT-3 LLM with full documentation available (Zhang et al., 2022) , someone could theoretically create their own LLM and platform without these filters, granted they have the monetary means to run an LLM. The ethical implications of text generating technology on education is the key concern of this document. The possibility that a student can have large portions of their writing completed by an undetectable algorithm transcend the practical issues surrounding academic misconduct. This technology not only presents ethical considerations for academics, but also copyright and the nature of authorship (Mindzak & Eaton, 2021) . The inevitable deep level questions beget responses that may require foundational changes in text-based industries. Pre-text -Using various platforms, the following prompts and inputs were used by the curator to create the output texts. Re-generation, number of attempts, the platform, customization, and the intention of the curator are typically noted -these actions are examples of curation. In-text -Phrases and paragraphs that have had strikethrough applied were left to demonstrate some of the obvious inconsistencies in generated text. There are also authentic texts in the summarizing sections and are followed by summaries generated by GPT-3 based platforms. Post-text -One of the purposes of this document is for the reader to see common patterns in generated text, draw inferences to serve as discussion primers about the nature of GPT-3 generated text. As such, there is analysis after the text that aims to highlight some of these common patterns. Granted, this analysis is from one perspective, and alternate versions and interpretations are equally valid. 'Stylistic elements of note' are added, but they are not part of over-arching patterns, but rather interesting moments of particular texts. GPT-2 was the predecessor to the ubiquitously used and available GPT-3, so the platforms used to generate this text are now offline. GPT-2's release was limited by OpenAI to only a few developers, and it took several months for those developers to have publicly facing platforms. The platforms used to create this section were preset to generate multiple paragraphs from prompts, without specific purposes. As such, they have various stylistic idiosyncrasies in their texts. In some cases, particularly while using InferKit, settings were manipulated to curate more accurate and smoother text in successive attempts The texts generated in this section were created with stylistic presets from a variety of platforms. For example, 'social media post', 'blog post', 'summary' and 'essay introduction' are typical examples from sites like copy.ai and speedwrite.com. Output: You are lost in the forest. You've gone off trail... but you need to find your way back. You've been lost for five days now. You need to find your way back. As you roll along you begin to hit a rock head on. You quickly stick out your hand. You find your way back to the trail. Just to the north is a hickory grove. As you are looking around you see that you were not the only lost, that there was a group out there heading to the west. You decide to head that way. Your spirits rise. You might have been lost for hours. Output: We are seeing the end of human civilization. And this end of the world does not have anything to do with the crash of the world economy. ""In this financial crisis, the capitalist system has again, re-emerged. Of course it is falling apart. Not without cause. It has created enormous production demands for all sorts of commodities. You get them for the ""big stuff,"" i.e. raw Analysis: GPT-2 being a forerunner to the latest large language models definitely lacked some typical style elements typical of academic writing. In this case, transition strategies are sparse. There are also repetitive (""You need to find your way back"") and illogical moments (""As you roll along you begin to hit a rock head on.""). This simplicity of the initial sentences is another commonality of automatically generated text. It tends to begin with simple sentences and then prefers complex strategies (with the subordinator in the initial position) to compound strategies. Although simple declarative sentences are not typical of the contemporary professional writer, it is a precedented creative style of early 20 th century American literature (Glass, 2021) . materials, for fossil fuels. ""Big stuff"" isn't hard to come by, even if you aren't a capitalist. But no capitalist is going to invest money if there are not going to be buyers for the goods they are producing. So, you get an economic depression that requires a credit system. Platform: Talktotransformer.com (offline) Number of attempts: 1 Intention: Investigate text generated based on common sense advice. Prompt: ""Eat everything on your plate"" Output: Eat everything on your plate. You need to eat your veggies. There are no other foods that are more central to human food habits than vegetables. It's a deeply instinctual response, which is why it's both difficult to resist and easy to see how it is that some Americans, as well as many in other countries, seem to have no problem consuming massive amounts of them. What is hard to comprehend is how bad Americans truly are at sating their craving for carrots and broccoli, for example. When pressed, even most nutrition-aware Americans will quickly admit that they only eat vegetables because their parents ate them and they like them. ""It's just the way I am,"" they will say. But that's clearly not how it is for most Americans. Analysis: This is a pretty logical production of text with connections of sophisticated ideas, but of course, it's stretching logic in some moments. I, for one, have never heard commodities referred to as ""big stuff"". There is also the contention that GPT-2 might not have been able to create the counter, right-wing approach to this topic, but it is impossible to say as this model is now offline. One grammar error of note is that the initial quotation mark is present in the second line, but it is never closed nor attributed. Just a general reminder, all attributions made by current text generators are untrue, but occasionally, a coincidental historical fact will occur as far as attribution (see Text 2.1). • The use of double quotation marks to highlight phrases of concern • The correct use of the id est acronym --""i.e."" This is a great example of a self-contradictory response. The third and fourth sentences are contradicted by the fifth, and the final sentence (sixth) contradicts the fifth. There is also the pattern of the simple sentences (one and two) being followed by more and more complicated sentence strategies incorporating subordination, adjective clauses, noun clauses, and even quoted speech. Text 2.1 Platform: InferKit.com Number of attempts: 1 Regeneration: None Intention: Explore the ability to be specific to actual people and their accomplishments. Prompt: ""Who is the pre-eminent academic integrity researcher in Canada?"" Customization: Try to Include these words -""Sarah Eaton"" Output: That's a good question. All the pre-eminent academics i know have been, at some point, forced to submit themselves to academic integrity audits. Some have complied reluctantly, thinking their methods should not be challenged, despite the serious ramifications. Others have risen to their defense, to say they have used rigorous scientific methods to rigorously interrogate data, and the one person who hasn't been able to convince academics is Sarah Eaton. She has dedicated herself to studying academic integrity, and she has done a wonderful job of it. In fact, she has written an absolutely brilliant piece in The Conversation on academic integrity, and it is well worth a read. Sarah's definition of academic integrity is very clear and concise: ""We see academic integrity as a process. It is a step in research development that looks to improve the quality of what we do with data, and also seeks to enhance how we represent our research in public discourse."" I knew Sarah's name when I read about her in the Globe and Mail in 2012. My Phd thesis was on the adoption of the Liberal party during the 2006 Ontario election. My research focused on the pre-campaign period, and in particular the research approach of one of the liberal party leaders, Dalton Mcguinty, who was a former MPP. Prior to the 2006 election, McGuinty had proclaimed publicly he did not want any political donation or campaigning money from teachers. My research identified three reasons for McGuinty's change of position: first, teachers were concerned about getting into political trouble if they were caught breaking campaign finance laws by accepting donations, and second, teachers valued being part of the government process. Also, third, teachers thought they could be better represented if the government were more open to public discussions and debates on education policy. Prompt: ""How has honouring learner variability and/or social identity been important to you and how has this experience changed your thinking and actions?"" Output: It is true that we do have differences in the way we learn and it is up to us to be aware of that and acknowledge it. We shouldn't be trying to force learners into learning the way that we want them to learn it because that does not foster authentic learning. I believe learners have a role to play in building their own learning style which is how we actually become more Analysis: In this text, a seemingly inexplicable real-life, historical fact was produced: Sarah Elaine Eaton has indeed published in The Conversation about academic integrity (The Conversation, 2022). When I presented this to her, she was humbly adamant that the surrounding text be identified as ""editorial"". The assumption here is that educational topics (i.e., academic integrity) research and the Canadian context are related to the publication, The Conversation, and thus, the incidental connection is made. However, after the initial paragraph, an apparent heading ""Who is Sarah Eaton?"" appears, and we see more topical drift. It is interesting too that Sarah's definition of academic integrity (which is inaccurate here) occurs after the heading rather than immediately describing whom she is. In the third and fourth paragraph, the topical drift becomes very clear. Where it drifts to is of interest and a common pattern: when education is involved in a Canadian context, provincial politics are a popular topic for GPT-3, and the former Ontario Premier Dalton McGuinty is mentioned. As is often the case, the final paragraph is scarcely related to the input text. • Improved sentence complexity and sophistication • The redundant ""That's a good question"" at the outset is a typical 'word count' padding phrase. • The 'rule of three' list in the final paragraph (phrased in parallel structure) is commonly taught in composition classes. • There is an occasional lack of capitalization in this output -""i"" in the first paragraph and ""Mcguinty"" in the third. However, in other instances these are capitalized. • Irregular expression of ""Phd"" successful learners. I think the reason for this is because not everyone learns the same. You can have similar learning outcomes but if you do not have the capacity to have a consistent learning pace then it is not going to be successful for you.  If we believe the current theories on the cause of climate change, they are caused by sunspots, waves in the jet stream, El Nino, ocean currents, volcanic eruptions and other natural processes. There is no scientific theory to support the theory that carbon dioxide in the atmosphere and other greenhouse gases released into the atmosphere cause global warming and climate change. The Paris climate agreement is a questionable legal document. According to Thomas Jefferson, one of the signers of the Paris agreement, the ""authority of this instrument consists in nothing more than an agreement among governments, and not in a legal or political constitution."" In other words, the agreement is meaningless because it is not an international treaty ratified by the Senate. Climate change will not affect one's health. Current theories on climate change predict that sea level will rise, although this has not happened yet. There is no scientific reason to believe that greenhouse gas emissions cause an increase in atmospheric temperatures. Warmer temperatures in the Northern Hemisphere have resulted in record crop yields. As far as discussion board posts go, this would be a passable albeit underwhelming submission. Personally, I think that as a participating student or as an instructor, this would be glazed over for its vagueness, but the participation of the 'author' would be noted and graded. This raises the question of whether a blasé attempt at participating in a text-based discussion board would be acceptable in the world of online learning where text generators are ubiquitous. In the 50s and 60s, I had a friend who had a mean dog named Duke. He knew that Duke did not like people so he would spray him with water when he saw him. Duke would charge at the hose and let the water hit him, giving him an opportunity to be sprayed again. Would a gasoline-powered vehicle hold up if hit by a Ford Model T? Of course not. SURPRISE! The greenhouse gases that are in the air are not as bad as the world is made out to be. They are a necessary part of living in a civilized society. Like breathing, they have a purpose. SURPRISE! The system of global warming is based on flawed theories.  The first two paragraphs are clear and well-argued but slightly flawed. It uses climate related vernacular, but it does not provide deeper explanations of what it posits. The first sentence starts logically, and the text stays on topic throughout; however, the content again lacks accuracy and verifiable attribution. Obviously, Thomas Jefferson signed an important historical document, but not the one in question, and indeed treaties get ratified, but not by a Senate in this case (assumedly the referring to the legislative process of the USA). By the third paragraph, the arguable connections are few and the explanations disappear. The strikethrough paragraph seems to be an anecdote in an attempt at a historical anecdote for climate change. It is jarring to include it in the response, but the notion of using an anecdote as justification for an illogical claim is a common --if not fallaciousargumentative strategy. By the end, logic dissipates with the claim that a Model T Ford, an early 20 th century car, would damage a gasoline-powered vehicle, which of course, a Model T Ford is an example of. The rhetorical questions and addition of the ""SURPRISE!"" seems to give it a spoken, colloquial style, in an apparent shift from what started like academic or journalistic writing. • Anglicized characters in foreign loan words ""El Nino"" • All-caps rhetorical mode of sarcasm -""SURPRISE!"" Prompt: The author is definitely bent towards in-class learning as he has stated the disadvantages of online learning far more elaborately than online training providers. I found him clear, refreshing and very clear on the rationale behind his recommended approach. There is also no lack of important learning material to tap. It is well-designed and practical. The author made a strong case for some of the people who are invisible and voiceless in today's world. In the quest to make a long term difference, the author uses both modern education and technology to reach out to many. The author has chosen a good resource in the book to look at a ground-based method called 'Life Skills'. The term is derived from the Latin word 'condotta', which refers to a seed or a thought, a means of getting to know something or the way to lead a life. The author gives it the title 'Life Skills' with a clear and sharp focus on the factors that a person needs to be successful in his/her journey of life. This is a very useful book for students, employees and business professionals alike. It is one of those books that can benefit anybody whether you are an individual or an organization. The book has been reviewed and approved by India's biggest and best business school, IIM Ahmedabad. Again, the first sentence is a simple sentence with a rule-of-three list. Another interesting point is that the prompt contains gendered language and that is mirrored in the initial simple sentences. Then, then he/him is abandoned in favour of the vague, ungendered ""the author"", but the text never uses they/them, and in the third paragraph, it uses ""his/her"" determiners in lieu of ""their"". After searching a little more, in all the samples produced, GPT-3 never uses they/them in the hypothetical singular pronoun. Following this logic, it would be interesting to see if GPT-3 could produce text that acknowledges gender neutral/ non-binary people who use they/them as personal pronouns. Another problematic moment is the explanation of the Latin word ""condotta"". It is not a ""seed"", nor ""a means of getting to know something"", nor ""the way to lead a life"". The final sentence of this paragraph also uses the rule-of-three list. Interestingly, the institute IIM Ahmedabad exists in India, but it the superlative assessment of the it is, of course, editorial. Platform: Inferkit.com Number of attempts: 2 Regeneration: None Purpose: Investigate how GPT-3 responds to contemporary issues related to the COVID-19 pandemic) Prompt: The Canadian government should raise taxes on the very wealthy individuals and companies to help support small businesses and entrepreneurs affected by the COVID-19 lockdown. Inequality is a big problem in Canada. Many entrepreneurs, whether they're selling products or services or through creative businesses like being a house cleaner, can't take risk to launch their own businesses because they have no access to financing. Lower taxes for rich people create a powerful disincentive to risk, and to leave a job for another. As a tax policy, the Canadian tax system is more progressive than the U.S. system. If the Canadian government was more aggressive in raising taxes on the rich to pay for social programs, it could help ease the pain of Canadians who are feeling the impact of the shutdown. 3) Make travel more difficult. It's not like the U.S. government is doing anything to help travelers during this time either. So far there has been little public debate on how the shutdown will impact foreign travel and international air travel. People will fly to get home to their families, many of whom will be able to fly home even if flights in and out of the U.S. are shut down. If there's a national emergency, the U.S. government can do something to make air travel easier. In Canada, the government is doing nothing to help Canadians get home. So if there's an emergency, Canadians will be stuck. In fact, the Conservatives have made travel more difficult for people who are trying to enter Canada on a temporary visa. Canada's government has no contingency plan to handle the shutdown. And in the past it has struggled to respond to natural disasters, such as forest fires. So we'll probably end up having to find other ways to get around the shutdown. And it's not likely that the government will be able to help.  Plant-based diets keep humans healthy by consuming foods that are high in plant-based proteins and fibers while reducing the amount of meat that we eat. Not only do plant-based diets help with reducing the risk of heart disease, but they also reduce the amount of land needed to produce all the calories that we would need to sustain life. They also take less energy and produce fewer greenhouse gas emissions, which contributes to the environment. The above text was copied and pasted into the input field and regenerated. The Dietary Guidelines for Americans recommends a diet of about 15 percent of calories in carbohydrates, 15 percent in fat and 65 percent in protein. Research has shown that if Americans consumed this diet, we could avert about 12.6 million premature deaths, 58 million diabetes cases and 14.1 billion gallons of air pollution from global warming. Because The Pile was created before the COVID-19 pandemic, it rarely if ever references the name of the pandemic-inducing virus explicitly. This is consistent with other LLM platforms such as automatically generated transcripts in video platforms, which struggle to produce the scientific name of the virus. This speaks to the fact that updating educational materials to contemporary issues can mitigate the academic integrity issues that are inherent with text generators. However, it is interesting that it was able to associate ""lockdown"" with contemporary approaches to pandemics. It also latches on to another heavily written about topic when concerning Canadian approaches medicine -a comparison to the U.S. system. In the final paragraph, the Canadian context is again apparent as 'forest fires' are a natural disaster commonly experienced across Canada. In addition, the plant-based diet is environmentally friendly, as we don't need as much land to grow plants for our diets. In fact, plant-based diets have twice as much protein and five times as much fiber as meat-based diets. Some people find it challenging to cook from scratch and they struggle with making dietary changes. The importance of cooking at home for a vegan diet was presented by Rose Epstein, a registered dietician at the Barbara Ann Karmanos Cancer Institute in Detroit. ""There are lots of studies and research that shows it is the simplest things you can do to be vegan -making sure that you're buying foods that have no animal ingredients, so foods that have no genetically modified ingredients, things like canola oil, coconut oil, etc.,"" she said. ""You can't completely go vegan. You're still going to have to have cheese on your pizza, you're still going to have to have some chicken or fish, but you're going to have to limit the amount that you do eat."" Epstein suggested making a pantry and refrigerator for a vegan diet as well as a list of ingredients to avoid when shopping. The most common vegan substitutes for animal products include nut milks, tofu, soy, miso and nutritional yeast. Nut milks contain only water, and this is a very healthy choice for your body.  This is perhaps the best example of a text that includes statistics and authorities (Rose Epstein) that do not in fact exist; however, the ""Barbara Ann Karmanos Cancer Institute"" exists and is accurately placed in Detroit. This pattern is also seen in Text 2.3. Considering the vast amount of writing being done in lifestyle journalism, it has no problem making accurate claims about the topic. Although there is some balance between 'health' and 'environment', once the regeneration of the text happens, the output becomes much more focused on the health aspect of the prompt. It's propensity for lists is also evident here. This is also shows GPT-3's ability as far as using more sophisticated punctuation strategies, like hyphens, the em dash and quoted speech. With technologies like neural networks and genetic engineering, educational opportunities for a person's entire life could be enhanced. We will, therefore, probably have a better idea of who we want to be, what kind of future we want to create and what to expect in the future. It is also expected that our universe will evolve more rapidly. New physics, modeling and advanced technologies could be the end result of quantum physics and possible information theory, which might allow a person's mind to be changed. A significant difference in the information processing, perhaps? Future of electronic devices will change. A next step in the evolution of human beings, thanks to those who study it and those who use it. New means of creating, storing, displaying, monitoring and manipulating information, and brain-computer interfaces will help people to communicate and interact with their environment in more complex ways. Decisions about when, where and with whom we interact with our surrounding world will become irrelevant in the next few decades. Research and development in brain-machine interfaces will offer new possibilities to the blind, deaf and people with certain types of disabilities. All of them will be capable of reading, writing, moving, judging, predicting and performing a multitude of other operations. This also includes a next step in the evolution of human beings: neuro-modifications and life extension (through gene therapy, or simply replacing aged neurons and replacing missing neurons). Imagine a complete overhaul of the human mind in the next few decades? The 'list of three' rule is again apparent in the opening paragraph, but this output misses the mark as far as staying focused on education. The text is very broad and at points inaccurate, e.g. ""It is also expected that our universe will evolve more rapidly"". While many of the technological interventions it discusses are indeed related to education, the text never deeply explains any of them. ""Education"" is only mentioned once, but the aims of education, i.e., an improved future, are the focus of the text. While ""neuro-modifications"" do connect to a theoretical educational change in the future, much of what is proposed here is very distant horizon and focuses mainly on speculative technology. If the prompt was posed from a pedagogical context, this text would be far from accurate. Perhaps the interpretation of ""twenty-first century"" is that of a far-off future. • Sentence fragments at the beginning of the second paragraph: were these intended as headings/ subheadings? • Unclear pronoun in second paragraph ""All of them"". Is this in reference to the interfaces or the people? • Added rhetorical question mark at the end of each paragraph in sentences constructed as imperative statements.  A lot of people seem to think that walking is good for you, but they're wrong. Walking isn't an especially healthy form of exercise. In fact, it's downright unhealthy if you're doing it regularly. To make sure you're getting your exercise goals met, the American College of Sports Medicine recommends doing 30 minutes of aerobic exercise, 5 days per week, to help you lose weight and improve your health. The physical activity of choice should be aerobic, which means exercise that gets your heart rate up and improves your breathing and cardiovascular health. Walkers, however, tend to walk faster than runners. That extra speed is the reason why we haven't evolved to be able to breathe efficiently when we walk, says Dr. Frank Gorman, professor of anatomy at the Harvard Medical School. As a consequence, ""at rest, our heart rate is higher and breathing is more difficult,"" Dr. Gorman says. The longer you can keep your heart rate steady during a walk, the more efficient your breathing becomes. ""Just like your car works better when it's warmed up than when it's cold, the same thing happens when you walk,"" Dr. Gorman says. Most of us don't walk for exercise because we feel that we're too out of shape, but in reality, we're just fine. In fact, we're healthy, but we have trouble breathing because our bodies aren't getting the oxygen they need. The exercise you do should be pretty intense, not something that doesn't challenge your cardiovascular system, This does very reasonable job of staying on topic for such an unjustifiably inaccurate statement. It has several inaccurate and contradictory moments, but overall, it commits to its thesis and concisely states it as such in its concluding sentence. There are several moments where it appeals to authority, but again does not provide citations. The ""American College of Sports Medicine"" exists and does indeed recommend ""moderate intensity aerobic physical activity for a minimum of 30 min on five days per week"" (ACSM, 2022), but the generator takes liberties by implying that walking does not qualify. Further, there is a medical doctor, Dr. Frank Mark Gorman, (Mark P. Gorman, 2022) associated with Harvard Medical School and working in Boston, but he is not a professor of anatomy. Another interesting made-up fact that is believable, it is distinct from being factual. Output 1: It's been a really long journey, but I'm so glad that I have taken it. It has meant I have had the opportunity to try out lots of new things that I wouldn't have had the chance to do if I wasn't studying for my PhD. I've had some unbelievably good times and met some amazing people on my way through. Output 2: This is my first response to the article. I'll try not to repeat what has already been said, but I can't promise it because I did not read all comments. First of all, I want to say that this is an important article and that it's great that it makes readers aware of the situation in Poland (as well as other countries in central Europe). It would be fantastic if more journalists would write about this issue, so people could realise how women are treated there. I want to add two things: 1) The title suggests that Anna's doctorate was only possible because she was ""a woman"". Output 3: I am extremely proud of Anna and her accomplishments. This is a milestone that few ever reach, and Anna has earned it. She also had a very good reason to dance: she's in the same PhD program as me, and we both started in Fall 2010, so we've been in the same program for over 4 years now. Output 4: Reed's prestige is more about their alumni connections than it is about the quality of their students. It's not that they don't care, but one could argue that they have a vested interest in placing you wherever you're likely to have the best success. For example, if your best prospect for employment is probably Google, they'll put you in an MS program at Stanford (where Google has offices) rather than at another school where your prospects are not as good.  George Brown College is poised to transform Toronto's skyline with the construction of a masstimber building called The Arbour. The 10-storey structure -an addition to our Waterfront Campus -will be the first mass-timber and low-carbon institutional building in Ontario. Sherbourne Street, just north of the Daphne Cockwell Centre for Health Sciences. Output 1: This would be a very self-serving congratulatory message as it doesn't acknowledge Anna and focuses entirely on the author's own experience studying for their PhD. Output 2: This refers to an article that was not part of the prompt, but it does do some interesting things. First, it refers to Poland based on the surname ""Bartosik"" and then begins to focus on vague women's issues. It ends on a singular list item without adding a second as it purports. Most concerningly is that the final sentence could be construed as an example of discriminatory bias, but the lack of completion leaves this problematic statement unexplained. Output 3: This starts off with what would be a congratulatory post but drifts topically into the personal connection to the author rather than engaging with Anna's accomplishments as one would expect. Likewise, the timeline for completing a PhD could be considered anachronistic depending on the date of the post. This seems like a vague explanation/ criticism of Reed College's co-op placement program, which is far from the intended message. 1. The Arbour, a new 10-storey mass-timber and low-carbon institutional building from George Brown College, will be the first of its kind in Ontario. Construction begins in fall 2021 at the corner of Queens Quay East and Lower Sherbourne Street, just north of the Daphne Cockwell Centre for Health Sciences. 2. The Arbour, a 10-storey structure, will be the first building in Canada built with mass timber and will transform Toronto's skyline. It will be an addition to George Brown's waterfront campus at the corner of Queens Quay East and Lower Sherbourne Street, just north of the Daphne Cockwell Centre for Health Sciences. 3. The Arbour is a mass-timber building, designed to be built significantly faster and use less energy than traditional timber buildings. Construction begins in fall 2021 at the corner of Queens Quay East and Lower Sherbourne Street. It will be an addition to our Waterfront Campus and the first one in Ontario. [A] Restaurant operators across Canada are struggling to find enough staff to run their operations. This labour crisis has been highly publicized by Canadian media as a ""labour shortage."" A recent survey by Restaurants Canada found that 80 per cent of food service operators were finding it difficult to hire kitchen staff and 67 per cent were having trouble filling serving, bar-tending and hosting positions. Prior to the pandemic, Canada's food service sector employed 1.2 million people, and according to Statistics Canada it currently needs to fill 130,000 positions to reach pre-pandemic levels. That said, the Canadian restaurant industry has been struggling with hiring and retention problems for many years. Should the chronic hiring struggles of Canadian restaurants be referred to as a labour shortage, or can it be more accurately portrayed as a retention issue fueled by a lack of decent work? [C] A 2010 Canadian Restaurant and Foodservice Association report found that 22 per cent of Canadians worked in a restaurant as their first job -the highest of any industry. The study also found that 32 per cent of Canadians have at one point worked in the restaurant industry. These statistics show that millions of Canadians have been introduced to restaurant work and the industry has enjoyed a seemingly endless supply of labour for decades. So why is it that the restaurant industry is burning through so many people? [D] Our research on restaurant work conditions shows that working in a restaurant is difficult, requiring the sacrifice of work-life balance due to long hours and unpredictable schedules. While restaurant work can be rewarding and fun, it can also be low-paying, stressful and physically demanding, all of which can have a negative impact on mental health. Many restaurant workers spend at least eight hours a day on their feet with no time for breaks or meals. Workers are also required to forgo their social and family life by having to work late nights, weekends and holidays. Many restaurant workers almost never know precisely when their shifts will end, and tend to be placed on unpredictable split shifts or ""on call"" shifts to save labour costs. [E] The restaurant industry has also been rampant with sexual harassment, abuse and toxic work environments. A Statistics Canada study found that hospitality workers have the worst job quality out of any industry. This was largely due to low earnings, the inability to take time off, no paid sick leave, a lack of training opportunities and no supplemental medical and dental care. This same study found that 67 per cent of hospitality workers work in jobs with work conditions that fall below decent work levels. [F] So what exactly is ""decent work?"" It's a concept established by the International Labour Organization and is linked to the United Nation's Sustainable Development Goals. Decent work establishes universal conditions of work that are central to the well-being of workers. These conditions are considered to be minimum labour standards that include living wages, work hours that allow for free time and rest, safe working environments and access to health care. Decent work is considered a human right but based on the conditions of restaurant work, it appears the Canadian restaurant industry is struggling to provide it to all of its employees. [G] Through our research on restaurant work, and via conversations with many restaurant employees across the country, we've learned that many are fleeing the industry because the work is a grind. What's more, they don't see any future in a job that will continue to hinder their well-being. The pandemic allowed workers time to find jobs in other industries that provide more stability and feature regular work schedules, vacation time, higher pay and benefits. These workers often felt neglected, and that their employers did not believe they were worth investing in. While there are certainly good restaurant employers, the industry as a whole has failed to improve working conditions because historically, there were always new people to fill roles. [H] That raises the question: Could the continuous reference to a labour shortage in the restaurant industry actually be creating a lack of urgency in addressing longstanding issues of work quality? If restaurants want to operate at full staff in the post-pandemic future, they need to invest in their employees because, after all, it's impossible to run a restaurant without people working in it. The restaurant industry has always spent money, time and resources to attract customers and increase revenues. It's long past time for restaurant operators to consider their employees internal customers, and put as much effort into providing great experiences for them as they do for their external customers. A good place for operators to start is by providing decent and dignified work for all that provides decent wages, benefits and healthy working conditions. The solutions aren't easy. But restaurants can start by paying decent wages. It's not hard to find someone in Ontario to hire for $12 or $13 per hour, while Ontario has a high cost of living that sees regular prices in restaurants regularly exceeding $30 per person. But restaurant workers need to receive fair pay because the salary is set in the labour contracts they work under. What's more, many restaurant employers are legally obligated to provide workers with these fair wages by law. When combined with the lack of training opportunities and no supplemental medical and dental care, the health impacts for restaurant workers in Ontario are far-reaching. Whether it's working in a restaurant that supports community-based employment or giving all employees access to health benefits, restaurant employers need to acknowledge the overall health consequences that their employment practices have on restaurant workers. The importance of adequate food safety is not limited to where the food is coming from, but the entire supply chain. What's more, restaurant workers should not be discriminated against based on their age, gender, race, religion or disability status. Although detection of students using text generating platforms is possible, it remains pedagogically problematic and lacking certainty. There is no detection algorithm, and as previously mentioned, likely won't be one for some time, so assessors must rely on their subjective interpretation of student work. Even if a submission contains the hallmarks discussed in the analysis above, there is still no definitive proof as to whether a text generator was used. For cases of academic misconduct, a student would have to admit the transgression, and as always, it would be a contextual decision made by the teacher as to what the consequences, if any, might be. The following are both novel and known approaches to written assessment that can help mitigate the use of text generators. Keeping track of student writing may be one of the most effective suggestions for detecting the use of automatically generated text, and in the age of cloud storage and shared documents, one of the most practical. If an instructor is suspicious of an entire paper or a passage, having access to the student's previous work could function as a better primer for discussion about what elements of writing they are struggling with and why they elected to use a text generator. Of course, this is a simple task for a single semester or academic year if the instructor is consistent, but it could become more powerful, albeit more complicated, if an ongoing document of a students' work was carried with them through grades and perhaps even through institutions. Not only is this applicable in typical K -12 and post-secondary contexts, but it could also be applied to adult language learners. Continuing into the world of employment, such a document could be used in text-based careers like journalism and academia, thus allowing for verification that someone was indeed writing the content that they claimed. This possibility is perhaps an opportunity for an entrepreneur looking to utilize blockchain verification methods in education. Of course, there would be pedagogical possibilities for such a document; a student could much more readily reflect on their progress as a writer. Too often students ignore feedback and focus on grades, and past writing examples can get lost between hard drives and cloud storage. One of the functions of text generators that pose a problem to traditional language arts assessments is summarizing (see Text 3.3). Unlike text spinners that simply use a thesaurus program to swap vocabulary items, large language model platforms can change sentence structure, as well as re-interpret the ideas with mixed success. In fact, one platform of note, Speedwrite, has made this its major function and is currently marketing itself to students on social media (TikTok, 2022). However, there is a way to detect whether a large language platform was used to create summaries, albeit highly problematic concerning accessibility issues and academic integrity best practices. The 'trick' involves using the ""Find and Replace"" function in a word processor to replace all instances of the lower-case English character ""i"" with the Turkish language dot-less version ""ı"". Then, one must convert the document to a PDF as to not alert the reader to the multitude of spelling errors that would be detected by a word processor. If this altered text from the PDF is then pasted into current versions of text generators, depending on the presets of the platform, the ""ı"" will either disappear in generated text or be replicated by the text generator. See the image below using Speedwrite to see an instance where it is deleted (see ""reducng"", ""crss"" and ""arrve""). This 'trick' can also be performed with the Cyrillic character ""г"" to replace the English character ""r"" in some typefaces, but it is more obvious in the output as there may be instances of additional Cyrillic characters and even full Cyrillic words. There are other probable versions where this method could be replicated with varying results. Beyond this being an ethically dubious ""gotcha"" strategy (Price, 2002) as far as identifying academic misconduct, it is also a problem for accessibility as a screen reader will not be able to interpret words with the ""ı"" and will mispronounce them. Considering the frequency of this vowel, the entire PDF document becomes unreadable to a screen reader and thus inaccessible. However, it would be unreasonable to completely ignore this idiosyncrasy as it may prove valuable in future research. As demonstrated in the previous sections, some language-based assessment tasks are very easily completed by text generators. Chapter/ article summaries, short answer questions of a general nature, and online discussion board posts -all common assessment tools in the late twentieth and early twenty-first centuries -can be completed with passable success. Though these skills are still presently valued, and thus these assessments are still valid, the next generation of education will have to continue to augment their assessments to ensure academic integrity. Educational frameworks that put an impetus on authentic, meaningful attempts (whether successful or not) not only account for academic misconduct using AI and beyond, but they also encourage students to try to develop their skills, rather than gamify passing a course. Though there is an oft-dogmatic requirement in academia to exclude the subjective experience of the author, including a requirement of a connection to a writer's experience can ensure that the vague, general writing demonstrated by LLM text generating platforms is not the sole requirement of an assessment. While there will always be a functional place for including broad, topical writing, it cannot be the only type of writing that is required in an assessment. Adhering to specified expectations of style and form could be an interesting outcome for student writers to master. To this end, creative writing education will need to adjust as GPT-3 platforms are apt at creating poetry and prose, although they tend to rely on cliché content and form (Macaulay, 2021) . Another hallmark of GPT-3 generated text is that it cannot accurately add research with correct attribution of ideas and quotes to its creations (as of the time of writing). Therefore, making research and attribution a stronger focus of student outcomes works both to limit the impact of LLM generators/ transformers and also improves critical thinking anchored in deep research skills. One way to minimize the impact of text generating and transforming platforms on traditional writing assignments is to modify the process and requirements of these assignments. For example, rather than requiring a summative essay as a major portion of a grade, having requisite elements like an annotated bibliography or an outline would require students who are relying on automated writing tools to reverse engineer their essay. Since much academic misconduct often occurs late in semesters in an act of desperation, more time and mark value given to process assignments minimizes the opportunity to rely on automated writing (Eaton, 2021) . It is important to note that in many educational contexts, making scaffolded and formative assessments mandatory to write summative assessments would require a change in grading policy from school administrators. Also, having an opportunity to conference with students throughout the semester about their writing provides valuable collaborative moments. It verifies that students are indeed putting time and thought into their writing and allows teachers to suggest resources and content that can improve the student's writing skills. This can be done virtually using shared documents and can be an ongoing, asynchronous conversation using 'comments' functions. Again, having the time to do this is a key consideration, and large class sizes are not conducive to this process. Creative formats and re-interpretations of essays also give students opportunities to explore digital tools for creating infographics, podcasts and videos. Allowing for multiple means of expression is discussed further the Universal Design for Learning (UDL) section below. Discerning writing-assistive technologies from one another is not a productive nor inclusive pursuit. The lines between spell check, grammar check, editing functions, Grammarly, translation, spinners, text transformers and text generators are not worth debating as to what constitutes the threshold of a breach in academic integrity. (Eaton, 2021) In fact, with the correct presets, students also can use text generators as prompt creators and language learning tools. However, technological aides do not level the playing field of skill building as students have diverse abilities and needs. As is with high-quality academic publishing, the ethical disclosure of conflicts of interest provides insight into what we can do to model the disclosure of language tool usage. The inclusion of disclosure of what tools are used and how they contributed to a text serves to allow a reader to make a judgement of the integrity. Disclosure will also be fruitful for readers and assessors to classify assistive tools and begin to discuss and share best practices for learners. The flipped classroom model was popularized by Bergmann & Sams (2012) and there has been significant research into its success over the last decade. The key concept is that students engage with learning materials like reading and videos outside of the classroom, and then they spend the in-class time as a proving ground for their understanding of the concepts. This also allows for a more adaptive approach to learning since students who are struggling to master concepts can be given extra resources more efficiently, rather than waiting for their instructors assessment, which can take time to complete. Although the flipped classroom is not popular in language arts classes, its implementation would serve to minimize the usage of text generating platforms. One caveat would be that in-class writing seems like a waste of in-class time wherein there is so much opportunity for students to collaborate. To address this, teachers would need to adapt activities such as group writing and peer editing that utilize social dynamics of synchronous classes (both virtual and face-to-face). As per the previous section, there are opportunities for further creative and alternative assignments for teachers and students to explore in this model. UDL is, broadly speaking, an approach to education via instructional design that accounts for diversity in learners. It replaces the debunked concept of learning styles and incorporates accessibility as the default for all content and material. The three core components of UDL are multiple means of representation (the learning content), multiple means of engagement (how students interact with the content), and multiple means of expression (how students demonstrate their understanding of the content). Through this lens, educators provide expanded options for all three stages of learning and students can self-select what interventions they perceive as the best option for themselves (CAST, 2022) . Indeed, this approach requires more individual interaction between students and teachers, and fewer synchronous in-person lectures. It is easy to see the alignment between UDL and the flipped classroom as well. The axiom goes that pedagogy comes before tools, but I contend that here the pedagogy is dependent on the improvement of tools, and if the technology of LLM serves to disrupt education, it also is serving the ends of improving our ability to deliver universally designed curriculum. One of the best demonstrators of UDL tools is captioning in videos. Closed captions first occurred in television and film in situations where a foreign language was being spoken or to accommodate the hard of hearing. On cable television, a special setting enabled the digitized scripts to be broadcast alongside programs, with the double-edged intention of adhering to accessibility legislation and expanding the television audience. Now, captions have been automated by, yes, LLM. Though there are still improvements to be made, automated captions have been greatly improved over the last few years by improved language recognition. As a multiple means of representation, captions are a tool that enables people to better understand videos regardless of their auditory ability or their language status; however, captions also help all people to view a video when they are in a situation where sound is not an option. This intervention, enabled by powerful NLP algorithms, allows for greatly expanded access to educational materials. Beyond captions, LLM can improve translation, generate better search terms, give writing suggestions and even create prompts for students who might be stuck for ideas (Kucanin & Morrison, 2022) . Concerning the use of UDL to account for an increased use in text generators, a curriculum designed around meeting students' learning abilities provides less of an impetus for students to take shortcuts. Since UDL is inherently an anti-oppressive framework, students are given time to master concepts rather than rushed through rigid, prescriptive educational tasks (Fritzgerald, 2020) . If a teacher and student can negotiate the acceptable uses of text generators/ transformers, then the problem of academic misconduct evaporates, and the student can critically analyze the nature of these platforms without regarding it being 'a hack' to complete written work. While the rates of automatically generated text being submitted by students has not yet been studied, it stands to reason students will try with mixed success to use this technology to automate their writing. With no apparent route for the automation of identifying these texts, educators will need to re-assess what their best practices are. Of course, not all students will take this shortcut, but with predatory contract cheating services potentially utilizing LLM to lower their prices, there is an increased probability that students will consider the value proposition of paying to pass a course. If one of the issues presented by this technology is that students can pass classes based on inauthentic work, then perhaps we as educators should be searching for other frameworks that preclude inauthenticity and rely less on deadlines. Universal Design for Learning (UDL) framework, for example, provides modes of expression that don't put students in a position where they need to use prescribed, singular formats, i.e. an essay, to meet outcomes of a course (CAST, 2022) Adaptive learning likewise allows for students to progress at their own pace rather than adhering to rigid deadlines. These along with a host of other antioppressive approaches to education serve to lessen the impetus for students to cheat and rather allow flexibility for students to improve their skills regardless of the external factors governing their academic behaviour (Verschelden, 2017) It is also important to think about the context of how these technologies might be used in education. In the context of academic publishing, complete papers being generated are not a present possibility. One researcher notes that ""At present, any half-awake honest reviewer would reject a paper generated by AI Transformer programs. But if AIs can be tuned to academic writing and made to reference real papers, they will make reviewing far harder."" (Sharples, 2022) . Also, one of the services provided by the GPT-3 powered platform Writefull is that of an automated abstract generator (Writefull, 2022) . While this is new ground for discussion, automating an abstract seems less harmful than other forms of academic misconduct, and perhaps would not even qualify as such if the researchers provided disclosure of using that tool -indeed, this tool actually makes academic publishing more inclusive and accessible for those who do not speak a target language of publishing or struggle with writing despite their expertise in another field of study. However, when AI can also be used to create images that convey dishonest lab results --considering the stakes involved in medical research --it poses a very real threat to human lives (Krämer, 2022) . Thinking about the usage of this technology through the lenses of both contemporary issues of academic integrity and classical philosophical perspectives provide a primer for ethical discussions that are just beginning (Kumar et al., 2022) . As with all technology, an attempt to regulate LLM would be arduous if not impossible at this point. Though this technology is disruptive and 'scary' for many of us, make no mistake that it is a phenomenal achievement in the field NLP. The existence of these tools hopefully elicits more fruitful actions pedagogically that will serve the future generations of writers, researchers, and thinkers to push the boundaries of what meaningful, human communication entails. & 2 -Most of the changeable vocabulary has remained the same('low-carbon', 'additional', 'skyline', etc.), but the order in which the information is presented has been transformed. The sentence structures change slightly but appear mostly similar.3 -In addition to the above stated pattern, this version adds a fact about mass timber buildings that was not in the source text, ""…designed to be built significantly faster and use less energy than traditional timber buildings"".Overall:The paraphrasing functions of GPT-3 correctly identify proper nouns that can not be changed, but are still reliant on similar sentence strategies.","/scholar?q=related:oDAmyDtDyGwJ:scholar.google.com/&scioq=%22large+language+models%22+%2B%22higher+education%22&hl=en&as_sdt=0,33&as_ylo=2000&as_yhi=2023"
